{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"changelog/","text":"Changelog \u00b6 0.7.0 (2022-07-20) \u00b6 Full Changelog Documentation updates: Document supported GraphQL elements #32 Broken links in documentation #11 Move solutions to main repository #7 Miscellaneous: Expose partition information in mirror #30 TopicTypeService should be aware of different schema formats #24 GraphQL to Protobuf converter #23 Ensure Protobuf schema doesn't exist when creating a new topic #22 New configuration variable for schema type #21 Improve validation checks for the topic directive #20 Enable the app deployment from a private container registry #18 Design: Protobuf support #17 No error message when creating the same gateway, app, or mirror multiple times #15 New TypeResolver for Protobuf #2 Support reading Protobuf data #1 0.6.0 (2022-04-24) \u00b6 Open-Source release \ud83c\udf89","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#070-2022-07-20","text":"Full Changelog Documentation updates: Document supported GraphQL elements #32 Broken links in documentation #11 Move solutions to main repository #7 Miscellaneous: Expose partition information in mirror #30 TopicTypeService should be aware of different schema formats #24 GraphQL to Protobuf converter #23 Ensure Protobuf schema doesn't exist when creating a new topic #22 New configuration variable for schema type #21 Improve validation checks for the topic directive #20 Enable the app deployment from a private container registry #18 Design: Protobuf support #17 No error message when creating the same gateway, app, or mirror multiple times #15 New TypeResolver for Protobuf #2 Support reading Protobuf data #1","title":"0.7.0 (2022-07-20)"},{"location":"changelog/#060-2022-04-24","text":"Open-Source release \ud83c\udf89","title":"0.6.0 (2022-04-24)"},{"location":"roadmap/","text":"Roadmap \u00b6 The roadmap outlines topics that are currently worked on and gives an overview of the project's future direction. We track and priorities planned features through the corresponding milestones and project boards . Upcoming releases \u00b6 0.8 \u00b6 Development: Q3 2022 Improved gateway performance: Pre-computation of a key's location Kafka 3.0 support Further ideas \u00b6 Kafka-Streams library for custom REST APIs in Quick More complex query arguments, like ranges and filters Support for custom authorization Support different ingress controllers like nginx Completed releases \u00b6 The changelog has a detailed list of releases. 0.7 \u00b6 Protobuf support 0.6 \u00b6 Open-Source release \ud83c\udf89","title":"Roadmap"},{"location":"roadmap/#roadmap","text":"The roadmap outlines topics that are currently worked on and gives an overview of the project's future direction. We track and priorities planned features through the corresponding milestones and project boards .","title":"Roadmap"},{"location":"roadmap/#upcoming-releases","text":"","title":"Upcoming releases"},{"location":"roadmap/#08","text":"Development: Q3 2022 Improved gateway performance: Pre-computation of a key's location Kafka 3.0 support","title":"0.8"},{"location":"roadmap/#further-ideas","text":"Kafka-Streams library for custom REST APIs in Quick More complex query arguments, like ranges and filters Support for custom authorization Support different ingress controllers like nginx","title":"Further ideas"},{"location":"roadmap/#completed-releases","text":"The changelog has a detailed list of releases.","title":"Completed releases"},{"location":"roadmap/#07","text":"Protobuf support","title":"0.7"},{"location":"roadmap/#06","text":"Open-Source release \ud83c\udf89","title":"0.6"},{"location":"developer/architecture/","text":"Architecture \u00b6 Quick has the following high-level architecture: The system is deployed in Kubernetes. We use Traefik as an ingress load balancer that can route to the manager, ingest service, and gateways. Since Quick central functionality is built on top of Kafka, we also use it to store any metadata. Traefik \u00b6 We use Traefik as a load balancer. For routing, Traefik is configured through two K8s resources: Ingress and Middleware . An ingress defines a path to service mapping, e.g., demo.d9p.io/manager should go to the manager service. The ingress is annotated with a middleware: apiVersion : networking.k8s.io/v1 kind : Ingress metadata : annotations : traefik.ingress.kubernetes.io/router.middlewares : quick-demo-service-stripprefix@kubernetescrd We use the middleware to strip prefixes from the path. For instance, we can access GraphQL of the gateway demo through https://demo.d9p.io/gateway/demo/graphql . The middleware ensures that Traefik forwards this request to http://quick-gateway-demo/graphql . For gateways, the manager has to deploy those resources. Manager \u00b6 The manager handles user requests from the CLI . Most tasks are therefore based on k8s resources. We use a templating engine for a new resource that creates the respective YAML strings. The strings are then loaded into fabric8io k8s client's models and sent to the k8s API. Additionally, the manager has administrative-like tasks: * deployment of the topic registry at startup * deletion of succeeded jobs Ingest \u00b6 The ingest service is an HTTP service for ingesting data into a Kafka topic. As this requires serializers for the keys and values, we need to know which to use. The ingest service requests (and caches) this information from the topic registry. Further, when a topic is immutable in the topic registry, the ingest service first checks its mirror. Mirror \u00b6 Mirrors are Kafka Streams applications that read the content of a topic and expose it through a key-value REST API. See our our blog post for more information on why we use this approach. A mirror is automatically deployed when the user creates a new topic. Gateway \u00b6 The gateway is Quick's implementation for the GraphQL server. The user can apply a schema to it through the manager. Common \u00b6 All our subprojects share a library called common . The package contains code that is used throughout the projects, including: exception-handling configs security (API-Key) API models","title":"Architecture"},{"location":"developer/architecture/#architecture","text":"Quick has the following high-level architecture: The system is deployed in Kubernetes. We use Traefik as an ingress load balancer that can route to the manager, ingest service, and gateways. Since Quick central functionality is built on top of Kafka, we also use it to store any metadata.","title":"Architecture"},{"location":"developer/architecture/#traefik","text":"We use Traefik as a load balancer. For routing, Traefik is configured through two K8s resources: Ingress and Middleware . An ingress defines a path to service mapping, e.g., demo.d9p.io/manager should go to the manager service. The ingress is annotated with a middleware: apiVersion : networking.k8s.io/v1 kind : Ingress metadata : annotations : traefik.ingress.kubernetes.io/router.middlewares : quick-demo-service-stripprefix@kubernetescrd We use the middleware to strip prefixes from the path. For instance, we can access GraphQL of the gateway demo through https://demo.d9p.io/gateway/demo/graphql . The middleware ensures that Traefik forwards this request to http://quick-gateway-demo/graphql . For gateways, the manager has to deploy those resources.","title":"Traefik"},{"location":"developer/architecture/#manager","text":"The manager handles user requests from the CLI . Most tasks are therefore based on k8s resources. We use a templating engine for a new resource that creates the respective YAML strings. The strings are then loaded into fabric8io k8s client's models and sent to the k8s API. Additionally, the manager has administrative-like tasks: * deployment of the topic registry at startup * deletion of succeeded jobs","title":"Manager"},{"location":"developer/architecture/#ingest","text":"The ingest service is an HTTP service for ingesting data into a Kafka topic. As this requires serializers for the keys and values, we need to know which to use. The ingest service requests (and caches) this information from the topic registry. Further, when a topic is immutable in the topic registry, the ingest service first checks its mirror.","title":"Ingest"},{"location":"developer/architecture/#mirror","text":"Mirrors are Kafka Streams applications that read the content of a topic and expose it through a key-value REST API. See our our blog post for more information on why we use this approach. A mirror is automatically deployed when the user creates a new topic.","title":"Mirror"},{"location":"developer/architecture/#gateway","text":"The gateway is Quick's implementation for the GraphQL server. The user can apply a schema to it through the manager.","title":"Gateway"},{"location":"developer/architecture/#common","text":"All our subprojects share a library called common . The package contains code that is used throughout the projects, including: exception-handling configs security (API-Key) API models","title":"Common"},{"location":"developer/cli/","text":"CLI \u00b6 Our CLI is written in Python. It has two modules: quick_client and quick . The quick_client module is the REST API client for the manager. It's automatically generated as explained in Development - OpenAPI The quick module is a CLI wrapper for the REST API client. Development \u00b6 Setup \u00b6 We use poetry as build system. You can run poetry install in the project directory. This command creates a new virtual environment with all runtime and dev dependencies installed by default. Note You can run poetry config virtualenvs.path <PATH> to set the path where virtualenvs are created. To create a new version and install it, run: poetry build -f wheel && \\ pip install ./dist/quick_cli-0.1.3-py3-none-any.whl --force-reinstall If you want to add a new dependency, make sure to commit the updated poetry.lock file. Code quality \u00b6 We use flake8, isort, and black for formatting and linting the project. You can use the provided pre-commit-config to make sure your PRs pass. Install the hooks with pre-commit install (making them run before each commit). You can also run them manually with pre-commit run --all-files . Currently, mypy is excluded from pre-commit. However, feel free to run mypy . and fix possible errors. Documentation \u00b6 The CLI comes with an argparse-to-markdown script for generating the CLI's documentation. The created file is commands.md . After updating commands, update it with the following command: python quick/generate_docs.py > commands.md Architecture \u00b6 The CLI uses Python's ArgParse . It follows an OOP approach for defining new subcommands. There are two base classes: Group A Group is a subcommand that has one more child subcommands. The subcommands are defined in its sub_parser field. Attention A new top-level group (i.e., used as quick <new-group> ) must be added the COMMANDS list in commands/__init__.py . Command A Command is a subcommand that executes an action. You can override the add_args method to add new required and optional arguments. The execute method contains the logic for the command action. This approach using base classes lets us define common behavior, like recurring arguments (for example, --debug ) and setup configurations.","title":"CLI"},{"location":"developer/cli/#cli","text":"Our CLI is written in Python. It has two modules: quick_client and quick . The quick_client module is the REST API client for the manager. It's automatically generated as explained in Development - OpenAPI The quick module is a CLI wrapper for the REST API client.","title":"CLI"},{"location":"developer/cli/#development","text":"","title":"Development"},{"location":"developer/cli/#setup","text":"We use poetry as build system. You can run poetry install in the project directory. This command creates a new virtual environment with all runtime and dev dependencies installed by default. Note You can run poetry config virtualenvs.path <PATH> to set the path where virtualenvs are created. To create a new version and install it, run: poetry build -f wheel && \\ pip install ./dist/quick_cli-0.1.3-py3-none-any.whl --force-reinstall If you want to add a new dependency, make sure to commit the updated poetry.lock file.","title":"Setup"},{"location":"developer/cli/#code-quality","text":"We use flake8, isort, and black for formatting and linting the project. You can use the provided pre-commit-config to make sure your PRs pass. Install the hooks with pre-commit install (making them run before each commit). You can also run them manually with pre-commit run --all-files . Currently, mypy is excluded from pre-commit. However, feel free to run mypy . and fix possible errors.","title":"Code quality"},{"location":"developer/cli/#documentation","text":"The CLI comes with an argparse-to-markdown script for generating the CLI's documentation. The created file is commands.md . After updating commands, update it with the following command: python quick/generate_docs.py > commands.md","title":"Documentation"},{"location":"developer/cli/#architecture","text":"The CLI uses Python's ArgParse . It follows an OOP approach for defining new subcommands. There are two base classes: Group A Group is a subcommand that has one more child subcommands. The subcommands are defined in its sub_parser field. Attention A new top-level group (i.e., used as quick <new-group> ) must be added the COMMANDS list in commands/__init__.py . Command A Command is a subcommand that executes an action. You can override the add_args method to add new required and optional arguments. The execute method contains the logic for the command action. This approach using base classes lets us define common behavior, like recurring arguments (for example, --debug ) and setup configurations.","title":"Architecture"},{"location":"developer/contributing/","text":"Contributing \u00b6 Code quality \u00b6 The project uses several plugins to ensure code quality. Most of them run during the compilation of the project. Any warnings or errors should be addressed before merging. Checkstyle \u00b6 We use Checkstyle to enforce our coding style. The configuration is located in the config/checkstyle/checkstyle.xml . It's based on Google's Java coding style. You can download the Checkstyle Plugin in the IntelliJ Plugin Store. By importing the checkstyle.xml as code style, the reformat action Ctrl + Alt + L works with it. Further, you can run Gradle tasks checkstyleMain and checkstyleTest . These tasks list problems in the shell and create an HTML report located in build/reports/checkstyle/ . Copyright header \u00b6 All .java and .kt files should contain a copyright header. IntelliJ can automatically prepend the header for new classes using a copyright profile. To set up the functionality, import config/copyright/quick-license.xml in Settings | Editor | Copyright | CopyrightProfiles . Checkstyle will alert you if the header is missing. To prevent Intellij from putting headers to all other kinds of files, you can create a custom shared scope in Settings | Appearance & Behaviour | Scopes with pattern file:*.java||file:*.kt and associate this with the copyright profile in Settings | Editor | Copyright . Error Prone \u00b6 Error Prone extends the Java Compiler to catch common mistakes. It's enabled by default when compiling with Gradle. Attention Lombok and Error Prone don't work that well together. There might be some false-positives when Lombok is used. If possible, use @SuppressWarning . Otherwise, disable the check completely in the QuickCodeQualityPlugin . Furthermore, Error Prone throws an IndexOutOfBounds exception for the pattern UnusedVariable when a Lombok annotation adds an unused field. That may usually happen with @Sl4j . In such cases, remove the annotation as it isn't used. IntelliJ Setup \u00b6 To add the plugin, start the IDE and find the Plugins dialog. Browse Repositories, choose Category: Build , and find the Error-prone plugin. Right-click and choose Download and install . The IDE will restart after you\u2019ve exited these dialogs. To enable Error Prone, choose Settings | Compiler | Java Compiler | Use compiler: Javac with error-prone and also make sure Settings | Compiler | Use external build is not selected. NullAway \u00b6 NullAway is a tool to help eliminate NullPointerExceptions (NPEs) in your Java code. It's built as a plugin to Error Prone. With NullAway, the compiler assumes that a variable is never null unless there is a @Nullable annotation. Attention @Nullable has its origin in the JSR 305 that has been dormant since 2012. Therefore, using javax.annotation.Nullable is problematic. We chose to use edu.umd.cs.findbugs.annotations.NonNull instead. Jacoco \u00b6 We use Jacoco for test coverage. The ReporterPlugin creates the task codeCoverageReport that creates a test report in build/reports/jacoco . There is an HTML report for manual inspection and an XML report that you can export to Sonarqube. Sonarqube \u00b6 There is currently no public Sonarqube project. You can run one locally and set the properties in gradle.properties . Issues \u00b6 We use GitHub issues to keep track of our tasks. Issues should always have one or more labels . Pull Request Workflow \u00b6 The master branch is protected, i.e., you can't push directly to it. We use a workflow similar to GitHub Flow , except that we squash Pull Requests (PRs). You start by creating a new local branch, committing the changes, and creating a PR on GitHub. Please don't wait till the end of creating the PR and try to keep it small(ish). Git Branch \u00b6 The branch should have a meaningful name and roughly follow the scheme TYPE / COMPONENT / TOPIC . For example, when working on a new feature in the manager, feature/mananger/new-feature could be used. You can drop TYPE and/or COMPONENT if they aren't applicable. The name carries some importance because it's used in the CI for tagging the images created for the PR. For example, the branch feature/mananger/new-feature can be deployed with the tag feature-manager-new-feature . it helps find your way in git. Pull Request \u00b6 Some general guidelines regarding Pull Requests: Use a meaningful title (not the default branch name) and add a short description for non-trivial changes. Publish your branch early on, and create a draft PR in case it isn't ready. This allows for early feedback and helps prevent misunderstandings. Keep your branch up-to-date with master, otherwise, you can't merge it. If applicable, link the issues closed by this PR. Add a meaningful commit message when merging the PR. For example, you can use the PR description. Be careful with dependent branches/PRs. Otherwise, reviewers might have a hard time getting through the diff. See the next section for more information. Dependent Pull Requests \u00b6 Squashing merge commits is great for having a clean commit history in master. It's sometimes, however, troublesome when dealing with dependent features. The StackOverflow answer Hold on, skip merging explains the preferred workflow in such situations. Release process \u00b6 We follow SemVer versioning. A new release can be created by manually triggering the GitHub Action workflow Create release . You can specify the scope of the release, i.e., major, minor, or patch. The process: creates a release commit creates a git tag adds a changelog entry creates a GitHub Release with the changelog entry pushes a new Docker image adds the corresponding Helm chart to the GitHub release adds the reference to the new Helm chart to the Helm Repository for minor and major releases, creates a new version in the documentation creates a commit with the new dev version Changelog \u00b6 We use the github-changelog-generator to create our changelog automatically. You can find the configuration in the release workflow . We only include closed issues but not pull requests. If a closed issue shouldn't be included, label it as invalid.","title":"Contributing"},{"location":"developer/contributing/#contributing","text":"","title":"Contributing"},{"location":"developer/contributing/#code-quality","text":"The project uses several plugins to ensure code quality. Most of them run during the compilation of the project. Any warnings or errors should be addressed before merging.","title":"Code quality"},{"location":"developer/contributing/#checkstyle","text":"We use Checkstyle to enforce our coding style. The configuration is located in the config/checkstyle/checkstyle.xml . It's based on Google's Java coding style. You can download the Checkstyle Plugin in the IntelliJ Plugin Store. By importing the checkstyle.xml as code style, the reformat action Ctrl + Alt + L works with it. Further, you can run Gradle tasks checkstyleMain and checkstyleTest . These tasks list problems in the shell and create an HTML report located in build/reports/checkstyle/ .","title":"Checkstyle"},{"location":"developer/contributing/#copyright-header","text":"All .java and .kt files should contain a copyright header. IntelliJ can automatically prepend the header for new classes using a copyright profile. To set up the functionality, import config/copyright/quick-license.xml in Settings | Editor | Copyright | CopyrightProfiles . Checkstyle will alert you if the header is missing. To prevent Intellij from putting headers to all other kinds of files, you can create a custom shared scope in Settings | Appearance & Behaviour | Scopes with pattern file:*.java||file:*.kt and associate this with the copyright profile in Settings | Editor | Copyright .","title":"Copyright header"},{"location":"developer/contributing/#error-prone","text":"Error Prone extends the Java Compiler to catch common mistakes. It's enabled by default when compiling with Gradle. Attention Lombok and Error Prone don't work that well together. There might be some false-positives when Lombok is used. If possible, use @SuppressWarning . Otherwise, disable the check completely in the QuickCodeQualityPlugin . Furthermore, Error Prone throws an IndexOutOfBounds exception for the pattern UnusedVariable when a Lombok annotation adds an unused field. That may usually happen with @Sl4j . In such cases, remove the annotation as it isn't used.","title":"Error Prone"},{"location":"developer/contributing/#intellij-setup","text":"To add the plugin, start the IDE and find the Plugins dialog. Browse Repositories, choose Category: Build , and find the Error-prone plugin. Right-click and choose Download and install . The IDE will restart after you\u2019ve exited these dialogs. To enable Error Prone, choose Settings | Compiler | Java Compiler | Use compiler: Javac with error-prone and also make sure Settings | Compiler | Use external build is not selected.","title":"IntelliJ Setup"},{"location":"developer/contributing/#nullaway","text":"NullAway is a tool to help eliminate NullPointerExceptions (NPEs) in your Java code. It's built as a plugin to Error Prone. With NullAway, the compiler assumes that a variable is never null unless there is a @Nullable annotation. Attention @Nullable has its origin in the JSR 305 that has been dormant since 2012. Therefore, using javax.annotation.Nullable is problematic. We chose to use edu.umd.cs.findbugs.annotations.NonNull instead.","title":"NullAway"},{"location":"developer/contributing/#jacoco","text":"We use Jacoco for test coverage. The ReporterPlugin creates the task codeCoverageReport that creates a test report in build/reports/jacoco . There is an HTML report for manual inspection and an XML report that you can export to Sonarqube.","title":"Jacoco"},{"location":"developer/contributing/#sonarqube","text":"There is currently no public Sonarqube project. You can run one locally and set the properties in gradle.properties .","title":"Sonarqube"},{"location":"developer/contributing/#issues","text":"We use GitHub issues to keep track of our tasks. Issues should always have one or more labels .","title":"Issues"},{"location":"developer/contributing/#pull-request-workflow","text":"The master branch is protected, i.e., you can't push directly to it. We use a workflow similar to GitHub Flow , except that we squash Pull Requests (PRs). You start by creating a new local branch, committing the changes, and creating a PR on GitHub. Please don't wait till the end of creating the PR and try to keep it small(ish).","title":"Pull Request Workflow"},{"location":"developer/contributing/#git-branch","text":"The branch should have a meaningful name and roughly follow the scheme TYPE / COMPONENT / TOPIC . For example, when working on a new feature in the manager, feature/mananger/new-feature could be used. You can drop TYPE and/or COMPONENT if they aren't applicable. The name carries some importance because it's used in the CI for tagging the images created for the PR. For example, the branch feature/mananger/new-feature can be deployed with the tag feature-manager-new-feature . it helps find your way in git.","title":"Git Branch"},{"location":"developer/contributing/#pull-request","text":"Some general guidelines regarding Pull Requests: Use a meaningful title (not the default branch name) and add a short description for non-trivial changes. Publish your branch early on, and create a draft PR in case it isn't ready. This allows for early feedback and helps prevent misunderstandings. Keep your branch up-to-date with master, otherwise, you can't merge it. If applicable, link the issues closed by this PR. Add a meaningful commit message when merging the PR. For example, you can use the PR description. Be careful with dependent branches/PRs. Otherwise, reviewers might have a hard time getting through the diff. See the next section for more information.","title":"Pull Request"},{"location":"developer/contributing/#dependent-pull-requests","text":"Squashing merge commits is great for having a clean commit history in master. It's sometimes, however, troublesome when dealing with dependent features. The StackOverflow answer Hold on, skip merging explains the preferred workflow in such situations.","title":"Dependent Pull Requests"},{"location":"developer/contributing/#release-process","text":"We follow SemVer versioning. A new release can be created by manually triggering the GitHub Action workflow Create release . You can specify the scope of the release, i.e., major, minor, or patch. The process: creates a release commit creates a git tag adds a changelog entry creates a GitHub Release with the changelog entry pushes a new Docker image adds the corresponding Helm chart to the GitHub release adds the reference to the new Helm chart to the Helm Repository for minor and major releases, creates a new version in the documentation creates a commit with the new dev version","title":"Release process"},{"location":"developer/contributing/#changelog","text":"We use the github-changelog-generator to create our changelog automatically. You can find the configuration in the release workflow . We only include closed issues but not pull requests. If a closed issue shouldn't be included, label it as invalid.","title":"Changelog"},{"location":"developer/development/","text":"Development \u00b6 Tests \u00b6 We differentiate between unit tests and integration tests in our test suite. The latter has a custom annotation @IntegrationTest that should be used to mark those tests. We don't run them for draft PRs to keep the feedback loop. Build logic \u00b6 We use custom Gradle build logic to orchestrate our builds. It's located in the build-logic directory and referenced by includeBuild(\"build-logic\") in settings.gradle.kts . The build-logic contains Quick's custom Gradle plugins. Quick plugins \u00b6 The convention module configures conventions and plugins that can be applied to a subproject. BasePlugin The BasePlugin is applied to all Quick projects. It configures Java, Compiler Settings, Lombok, and more. QuickJibPlugin The plugin applies Google's Jib plugin and sets the image location. QuickCodeQualityPlugin Plugin that ensures the project's code quality. This includes checkstyle, errorprone, nullaway, and jacoco. See Contributing - Code Quality for detailed information. ReporterPlugin The reporter plugin is applied to the root project. It allows the aggregation of data from subprojects. For example, we use this to collect and merge Jacoco test coverage for the whole project. See Operations - Registry for more information. Gradle version catalog for dependencies \u00b6 Quick uses Gradle's version catalog to define the dependencies. The list of dependencies can be found under the Gradle folder in the libs.version.toml file . OpenAPI \u00b6 The manager API is specified in the openapi directory . We use the OpenAPI generator (Version 4.3.1) to generate our python client . To download the OpenAPI JAR, please visit the OpenAPI installation documentation . java -jar openapi-generator-cli.jar generate \\ -i quick/openapi/spec/Quick-Manager-v1.yaml \\ -g python \\ -o quick-cli/ \\ -p = generateSourceCodeOnly = true,packageName = quick_client \\ --global-property apiTests = false,modelTests = false,modelDocs = false This assumes the following directory structure: quick-project \u251c\u2500\u2500 openapi-generator-cli.jar \u251c\u2500\u2500 quick \u2514\u2500\u2500 quick-cli Documentation \u00b6 The documentation is part of the main repository. It's built with mkdocs-materialize . mkdocs generates static websites from markdown files. You can find all related files in the docs directory. Local development \u00b6 mkdocs is a Python project. You can install all required dependencies with the provided requirements.txt . Run mkdocs serve from the docs directory for local development. Then you can view a live version of the documentation on http://localhost:8000 . mkdocs is configured by the mkdocs.yaml file. The markdown files are in their own docs directory because mkdocs expects the files in a subdirectory. Build \u00b6 We deploy our built documentation to the gh-pages branch. For versioning, we use mike . As suggested by mike , we omit the documentation version's patch. To push a new version, run: mike deploy x.y latest This command also sets x.y as latest . With that, /latest redirects to /x.y . If you update an older release, omit latest , e.g.: mike deploy x.y We also want to redirect / to /latest/ , which redirects to /x.y/ . This was done with: mike set-default latest It creates an index.html in the root, redirecting to /latest/ . Unless the file was deleted, there is no need to run the command above. Note These commands should only be run locally for testing purposes. Therefore, we drop the --push flag here. Deployment \u00b6 As described, mike pushes to the gh-pages branch. GitHub automatically hosts the branch on bakdata.github.io/quick .","title":"Development"},{"location":"developer/development/#development","text":"","title":"Development"},{"location":"developer/development/#tests","text":"We differentiate between unit tests and integration tests in our test suite. The latter has a custom annotation @IntegrationTest that should be used to mark those tests. We don't run them for draft PRs to keep the feedback loop.","title":"Tests"},{"location":"developer/development/#build-logic","text":"We use custom Gradle build logic to orchestrate our builds. It's located in the build-logic directory and referenced by includeBuild(\"build-logic\") in settings.gradle.kts . The build-logic contains Quick's custom Gradle plugins.","title":"Build logic"},{"location":"developer/development/#quick-plugins","text":"The convention module configures conventions and plugins that can be applied to a subproject. BasePlugin The BasePlugin is applied to all Quick projects. It configures Java, Compiler Settings, Lombok, and more. QuickJibPlugin The plugin applies Google's Jib plugin and sets the image location. QuickCodeQualityPlugin Plugin that ensures the project's code quality. This includes checkstyle, errorprone, nullaway, and jacoco. See Contributing - Code Quality for detailed information. ReporterPlugin The reporter plugin is applied to the root project. It allows the aggregation of data from subprojects. For example, we use this to collect and merge Jacoco test coverage for the whole project. See Operations - Registry for more information.","title":"Quick plugins"},{"location":"developer/development/#gradle-version-catalog-for-dependencies","text":"Quick uses Gradle's version catalog to define the dependencies. The list of dependencies can be found under the Gradle folder in the libs.version.toml file .","title":"Gradle version catalog for dependencies"},{"location":"developer/development/#openapi","text":"The manager API is specified in the openapi directory . We use the OpenAPI generator (Version 4.3.1) to generate our python client . To download the OpenAPI JAR, please visit the OpenAPI installation documentation . java -jar openapi-generator-cli.jar generate \\ -i quick/openapi/spec/Quick-Manager-v1.yaml \\ -g python \\ -o quick-cli/ \\ -p = generateSourceCodeOnly = true,packageName = quick_client \\ --global-property apiTests = false,modelTests = false,modelDocs = false This assumes the following directory structure: quick-project \u251c\u2500\u2500 openapi-generator-cli.jar \u251c\u2500\u2500 quick \u2514\u2500\u2500 quick-cli","title":"OpenAPI"},{"location":"developer/development/#documentation","text":"The documentation is part of the main repository. It's built with mkdocs-materialize . mkdocs generates static websites from markdown files. You can find all related files in the docs directory.","title":"Documentation"},{"location":"developer/development/#local-development","text":"mkdocs is a Python project. You can install all required dependencies with the provided requirements.txt . Run mkdocs serve from the docs directory for local development. Then you can view a live version of the documentation on http://localhost:8000 . mkdocs is configured by the mkdocs.yaml file. The markdown files are in their own docs directory because mkdocs expects the files in a subdirectory.","title":"Local development"},{"location":"developer/development/#build","text":"We deploy our built documentation to the gh-pages branch. For versioning, we use mike . As suggested by mike , we omit the documentation version's patch. To push a new version, run: mike deploy x.y latest This command also sets x.y as latest . With that, /latest redirects to /x.y . If you update an older release, omit latest , e.g.: mike deploy x.y We also want to redirect / to /latest/ , which redirects to /x.y/ . This was done with: mike set-default latest It creates an index.html in the root, redirecting to /latest/ . Unless the file was deleted, there is no need to run the command above. Note These commands should only be run locally for testing purposes. Therefore, we drop the --push flag here.","title":"Build"},{"location":"developer/development/#deployment","text":"As described, mike pushes to the gh-pages branch. GitHub automatically hosts the branch on bakdata.github.io/quick .","title":"Deployment"},{"location":"developer/notice/","text":"Dependencies notice \u00b6 All Quick dependencies are published with one of the following licenses: Apache License 2.0 MIT License GNU Lesser GPL 3 Eclipse Public License 2.0 If you add new dependencies, include their license in this list and make sure it complies with the Quick project licensed under the Apache License 2.0. Apache License 2.0 \u00b6 Libraries \u00b6 Apache Avro Apache Kafka, Kafka Streams AssertJ Awaitly Caffeine Confluent schema-registry-client, avro-serde FasterXML Guava JSON2Avro Converter Kafka for JUnit Kubernetes client (fabric8) Log4j Micronaut OkHttp picocli REST Assured RxJava Sundrio Thymeleaf Plugins \u00b6 Error Prone Gradle Checkstyle Gradle Test Logger Jib Spring Dependency Management Tools \u00b6 OpenApi Generator MIT \u00b6 Libraries \u00b6 fluent-kafka-streams-test GraphQL Java Mockito SLF4J streams-bootstrap Plugins \u00b6 Lombok (FreeFair) NullAway Eclipse PL 2.0 \u00b6 Libraries \u00b6 JUnit5 Plugins \u00b6 JaCoCo GNU Lesser GPL 3 \u00b6 Plugins \u00b6 SonarScanner for Gradle","title":"Dependencies notice"},{"location":"developer/notice/#dependencies-notice","text":"All Quick dependencies are published with one of the following licenses: Apache License 2.0 MIT License GNU Lesser GPL 3 Eclipse Public License 2.0 If you add new dependencies, include their license in this list and make sure it complies with the Quick project licensed under the Apache License 2.0.","title":"Dependencies notice"},{"location":"developer/notice/#apache-license-20","text":"","title":"Apache License 2.0"},{"location":"developer/notice/#libraries","text":"Apache Avro Apache Kafka, Kafka Streams AssertJ Awaitly Caffeine Confluent schema-registry-client, avro-serde FasterXML Guava JSON2Avro Converter Kafka for JUnit Kubernetes client (fabric8) Log4j Micronaut OkHttp picocli REST Assured RxJava Sundrio Thymeleaf","title":"Libraries"},{"location":"developer/notice/#plugins","text":"Error Prone Gradle Checkstyle Gradle Test Logger Jib Spring Dependency Management","title":"Plugins"},{"location":"developer/notice/#tools","text":"OpenApi Generator","title":"Tools"},{"location":"developer/notice/#mit","text":"","title":"MIT"},{"location":"developer/notice/#libraries_1","text":"fluent-kafka-streams-test GraphQL Java Mockito SLF4J streams-bootstrap","title":"Libraries"},{"location":"developer/notice/#plugins_1","text":"Lombok (FreeFair) NullAway","title":"Plugins"},{"location":"developer/notice/#eclipse-pl-20","text":"","title":"Eclipse PL 2.0"},{"location":"developer/notice/#libraries_2","text":"JUnit5","title":"Libraries"},{"location":"developer/notice/#plugins_2","text":"JaCoCo","title":"Plugins"},{"location":"developer/notice/#gnu-lesser-gpl-3","text":"","title":"GNU Lesser GPL 3"},{"location":"developer/notice/#plugins_3","text":"SonarScanner for Gradle","title":"Plugins"},{"location":"developer/operations/","text":"Operations \u00b6 Tools \u00b6 A list of tools we use: Gradle kubectl (recommendation: k9s ) Helm Poetry Kubernetes Cluster \u00b6 To deploy Quick, you need access to a Kubernetes cluster. Each Quick deployment should have its namespace. However, the infrastructure deployments (Kafka, Schema Registry and Traefik) can be shared between instances. Container Registry \u00b6 All our images are located in our Docker Hub Registry : quick-mirror quick-manager quick-gateway quick-ingest To configure docker inside the CI, use the secrets DOCKERHUB_USERNAME and DOCKERHUB_TOKEN in a workflow to login: - name: Login to Docker Hub uses: docker/login-action@v1 with: username: ${{ inputs.username }} password: ${{ inputs.token }} Once you have a docker configured, you can tag and push images using jib: ./gradlew -Pversion=<image-tag> jib CI \u00b6 Our CI runs on top of GitHub Actions. You can find the workflows in ./.github/workflows . The main workflow ci.yaml has the following tasks: build & test project push image to registry update Helm chart update documentation For a PR branch, the image tag is the branch name. For the master branch, the image tag is the latest release version incremented by one patch version and a -dev suffix. For example, if the current version is 0.5.3 , pushes an image with the tag 0.6.0-dev . The CI also provides a release workflow. See release process for more information. Helm chart \u00b6 The deployment of Quick in Kubernetes is done with Helm. The chart is part of the main repository and is hosted on our GitHub pages (https://bakdata.github.io/quick).","title":"Operations"},{"location":"developer/operations/#operations","text":"","title":"Operations"},{"location":"developer/operations/#tools","text":"A list of tools we use: Gradle kubectl (recommendation: k9s ) Helm Poetry","title":"Tools"},{"location":"developer/operations/#kubernetes-cluster","text":"To deploy Quick, you need access to a Kubernetes cluster. Each Quick deployment should have its namespace. However, the infrastructure deployments (Kafka, Schema Registry and Traefik) can be shared between instances.","title":"Kubernetes Cluster"},{"location":"developer/operations/#container-registry","text":"All our images are located in our Docker Hub Registry : quick-mirror quick-manager quick-gateway quick-ingest To configure docker inside the CI, use the secrets DOCKERHUB_USERNAME and DOCKERHUB_TOKEN in a workflow to login: - name: Login to Docker Hub uses: docker/login-action@v1 with: username: ${{ inputs.username }} password: ${{ inputs.token }} Once you have a docker configured, you can tag and push images using jib: ./gradlew -Pversion=<image-tag> jib","title":"Container Registry"},{"location":"developer/operations/#ci","text":"Our CI runs on top of GitHub Actions. You can find the workflows in ./.github/workflows . The main workflow ci.yaml has the following tasks: build & test project push image to registry update Helm chart update documentation For a PR branch, the image tag is the branch name. For the master branch, the image tag is the latest release version incremented by one patch version and a -dev suffix. For example, if the current version is 0.5.3 , pushes an image with the tag 0.6.0-dev . The CI also provides a release workflow. See release process for more information.","title":"CI"},{"location":"developer/operations/#helm-chart","text":"The deployment of Quick in Kubernetes is done with Helm. The chart is part of the main repository and is hosted on our GitHub pages (https://bakdata.github.io/quick).","title":"Helm chart"},{"location":"developer/range-query-details/","text":"Range queries details \u00b6 This part of the documentation describes the details of processing range queries. For the introduction of range queries, see: Range queries . This part outlines what happens under the hood when users follow the steps for integrating range queries into their applications (described in the user section). As a reminder, these steps are: Modify your GraphQL schema and define a range in the query. Apply the schema to the gateway. Configure your topic with the range information. Create and execute the range query. Technical Context \u00b6 Before delving into the details of each step, a technical context is provided for arriving at a better understanding of the range queries. Mirrors \u00b6 A corresponding mirror is deployed each time you create a new topic in Quick. A mirror is a Kafka Streams application that reads the content of a topic and exposes it through a key-value REST API. The API is linked with a specific state store. A state store in Kafka can either be a persistent state store (by default RocksDB) or in-memory state store. Regardless of the chosen state store type, their functionality is the same. In any case, it's a key-value store, meaning all keys are unique. Storing different values for the same key is impossible. Consider the following entries that are saved in a topic: key (UserId) value 1 {userId: 1, purchaseId: \"abc\", rating: 2} 1 {userId: 1, purchaseId: \"def\", rating: 4} 2 {userId: 2, purchaseId: \"ghi\", rating: 4} The table indicates that there are two entries for the userId=1 . The second entry is newer, meaning its value is the current one in the store. Suppose you query the store with userId=1 . In that case, you get {userId: 1, purchaseId: \"def\", rating: 4} , and there is no possibility of accessing the earlier value. In subsequent parts of this section, we refer to queries that can only retrieve the latest record as point queries. Similarly, suppose a specific mirror is only capable of supporting such queries. In that case, we say this is a mirror with a point index. Because of the intrinsic nature of state stores, providing a possibility to access previous values (making a range query that encompasses more than one value associated with userId=1 ) demands a change in the key representation. Introducing the possibility of carrying out range queries \u00b6 To circumvent the limitation of a key-value store and be able to perform range queries, Quick uses an alternative approach to deal with keys. Each key is a flattened string with a combination of the topic key and the value for which the range queries are requested. The keys are padded (depending on the type Int 10 digits or Long 19 digits) with zeros to keep the lexicographic order. The general format of the key in the state store is: <zero_paddings><topicKeyValue>_<zero_paddings><rangeFieldValue> . Following the example from the table: If we have a topic with userId as its key and want to create a range over the rating , the key in the state store for the first entry looks like this: 00000000001_00000000002 And for the second: 00000000001_00000000004 Regarding negative values, the minus sign is appended at the beginning of the padded string. For example, consider a user with the negative (for whatever reason) id number userId=-10 and rating=10 . Then, the index looks as follows: -00000000010_00000000010 The flatten-key approach creates unique keys for each user with a given rating. Consequently, all the values will be accessible when running a range query. In later parts of this section, a mirror that can support range queries is called a mirror with a range index. Modify your GraphQL schema and define a range in the query \u00b6 The modification of the schema has no impact until it is applied. Apply the schema to the gateway \u00b6 When you apply a schema that contains the topic directive with the additional fields ( rangeFrom and rangeTo ), a RangeQueryFetcher is created. This class will be later used to deliver a result of a range query to the user. Configure your topic with the range information \u00b6 When you execute the topic create command with the --range-field option, a request is sent to the Manager. The Manager prepares the deployment of a mirror, which contains both Point Index Processor and Range Index Processor . Each time a new value is sent to the topic, both processors are called. The first one creates a new key-value pair if the specified key does not exist. If it does, the value for the given key is overwritten (precisely as described above). If the key exists, but you specify null as the value, the key and the corresponding (previous) value will be deleted from the state store. The second processor creates the range index in the way that was discussed above. Create and execute the range query \u00b6 When you prepare a range query, you provide two additional parameters in the entry point. These attributes define your range. After you have executed the query, it hits the gateway. There, it is processed by the RangeQueryFetcher . RangeQueryFetcher is responsible for extracting the information about the range from the query you passed. Having collected the necessary data (information about the key, the start of the range, and the end of the range), the gateway sends the get request to the mirror and fetches the result.","title":"Range queries details"},{"location":"developer/range-query-details/#range-queries-details","text":"This part of the documentation describes the details of processing range queries. For the introduction of range queries, see: Range queries . This part outlines what happens under the hood when users follow the steps for integrating range queries into their applications (described in the user section). As a reminder, these steps are: Modify your GraphQL schema and define a range in the query. Apply the schema to the gateway. Configure your topic with the range information. Create and execute the range query.","title":"Range queries details"},{"location":"developer/range-query-details/#technical-context","text":"Before delving into the details of each step, a technical context is provided for arriving at a better understanding of the range queries.","title":"Technical Context"},{"location":"developer/range-query-details/#mirrors","text":"A corresponding mirror is deployed each time you create a new topic in Quick. A mirror is a Kafka Streams application that reads the content of a topic and exposes it through a key-value REST API. The API is linked with a specific state store. A state store in Kafka can either be a persistent state store (by default RocksDB) or in-memory state store. Regardless of the chosen state store type, their functionality is the same. In any case, it's a key-value store, meaning all keys are unique. Storing different values for the same key is impossible. Consider the following entries that are saved in a topic: key (UserId) value 1 {userId: 1, purchaseId: \"abc\", rating: 2} 1 {userId: 1, purchaseId: \"def\", rating: 4} 2 {userId: 2, purchaseId: \"ghi\", rating: 4} The table indicates that there are two entries for the userId=1 . The second entry is newer, meaning its value is the current one in the store. Suppose you query the store with userId=1 . In that case, you get {userId: 1, purchaseId: \"def\", rating: 4} , and there is no possibility of accessing the earlier value. In subsequent parts of this section, we refer to queries that can only retrieve the latest record as point queries. Similarly, suppose a specific mirror is only capable of supporting such queries. In that case, we say this is a mirror with a point index. Because of the intrinsic nature of state stores, providing a possibility to access previous values (making a range query that encompasses more than one value associated with userId=1 ) demands a change in the key representation.","title":"Mirrors"},{"location":"developer/range-query-details/#introducing-the-possibility-of-carrying-out-range-queries","text":"To circumvent the limitation of a key-value store and be able to perform range queries, Quick uses an alternative approach to deal with keys. Each key is a flattened string with a combination of the topic key and the value for which the range queries are requested. The keys are padded (depending on the type Int 10 digits or Long 19 digits) with zeros to keep the lexicographic order. The general format of the key in the state store is: <zero_paddings><topicKeyValue>_<zero_paddings><rangeFieldValue> . Following the example from the table: If we have a topic with userId as its key and want to create a range over the rating , the key in the state store for the first entry looks like this: 00000000001_00000000002 And for the second: 00000000001_00000000004 Regarding negative values, the minus sign is appended at the beginning of the padded string. For example, consider a user with the negative (for whatever reason) id number userId=-10 and rating=10 . Then, the index looks as follows: -00000000010_00000000010 The flatten-key approach creates unique keys for each user with a given rating. Consequently, all the values will be accessible when running a range query. In later parts of this section, a mirror that can support range queries is called a mirror with a range index.","title":"Introducing the possibility of carrying out range queries"},{"location":"developer/range-query-details/#modify-your-graphql-schema-and-define-a-range-in-the-query","text":"The modification of the schema has no impact until it is applied.","title":"Modify your GraphQL schema and define a range in the query"},{"location":"developer/range-query-details/#apply-the-schema-to-the-gateway","text":"When you apply a schema that contains the topic directive with the additional fields ( rangeFrom and rangeTo ), a RangeQueryFetcher is created. This class will be later used to deliver a result of a range query to the user.","title":"Apply the schema to the gateway"},{"location":"developer/range-query-details/#configure-your-topic-with-the-range-information","text":"When you execute the topic create command with the --range-field option, a request is sent to the Manager. The Manager prepares the deployment of a mirror, which contains both Point Index Processor and Range Index Processor . Each time a new value is sent to the topic, both processors are called. The first one creates a new key-value pair if the specified key does not exist. If it does, the value for the given key is overwritten (precisely as described above). If the key exists, but you specify null as the value, the key and the corresponding (previous) value will be deleted from the state store. The second processor creates the range index in the way that was discussed above.","title":"Configure your topic with the range information"},{"location":"developer/range-query-details/#create-and-execute-the-range-query","text":"When you prepare a range query, you provide two additional parameters in the entry point. These attributes define your range. After you have executed the query, it hits the gateway. There, it is processed by the RangeQueryFetcher . RangeQueryFetcher is responsible for extracting the information about the range from the query you passed. Having collected the necessary data (information about the key, the start of the range, and the end of the range), the gateway sends the get request to the mirror and fetches the result.","title":"Create and execute the range query"},{"location":"user/","text":"Quick user guide \u00b6 What is Quick? \u00b6 Quick orchestrates your data as a real-time stream of events. It helps you to run and maintain your apps on your data streams and exposes GraphQL APIs connecting the data streams to applications and devices. Quick runs in a Kubernetes cluster and on top of Apache Kafka The manager creates, modifies, and deletes other resources. You interact with it through the CLI . First, you can create topics in Apache Kafka that hold all your data. Quick provides an ingest service with a REST API to get data into your topics. For processing the data, the manager lets you deploy Kafka Streams applications in the cluster. They read data from topics, process it, and write it back to a topic. When you then want to query the data of Apache Kafka topics, you can use the gateway. The gateway is a GraphQL server. You can apply a GraphQL schema to it that describes the data of your topic. With the help of mirrors, the gateway can then efficiently query their content. Next to querying data, it also supports ingesting data through a GraphQL interface. User guide \u00b6 The user guide is split into three parts: Getting Started Examples Reference If you have never worked with Quick, we suggest jumping into the getting started section . It gives an overview of how to set up Quick and its CLI and shows the first steps when working with it. The guide also provides examples showcasing more complex use cases of Quick. The reference describes Quick's different parts in depth.","title":"Quick user guide"},{"location":"user/#quick-user-guide","text":"","title":"Quick user guide"},{"location":"user/#what-is-quick","text":"Quick orchestrates your data as a real-time stream of events. It helps you to run and maintain your apps on your data streams and exposes GraphQL APIs connecting the data streams to applications and devices. Quick runs in a Kubernetes cluster and on top of Apache Kafka The manager creates, modifies, and deletes other resources. You interact with it through the CLI . First, you can create topics in Apache Kafka that hold all your data. Quick provides an ingest service with a REST API to get data into your topics. For processing the data, the manager lets you deploy Kafka Streams applications in the cluster. They read data from topics, process it, and write it back to a topic. When you then want to query the data of Apache Kafka topics, you can use the gateway. The gateway is a GraphQL server. You can apply a GraphQL schema to it that describes the data of your topic. With the help of mirrors, the gateway can then efficiently query their content. Next to querying data, it also supports ingesting data through a GraphQL interface.","title":"What is Quick?"},{"location":"user/#user-guide","text":"The user guide is split into three parts: Getting Started Examples Reference If you have never worked with Quick, we suggest jumping into the getting started section . It gives an overview of how to set up Quick and its CLI and shows the first steps when working with it. The guide also provides examples showcasing more complex use cases of Quick. The reference describes Quick's different parts in depth.","title":"User guide"},{"location":"user/examples/","text":"Examples \u00b6 The examples showcase more complex use cases of Quick. TinyURL is an application for shortening long URLs. This example shows you how to use applications to transform a data stream. It also uses immutable topics to ensure the same key isn't created twice. Real-time monitoring and analytics builds a monitoring system for a car-sharing platform with Quick. Real-time customer profiles combines several features of Quick for user profiles on real-world music listening behaviour. The results of multiple independent apps are managed in a single schema. This includes a recommendation REST-service. The frontend also makes use of graphql subscriptions and mutations.","title":"Examples"},{"location":"user/examples/#examples","text":"The examples showcase more complex use cases of Quick. TinyURL is an application for shortening long URLs. This example shows you how to use applications to transform a data stream. It also uses immutable topics to ensure the same key isn't created twice. Real-time monitoring and analytics builds a monitoring system for a car-sharing platform with Quick. Real-time customer profiles combines several features of Quick for user profiles on real-world music listening behaviour. The results of multiple independent apps are managed in a single schema. This includes a recommendation REST-service. The frontend also makes use of graphql subscriptions and mutations.","title":"Examples"},{"location":"user/examples/TinyURL/","text":"TinyURL \u00b6 TinyURL is an application that shortens any given URL to a tiny one. For instance, shortening URLs is helpful for people posting on Twitter. This example shows a step-by-step guide on how to run your TinyURL application with Quick. What this will demonstrate \u00b6 the use of topics without duplicates the deployment of a simple topology running an analytics app from Docker Hub the creation and setup of a gateway the retrieval of user input (tiny URLs) and analytics results (token lookup count) Prerequisites \u00b6 A running Quick instance. See the Setup Quick section. You should have quick-cli installed and initialized. See the Setup Quick CLI section. Setup and installation \u00b6 Create a new gateway called tiny-url-gateway : quick gateway create tiny-url-gateway Attention When you create a gateway, it might take some time until the gateway is running. Apply the GraphQL schema on the tiny-url-gateway by using the following command: quick gateway apply tiny-url-gateway -f schema.gql The TinyUrl's gateway schema ( schema.gql ) schema.gql type Query { fetchCountOfToken ( token : String ) : TinyUrlCount fetchAll : [ TinyUrl ] @topic ( name : \"tiny-url\" ) } type TinyUrl { token : String ! url : String ! } type TinyUrlCount { tinyUrl : TinyUrl @topic ( name : \"tiny-url\" , keyArgument : \"token\" ) count : Long @topic ( name : \"count-fetch\" , keyArgument : \"token\" ) } Create a new topic called tiny-url . This topic stores the tokens as its key along with the URLs as its value. quick topic create tiny-url --key string --value schema --schema tiny-url-gateway.TinyUrl --immutable Note The --immutable flag. This flag determines that the topic is immutable, so there will be no duplicate keys. We use a simple Kafka streams application that aggregates the keys in the track-fetch topic. In other words, the application counts how many times the users fetch the TinyURLs. You can find the source code of the counter application in our GitHub repository . The diagram below shows the topology of the Kafka streams application. The topology uses a source topic called track-fetch and a sink topic called count-fetch : Create the two topics track-fetch and count-fetch with the following commands: quick topic create track-fetch --key string --value string && quick topic create count-fetch --key string --value long In the last step, you can use Quick to deploy your application: quick app deploy tiny-url-counter \\ --registry bakdata \\ --image quick-demo-tinyurl \\ --tag 1 .0.0 \\ --args input-topics = track-fetch output-topic = count-fetch productive = false Ingest and fetch TinyURLs \u00b6 After successfully setting up the application, topics, and gateway, it's time to create a TinyURL, a URL associated with its token. To do so, you just ingest a key/value (token as the key and URL as the value) in the tiny-url topic: curl --request POST --url \" $QUICK_URL /ingest/tiny-url/\" \\ --header 'content-type: application/json' \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data '@./tiny-urls.json' The TinyUrl's example data ( tiny-urls.json ) tiny-urls.json [ { \"key\" : \"d9p\" , \"value\" : { \"token\" : \"d9p\" , \"url\" : \"https://www.d9p.io\" } }, { \"key\" : \"bak\" , \"value\" : { \"token\" : \"bak\" , \"url\" : \"https://bakdata.com/\" } } ] Now you can simulate the tracking of a user's URL fetch by the URL token. Run the command below: curl --request POST --url \" $QUICK_URL /ingest/track-fetch/\" \\ --header 'content-type: application/json' \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data '{\"key\": \"d9p\", \"value\": \"\"}' Then, the quick-demo-tinyurl app counts how many times the same key was ingested into the topic track-fetch and outputs the number as a value in the output topic count-fetch . Query user inputs \u00b6 You can query the all the ingested TinyUrls using the query below: query { fetchAll { token url } } Query results \u00b6 Imagine users fetched the token d9p URL twice. Query the data and see the results: query { fetchCountOfToken ( token : \"d9p\" ) { tinyUrl { url } count } } The output should be: { \"data\" : { \"fetchCountOfToken\" : { \"url\" : \"https://www.d9p.io\" , \"count\" : 2 } } } Teardown resources \u00b6 To delete all the resources, follow these steps: Delete counter application: quick app delete tiny-url-counter Delete topics: quick topic delete tiny-url && quick topic delete track-fetch && quick topic delete count-fetch Delete gateway: quick gateway delete tiny-url-gateway","title":"TinyURL"},{"location":"user/examples/TinyURL/#tinyurl","text":"TinyURL is an application that shortens any given URL to a tiny one. For instance, shortening URLs is helpful for people posting on Twitter. This example shows a step-by-step guide on how to run your TinyURL application with Quick.","title":"TinyURL"},{"location":"user/examples/TinyURL/#what-this-will-demonstrate","text":"the use of topics without duplicates the deployment of a simple topology running an analytics app from Docker Hub the creation and setup of a gateway the retrieval of user input (tiny URLs) and analytics results (token lookup count)","title":"What this will demonstrate"},{"location":"user/examples/TinyURL/#prerequisites","text":"A running Quick instance. See the Setup Quick section. You should have quick-cli installed and initialized. See the Setup Quick CLI section.","title":"Prerequisites"},{"location":"user/examples/TinyURL/#setup-and-installation","text":"Create a new gateway called tiny-url-gateway : quick gateway create tiny-url-gateway Attention When you create a gateway, it might take some time until the gateway is running. Apply the GraphQL schema on the tiny-url-gateway by using the following command: quick gateway apply tiny-url-gateway -f schema.gql The TinyUrl's gateway schema ( schema.gql ) schema.gql type Query { fetchCountOfToken ( token : String ) : TinyUrlCount fetchAll : [ TinyUrl ] @topic ( name : \"tiny-url\" ) } type TinyUrl { token : String ! url : String ! } type TinyUrlCount { tinyUrl : TinyUrl @topic ( name : \"tiny-url\" , keyArgument : \"token\" ) count : Long @topic ( name : \"count-fetch\" , keyArgument : \"token\" ) } Create a new topic called tiny-url . This topic stores the tokens as its key along with the URLs as its value. quick topic create tiny-url --key string --value schema --schema tiny-url-gateway.TinyUrl --immutable Note The --immutable flag. This flag determines that the topic is immutable, so there will be no duplicate keys. We use a simple Kafka streams application that aggregates the keys in the track-fetch topic. In other words, the application counts how many times the users fetch the TinyURLs. You can find the source code of the counter application in our GitHub repository . The diagram below shows the topology of the Kafka streams application. The topology uses a source topic called track-fetch and a sink topic called count-fetch : Create the two topics track-fetch and count-fetch with the following commands: quick topic create track-fetch --key string --value string && quick topic create count-fetch --key string --value long In the last step, you can use Quick to deploy your application: quick app deploy tiny-url-counter \\ --registry bakdata \\ --image quick-demo-tinyurl \\ --tag 1 .0.0 \\ --args input-topics = track-fetch output-topic = count-fetch productive = false","title":"Setup and installation"},{"location":"user/examples/TinyURL/#ingest-and-fetch-tinyurls","text":"After successfully setting up the application, topics, and gateway, it's time to create a TinyURL, a URL associated with its token. To do so, you just ingest a key/value (token as the key and URL as the value) in the tiny-url topic: curl --request POST --url \" $QUICK_URL /ingest/tiny-url/\" \\ --header 'content-type: application/json' \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data '@./tiny-urls.json' The TinyUrl's example data ( tiny-urls.json ) tiny-urls.json [ { \"key\" : \"d9p\" , \"value\" : { \"token\" : \"d9p\" , \"url\" : \"https://www.d9p.io\" } }, { \"key\" : \"bak\" , \"value\" : { \"token\" : \"bak\" , \"url\" : \"https://bakdata.com/\" } } ] Now you can simulate the tracking of a user's URL fetch by the URL token. Run the command below: curl --request POST --url \" $QUICK_URL /ingest/track-fetch/\" \\ --header 'content-type: application/json' \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data '{\"key\": \"d9p\", \"value\": \"\"}' Then, the quick-demo-tinyurl app counts how many times the same key was ingested into the topic track-fetch and outputs the number as a value in the output topic count-fetch .","title":"Ingest and fetch TinyURLs"},{"location":"user/examples/TinyURL/#query-user-inputs","text":"You can query the all the ingested TinyUrls using the query below: query { fetchAll { token url } }","title":"Query user inputs"},{"location":"user/examples/TinyURL/#query-results","text":"Imagine users fetched the token d9p URL twice. Query the data and see the results: query { fetchCountOfToken ( token : \"d9p\" ) { tinyUrl { url } count } } The output should be: { \"data\" : { \"fetchCountOfToken\" : { \"url\" : \"https://www.d9p.io\" , \"count\" : 2 } } }","title":"Query results"},{"location":"user/examples/TinyURL/#teardown-resources","text":"To delete all the resources, follow these steps: Delete counter application: quick app delete tiny-url-counter Delete topics: quick topic delete tiny-url && quick topic delete track-fetch && quick topic delete count-fetch Delete gateway: quick gateway delete tiny-url-gateway","title":"Teardown resources"},{"location":"user/examples/real-time-customer-profiles/","text":"Real-time customer profiles \u00b6 This example uses Quick to create real-time customer profiles for a music streaming service. These profiles will include user metrics, charts of the most-streamed albums, artists and tracks, and recommendations based on the user's playlist. What this will demonstrate \u00b6 the use of topics, of course analytics on an incoming stream integration of a recommendation service a global GraphQL schema forming the customer profile Visit the demo website to see the example up and running. This visualizes the real-time profiles in a front-end. The code can be found in Quick's example repository . The example uses the real world data set LFM-1b . The Kafka Streams application is written based on our open source streams-bootstrap library . Finally, there is a video explaining this example: Input: Listening events \u00b6 Every time a customer listens to a song, the system emits a listening event containing the ids of album, artist and track. The system additionally attaches metadata such as the timestamp to the event. Later, a Kafka Streams application processes it for the customer profile creation. Exemplary listening events { \"userId\" : 402 , \"artistId\" : 7 , \"albumId\" : 17147 , \"trackId\" : 44975 , \"timestamp\" : 1568052379 } { \"userId\" : 703 , \"artistId\" : 64 , \"albumId\" : 17148 , \"trackId\" : 44982 , \"timestamp\" : 1568052379 } { \"userId\" : 4234 , \"artistId\" : 3744 , \"albumId\" : 34424 , \"trackId\" : 105501 , \"timestamp\" : 1568052382 } { \"userId\" : 2843 , \"artistId\" : 71 , \"albumId\" : 315 , \"trackId\" : 2425 , \"timestamp\" : 1568052383 } { \"userId\" : 1335 , \"artistId\" : 13866 , \"albumId\" : 29007 , \"trackId\" : 83201 , \"timestamp\" : 1568052385 } Quick configuration \u00b6 Global GraphQL schema \u00b6 First, define the global schema with GraphQL. The query called getUserProfile combines six metrics for the customer profile: total listening events the first and last time a user listened to a song charts with user's most listened albums, artists and tracks Quick retrieves all that data from different topics via the @topic directive. Still, the charts contain solely ids and not the names of the corresponding music data. You can let Quick resolve those ids transparently. For that, use the topics (artists, albums, tracks) containing the mapping from ids to names and reference them in the GraphQL schema. The creation of the metrics topics (counts, firstlisten, lastlisten) is described below. The GraphQL user profile schema ( schema-user-profile.gql ) type Query { getUserProfile ( userId : Long ! ) : UserProfile } type UserProfile { totalListenCount : Long ! @topic ( name : \"counts\" , keyArgument : \"userId\" ) firstListenEvent : Long ! @topic ( name : \"firstlisten\" , keyArgument : \"userId\" ) lastListenEvent : Long ! @topic ( name : \"lastlisten\" , keyArgument : \"userId\" ) artistCharts : NamedArtistCharts ! @topic ( name : \"topartists\" , keyArgument : \"userId\" ) albumCharts : NamedAlbumCharts ! @topic ( name : \"topalbums\" , keyArgument : \"userId\" ) trackCharts : NamedTrackCharts ! @topic ( name : \"toptracks\" , keyArgument : \"userId\" ) } type NamedArtistCharts { topK : [ NamedArtistCount !]! } type NamedAlbumCharts { topK : [ NamedAlbumCount !]! } type NamedTrackCharts { topK : [ NamedTrackCount !]! } type Item { id : Long ! name : String ! } type NamedArtistCount { id : Long ! artist : Item ! @topic ( name : \"artists\" , keyField : \"id\" ) countPlays : Long ! } type NamedAlbumCount { id : Long ! album : Item ! @topic ( name : \"albums\" , keyField : \"id\" ) countPlays : Long ! } type NamedTrackCount { id : Long ! track : Item ! @topic ( name : \"tracks\" , keyField : \"id\" ) countPlays : Long ! } ... This is all you need to do to integrate data with Quick. For the Quick setup, please refer to the getting started guide . To avoid redundancy, we only show the setup for integral parts here. You find all steps in the justfile . Gateway \u00b6 Create a new gateway and apply the GraphQL schema. quick gateway create profiles quick gateway apply profiles -f schema-user-profile.gql Topics \u00b6 Then, create the input topics for the artist, album and track data. quick topic create albums --key long --value schema -s profiles.Item quick topic create artists --key long --value schema -s profiles.Item quick topic create tracks --key long --value schema -s profiles.Item quick topic create listeningevents --key long --value schema \\ --schema profiles.ListeningEvent The command expects the topic name and the type or schema of key and value. Since the topics contain complex values, they are referenced via <gateway name>.<type name> . This uses the definition in the global GraphQL schema you previously applied to the gateway. Analytics \u00b6 With gateway and input topics in place, you can now take care of the analytics. Kafka Streams apps will process the data and compute the respective parts of the profiles. Metrics \u00b6 The user profile has the following metrics: first listening event last listening event total number of listening events Create topics that later store the corresponding data: quick topic create firstlisten --key long --value long quick topic create lastlisten --key long --value long quick topic create counts --key long --value long Deploy the applications: quick app deploy firstlisten \\ --registry bakdata \\ --image quick-demo-profile-listenings-activity \\ --tag \"1.0.0\" \\ --args input-topics = listeningevents, output-topic = firstlisten, kind = FIRST, productive = false Quick supports running dockerized applications. You can deploy those applications with the command quick app deploy [...] . For details, call quick app deploy -h or see the reference . The bakdata image registry can be found here . Charts \u00b6 Similar to the metrics, you can add support for a user's charts in the profile. Create the topics: quick topic create topartists --key long \\ --value schema -s profiles.Charts quick topic create topalbums --key long \\ --value schema -s profiles.Charts quick topic create toptracks --key long \\ --value schema -s profiles.Charts Deploy the applications: quick app deploy topartists \\ --registry bakdata \\ --image quick-demo-profile-listenings-charts \\ --tag \"1.0.0\" \\ --args input-topics = listeningevents output-topic = topartists productive = false Recommendations \u00b6 Finally, the recommendations are integrated into the profiles. Therefore, add the getArtistRecommendations query, which is backed by an external service, to the schema. Schema extension with getArtistRecommendations type Query { getArtistRecommendations ( userId : Long ! , field : FieldType ! = ARTIST , limit : Int , walks : Int , walkLength : Int , resetProbability : Float ) : Recommendations @rest ( url : \"http://recommender/recommendation\" , pathParameter : [ \"userId\" , \"field\" ], queryParameter : [ \"limit\" , \"walks\" , \"walkLength\" , \"resetProbability\" ] ) } enum FieldType { ARTIST ALBUM TRACK } type Recommendations { recommendations : [ Recommendation !]! } type Recommendation { id : Long ! artist : Item @topic ( name : \"artists\" , keyField : \"id\" ) } getArtistRecommendations takes several parameters: userId is mandatory: It tells the service for which user it should compute the recommendations. field defines which type of recommendation to create: ARTIST , ALBUM or TRACK is possible. The schema sets it to ARTIST by default. The remaining parameters come from the underlying recommendation algorithm SALSA and have sensible default values. To leverage the external service, you can use the @rest directive. This directive integrates a REST services into your global schema. In this example, the recommendation service returns the result for a particular user id as a list of ids. Quick resolves these ids with the names from the artistis topic in the type recommendation . You can deploy the recommendation service via Quick as well: quick app deploy recommender \\ --registry bakdata \\ --image quick-demo-profile-recommender \\ --tag \"1.0.0\" \\ --port 8080 \\ --args input-topics = listeningevents productive = false Finally, everything is in place to query the artist recommendation. Example query query { getArtistRecommendations ( userId: 32226961 ){ recommendations { id name } } } Example results { \"data\" : { \"getArtistRecommendations\" : { \"recommendations\" : [ { \"id\" : 2041 , \"name\" : \"Leevi and the Leavings\" }, { \"id\" : 1825 , \"name\" : \"Neil Young\" }, { \"id\" : 1871 , \"name\" : \"Mogwai\" }, { \"id\" : 2353 , \"name\" : \"The National\" }, ... ] } } }","title":"Real-time customer profiles"},{"location":"user/examples/real-time-customer-profiles/#real-time-customer-profiles","text":"This example uses Quick to create real-time customer profiles for a music streaming service. These profiles will include user metrics, charts of the most-streamed albums, artists and tracks, and recommendations based on the user's playlist.","title":"Real-time customer profiles"},{"location":"user/examples/real-time-customer-profiles/#what-this-will-demonstrate","text":"the use of topics, of course analytics on an incoming stream integration of a recommendation service a global GraphQL schema forming the customer profile Visit the demo website to see the example up and running. This visualizes the real-time profiles in a front-end. The code can be found in Quick's example repository . The example uses the real world data set LFM-1b . The Kafka Streams application is written based on our open source streams-bootstrap library . Finally, there is a video explaining this example:","title":"What this will demonstrate"},{"location":"user/examples/real-time-customer-profiles/#input-listening-events","text":"Every time a customer listens to a song, the system emits a listening event containing the ids of album, artist and track. The system additionally attaches metadata such as the timestamp to the event. Later, a Kafka Streams application processes it for the customer profile creation. Exemplary listening events { \"userId\" : 402 , \"artistId\" : 7 , \"albumId\" : 17147 , \"trackId\" : 44975 , \"timestamp\" : 1568052379 } { \"userId\" : 703 , \"artistId\" : 64 , \"albumId\" : 17148 , \"trackId\" : 44982 , \"timestamp\" : 1568052379 } { \"userId\" : 4234 , \"artistId\" : 3744 , \"albumId\" : 34424 , \"trackId\" : 105501 , \"timestamp\" : 1568052382 } { \"userId\" : 2843 , \"artistId\" : 71 , \"albumId\" : 315 , \"trackId\" : 2425 , \"timestamp\" : 1568052383 } { \"userId\" : 1335 , \"artistId\" : 13866 , \"albumId\" : 29007 , \"trackId\" : 83201 , \"timestamp\" : 1568052385 }","title":"Input: Listening events"},{"location":"user/examples/real-time-customer-profiles/#quick-configuration","text":"","title":"Quick configuration"},{"location":"user/examples/real-time-customer-profiles/#global-graphql-schema","text":"First, define the global schema with GraphQL. The query called getUserProfile combines six metrics for the customer profile: total listening events the first and last time a user listened to a song charts with user's most listened albums, artists and tracks Quick retrieves all that data from different topics via the @topic directive. Still, the charts contain solely ids and not the names of the corresponding music data. You can let Quick resolve those ids transparently. For that, use the topics (artists, albums, tracks) containing the mapping from ids to names and reference them in the GraphQL schema. The creation of the metrics topics (counts, firstlisten, lastlisten) is described below. The GraphQL user profile schema ( schema-user-profile.gql ) type Query { getUserProfile ( userId : Long ! ) : UserProfile } type UserProfile { totalListenCount : Long ! @topic ( name : \"counts\" , keyArgument : \"userId\" ) firstListenEvent : Long ! @topic ( name : \"firstlisten\" , keyArgument : \"userId\" ) lastListenEvent : Long ! @topic ( name : \"lastlisten\" , keyArgument : \"userId\" ) artistCharts : NamedArtistCharts ! @topic ( name : \"topartists\" , keyArgument : \"userId\" ) albumCharts : NamedAlbumCharts ! @topic ( name : \"topalbums\" , keyArgument : \"userId\" ) trackCharts : NamedTrackCharts ! @topic ( name : \"toptracks\" , keyArgument : \"userId\" ) } type NamedArtistCharts { topK : [ NamedArtistCount !]! } type NamedAlbumCharts { topK : [ NamedAlbumCount !]! } type NamedTrackCharts { topK : [ NamedTrackCount !]! } type Item { id : Long ! name : String ! } type NamedArtistCount { id : Long ! artist : Item ! @topic ( name : \"artists\" , keyField : \"id\" ) countPlays : Long ! } type NamedAlbumCount { id : Long ! album : Item ! @topic ( name : \"albums\" , keyField : \"id\" ) countPlays : Long ! } type NamedTrackCount { id : Long ! track : Item ! @topic ( name : \"tracks\" , keyField : \"id\" ) countPlays : Long ! } ... This is all you need to do to integrate data with Quick. For the Quick setup, please refer to the getting started guide . To avoid redundancy, we only show the setup for integral parts here. You find all steps in the justfile .","title":"Global GraphQL schema"},{"location":"user/examples/real-time-customer-profiles/#gateway","text":"Create a new gateway and apply the GraphQL schema. quick gateway create profiles quick gateway apply profiles -f schema-user-profile.gql","title":"Gateway"},{"location":"user/examples/real-time-customer-profiles/#topics","text":"Then, create the input topics for the artist, album and track data. quick topic create albums --key long --value schema -s profiles.Item quick topic create artists --key long --value schema -s profiles.Item quick topic create tracks --key long --value schema -s profiles.Item quick topic create listeningevents --key long --value schema \\ --schema profiles.ListeningEvent The command expects the topic name and the type or schema of key and value. Since the topics contain complex values, they are referenced via <gateway name>.<type name> . This uses the definition in the global GraphQL schema you previously applied to the gateway.","title":"Topics"},{"location":"user/examples/real-time-customer-profiles/#analytics","text":"With gateway and input topics in place, you can now take care of the analytics. Kafka Streams apps will process the data and compute the respective parts of the profiles.","title":"Analytics"},{"location":"user/examples/real-time-customer-profiles/#metrics","text":"The user profile has the following metrics: first listening event last listening event total number of listening events Create topics that later store the corresponding data: quick topic create firstlisten --key long --value long quick topic create lastlisten --key long --value long quick topic create counts --key long --value long Deploy the applications: quick app deploy firstlisten \\ --registry bakdata \\ --image quick-demo-profile-listenings-activity \\ --tag \"1.0.0\" \\ --args input-topics = listeningevents, output-topic = firstlisten, kind = FIRST, productive = false Quick supports running dockerized applications. You can deploy those applications with the command quick app deploy [...] . For details, call quick app deploy -h or see the reference . The bakdata image registry can be found here .","title":"Metrics"},{"location":"user/examples/real-time-customer-profiles/#charts","text":"Similar to the metrics, you can add support for a user's charts in the profile. Create the topics: quick topic create topartists --key long \\ --value schema -s profiles.Charts quick topic create topalbums --key long \\ --value schema -s profiles.Charts quick topic create toptracks --key long \\ --value schema -s profiles.Charts Deploy the applications: quick app deploy topartists \\ --registry bakdata \\ --image quick-demo-profile-listenings-charts \\ --tag \"1.0.0\" \\ --args input-topics = listeningevents output-topic = topartists productive = false","title":"Charts"},{"location":"user/examples/real-time-customer-profiles/#recommendations","text":"Finally, the recommendations are integrated into the profiles. Therefore, add the getArtistRecommendations query, which is backed by an external service, to the schema. Schema extension with getArtistRecommendations type Query { getArtistRecommendations ( userId : Long ! , field : FieldType ! = ARTIST , limit : Int , walks : Int , walkLength : Int , resetProbability : Float ) : Recommendations @rest ( url : \"http://recommender/recommendation\" , pathParameter : [ \"userId\" , \"field\" ], queryParameter : [ \"limit\" , \"walks\" , \"walkLength\" , \"resetProbability\" ] ) } enum FieldType { ARTIST ALBUM TRACK } type Recommendations { recommendations : [ Recommendation !]! } type Recommendation { id : Long ! artist : Item @topic ( name : \"artists\" , keyField : \"id\" ) } getArtistRecommendations takes several parameters: userId is mandatory: It tells the service for which user it should compute the recommendations. field defines which type of recommendation to create: ARTIST , ALBUM or TRACK is possible. The schema sets it to ARTIST by default. The remaining parameters come from the underlying recommendation algorithm SALSA and have sensible default values. To leverage the external service, you can use the @rest directive. This directive integrates a REST services into your global schema. In this example, the recommendation service returns the result for a particular user id as a list of ids. Quick resolves these ids with the names from the artistis topic in the type recommendation . You can deploy the recommendation service via Quick as well: quick app deploy recommender \\ --registry bakdata \\ --image quick-demo-profile-recommender \\ --tag \"1.0.0\" \\ --port 8080 \\ --args input-topics = listeningevents productive = false Finally, everything is in place to query the artist recommendation. Example query query { getArtistRecommendations ( userId: 32226961 ){ recommendations { id name } } } Example results { \"data\" : { \"getArtistRecommendations\" : { \"recommendations\" : [ { \"id\" : 2041 , \"name\" : \"Leevi and the Leavings\" }, { \"id\" : 1825 , \"name\" : \"Neil Young\" }, { \"id\" : 1871 , \"name\" : \"Mogwai\" }, { \"id\" : 2353 , \"name\" : \"The National\" }, ... ] } } }","title":"Recommendations"},{"location":"user/examples/real-time-monitoring/","text":"Real-time monitoring and analytics \u00b6 This use case demonstrates how Quick can be used to process data streams and consume the results to build live dashboards. For that, we consider the example of a car-sharing company. Their fleet of cars drives around the city. All of them emit statuses that, among others, include the trip's and vehicle's ids as well as the car's current position and battery level. What this will demonstrate \u00b6 aggregations on an incoming stream how to join topic data at query-time subscriptions in action the ingest REST API used by an example producer A dashboard displays this information on an interactive map. Apache Kafka and data processing \u00b6 Quick is based on Apache Kafka. It organizes and stores event streams in topics. In this use-case, a vehicle topic contains the vehicle name and range. A status topic contains the emitted status events (e.g. battery level). Such event streams can be processed with the help of Kafka Streams. For example, an application can accumulate status events with the same trip id into a trip. It simply groups the incoming status events by their trip id and appends them to a list. The result is written into the trip topic. void buildTopology ( StreamsBuilder builder ){ builder . stream ( \"status\" ) . groupBy (( key , status ) -> status . getTripId ()) . aggregate ( Trip :: new , this :: aggregateTrip ) . toStream () . to ( \"trip\" ); } Trip aggregateTrip ( String tripId , Status newStatus , Trip trip ){ List < Status > route = trip . getRoute (); // first time we see this trip id if ( route == null ) { trip . setId ( tripId ); trip . setVehicleId ( newStatus . getVehicleId ()); route = new ArrayList <> (); trip . setRoute ( route ); } route . add ( newStatus ); return trip ; } You can find the full code in our example repository . The Kafka Streams application is written with our streams-bootstrap library , which, among others, offers sensible defaults and reduces the required boilerplate code. GraphQL schema \u00b6 After defining the topics, it is time to model the data required in the dashboard. Quick's querying logic is built upon the data query language GraphQL. It allows you to create a global schema of the data and the supported operations. Subscriptions are one type of such operations, allowing you to consume real-time data updates of the data through WebSocket connections. This is an exemplary GraphQL schema for live updates of the emitted status events. It contains a subscription operation called statusUpdates that delivers live updates of Status events. type Subscription { statusUpdates : Status @topic ( name : \"status\" ) } The status events have the following schema. type Status { statusId : String tripId : String vehicleId : String position : Position batteryLevel : Int distance : Int timestamp : Int } type Position { lat : Float lon : Float } Besides the live updates, single trips should also be accessible. A trip is the accumulation of all statuses with the same trip id. As this information should be queried on demand, subscriptions do not work in this case. GraphQL offers the Query operation instead. The query is called trip and allows to pass an id as an argument and returns the corresponding Trip . type Query { trip ( id : String ) : Trip } type Trip { id : String ! , vehicleId : String ! , route : [ Status ] } Connecting Apache Kafka & GraphQL \u00b6 Quick introduces a custom GraphQL directive called @topic . It allows you to annotate fields and connect them to a topic. With that, you define the relationship between the GraphQL schema and Kafka. First, connect the statusUpdates subscription to the status topic. This ensures that each event written to the Kafka topic is pushed into the GraphQL WebSocket connection. type Subscription { statusUpdates : Status @topic ( name : \"status\" ) } Second, we want to display information about a vehicle when querying a trip. Instead of creating a separate operation, you can add this information to Trip itself: Trip has a new field vehicle . It is populated with the vehicle topic data based on the trip's vehicleId value. One major advantage of GraphQL is its flexibility. When querying a trip, you can decide if you indeed require the vehicle information. If this is not the case, the corresponding data is never loaded, and thus no overhead occurs. However, if the data is needed, Quick transparently joins the vehicle information into the trip. type Query { trip ( id : String ) : Trip @topic ( name : \"trip\" , keyArgument : \"id\" ) } type Trip { id : String ! , vehicleId : String ! , vehicle : Vehicle @topic ( name : \"vehicle\" , keyField : \"vehicleId\" ) route : [ Status ] } type Vehicle { id : String ! , name : String ! , maxRange : Int ! } Quick \u00b6 Now you are ready to process and query the data with Quick. To start a Quick instance, you can refer to the getting started guide . Gateway \u00b6 Create a new gateway and apply the GraphQL schema. Final GraphQL schema ( schema.gql ) type Query { trip(id: String): Trip @topic(name: \"trip\", keyArgument: \"id\") } type Trip { id: String!, vehicleId: String!, vehicle: Vehicle @topic(name: \"vehicle\", keyField: \"vehicleId\") route: [Status] } type Vehicle { id: String!, name: String!, maxRange: Int! } type Subscription { statusUpdates: Status @topic(name: \"status\") } type Status { statusId: String tripId: String vehicleId: String position: Position batteryLevel: Int distance: Int timestamp: Int } type Position { lat: Float lon: Float } quick gateway create car-sharing quick gateway apply car-sharing -f ./schema.gql Topics \u00b6 Next, create all required topics. The command expects the topic name as well as the type or schema of key and value. Since the values are complex, you need to reference the GraphQL types. quick topic create vehicle -k string -v schema --schema car-sharing.Vehicle quick topic create status -k string -v schema --schema car-sharing.Status quick topic create trip -k string -v schema --schema car-sharing.Trip Application \u00b6 Then, start the Kafka Streams application. Quick supports running dockerized applications. quick app deploy trip-aggregator \\ --registry bakdata \\ --image quick-demo-monitoring-trip-aggregator \\ --tag latest \\ --args input-topics = status output-topic = trip For more detailed information, call quick app deploy -h or see the reference . The bakdata image registry can be found here . Go live \u00b6 When all resources are up, you can start to ingest data into the system. For this, checkout the examples git repository . Quick supports the ingest through a REST-API . For example, the following snippet shows a command ingesting new vehicles into the vehicle topic. curl -X POST --url $QUICK_URL /ingest/vehicle \\ --header \"content-type: application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./simulator/data/vehicles.json\" Example data are contained in carsharing/simulator/data . You may also follow the steps described there to create your own dataset. You can now start the simulation by sending data to the status topic. The script requires the environment variables QUICK_URL and QUICK_API_KEY set and the python requirements installed. python -m car_sharing_simulator.simulator With the simulation running, you can use queries and subscriptions. Subscriptions target the url ws://${QUICK_HOST}/gatway/car-sharing/graphql-ws . If you are using Altair, you can follow this setup . subscription { statusUpdates { statusId tripId vehicleId position { lat lon } batteryLevel distance timestamp } } For example, a subscription can yield the following results: statusId tripId vehicleId position.lat position.lon batteryLevel distance timestamp drj02vln8nwvwp5goc 2i8wnx o0338h 13.422029 52.50517 75 24942 1616808550 271m5qzgno3lrh0bn6 blnd1l eikegb 13.293791 52.54985 75 26312 1616808550 02xhrscvc6o0vijyk8 jkehob jis2t3 13.262929 52.54061 86 33972 1616808550 8clm8g1cu50tasdje8 5vfevl uae6rs 13.454952 52.48825 79 50281 1616808550 ru3bcvq4t08rko7n4i vkzhze 2vn7p2 13.424133 52.485806 70 118558 1616808550 h27j9qbpnim6v1l62x x7rsxx xc9bwi 13.411969 52.54107 54 147317 1616808550 k77v3tnu38n14n9unu 6a8t0o bkoi9p 13.505628 52.57557 82 29753 1616808550 f0so763cwocqmronef mikdho 1sjhjr 13.285142 52.49432 41 168217 1616808550 367iyqn9x7xcls7lwv f4ialb 06zmlu 13.351915 52.472813 67 69773 1616808550 kqtlcsiz08cjxjhk3h mdoh37 wu3qia 13.293555 52.536884 45 172664 1616808550 oxi6tmcg9kied6svuc uwz5xq 3q0q0d 13.398802 52.572403 47 102869 1616808550 9rodzbkwqllqqbc3d3 voxul7 v6k3ou 13.444397 52.46356 91 9592 1616808551 ... ... ... ... ... ... ... ... Inspect a single trip using the following query: { trip(id: \"jvae2u\") { id vehicle { name maxRange } route { statusId position { lat lon } statusId distance timestamp } } } Exemplary results { \"data\" : { \"trip\" : { \"id\" : \"jvae2u\" , \"vehicle\" : { \"name\" : \"BMW i3\" , \"maxRange\" : 396 }, \"route\" : [ { \"statusId\" : \"qw05eq3h8ct4x7q2p0\" , \"position\" : { \"lat\" : 13.393371 , \"lon\" : 52.52579 }, \"distance\" : 180625 , \"timestamp\" : \"1616789646\" }, [ ... ], { \"statusId\" : \"oebajab2xrgvdgo30d\" , \"position\" : { \"lat\" : 13.426252 , \"lon\" : 52.534878 }, \"distance\" : 184009 , \"timestamp\" : \"1616790087\" } ] } } }","title":"Real-time monitoring and analytics"},{"location":"user/examples/real-time-monitoring/#real-time-monitoring-and-analytics","text":"This use case demonstrates how Quick can be used to process data streams and consume the results to build live dashboards. For that, we consider the example of a car-sharing company. Their fleet of cars drives around the city. All of them emit statuses that, among others, include the trip's and vehicle's ids as well as the car's current position and battery level.","title":"Real-time monitoring and analytics"},{"location":"user/examples/real-time-monitoring/#what-this-will-demonstrate","text":"aggregations on an incoming stream how to join topic data at query-time subscriptions in action the ingest REST API used by an example producer A dashboard displays this information on an interactive map.","title":"What this will demonstrate"},{"location":"user/examples/real-time-monitoring/#apache-kafka-and-data-processing","text":"Quick is based on Apache Kafka. It organizes and stores event streams in topics. In this use-case, a vehicle topic contains the vehicle name and range. A status topic contains the emitted status events (e.g. battery level). Such event streams can be processed with the help of Kafka Streams. For example, an application can accumulate status events with the same trip id into a trip. It simply groups the incoming status events by their trip id and appends them to a list. The result is written into the trip topic. void buildTopology ( StreamsBuilder builder ){ builder . stream ( \"status\" ) . groupBy (( key , status ) -> status . getTripId ()) . aggregate ( Trip :: new , this :: aggregateTrip ) . toStream () . to ( \"trip\" ); } Trip aggregateTrip ( String tripId , Status newStatus , Trip trip ){ List < Status > route = trip . getRoute (); // first time we see this trip id if ( route == null ) { trip . setId ( tripId ); trip . setVehicleId ( newStatus . getVehicleId ()); route = new ArrayList <> (); trip . setRoute ( route ); } route . add ( newStatus ); return trip ; } You can find the full code in our example repository . The Kafka Streams application is written with our streams-bootstrap library , which, among others, offers sensible defaults and reduces the required boilerplate code.","title":"Apache Kafka and data processing"},{"location":"user/examples/real-time-monitoring/#graphql-schema","text":"After defining the topics, it is time to model the data required in the dashboard. Quick's querying logic is built upon the data query language GraphQL. It allows you to create a global schema of the data and the supported operations. Subscriptions are one type of such operations, allowing you to consume real-time data updates of the data through WebSocket connections. This is an exemplary GraphQL schema for live updates of the emitted status events. It contains a subscription operation called statusUpdates that delivers live updates of Status events. type Subscription { statusUpdates : Status @topic ( name : \"status\" ) } The status events have the following schema. type Status { statusId : String tripId : String vehicleId : String position : Position batteryLevel : Int distance : Int timestamp : Int } type Position { lat : Float lon : Float } Besides the live updates, single trips should also be accessible. A trip is the accumulation of all statuses with the same trip id. As this information should be queried on demand, subscriptions do not work in this case. GraphQL offers the Query operation instead. The query is called trip and allows to pass an id as an argument and returns the corresponding Trip . type Query { trip ( id : String ) : Trip } type Trip { id : String ! , vehicleId : String ! , route : [ Status ] }","title":"GraphQL schema"},{"location":"user/examples/real-time-monitoring/#connecting-apache-kafka-graphql","text":"Quick introduces a custom GraphQL directive called @topic . It allows you to annotate fields and connect them to a topic. With that, you define the relationship between the GraphQL schema and Kafka. First, connect the statusUpdates subscription to the status topic. This ensures that each event written to the Kafka topic is pushed into the GraphQL WebSocket connection. type Subscription { statusUpdates : Status @topic ( name : \"status\" ) } Second, we want to display information about a vehicle when querying a trip. Instead of creating a separate operation, you can add this information to Trip itself: Trip has a new field vehicle . It is populated with the vehicle topic data based on the trip's vehicleId value. One major advantage of GraphQL is its flexibility. When querying a trip, you can decide if you indeed require the vehicle information. If this is not the case, the corresponding data is never loaded, and thus no overhead occurs. However, if the data is needed, Quick transparently joins the vehicle information into the trip. type Query { trip ( id : String ) : Trip @topic ( name : \"trip\" , keyArgument : \"id\" ) } type Trip { id : String ! , vehicleId : String ! , vehicle : Vehicle @topic ( name : \"vehicle\" , keyField : \"vehicleId\" ) route : [ Status ] } type Vehicle { id : String ! , name : String ! , maxRange : Int ! }","title":"Connecting Apache Kafka &amp; GraphQL"},{"location":"user/examples/real-time-monitoring/#quick","text":"Now you are ready to process and query the data with Quick. To start a Quick instance, you can refer to the getting started guide .","title":"Quick"},{"location":"user/examples/real-time-monitoring/#gateway","text":"Create a new gateway and apply the GraphQL schema. Final GraphQL schema ( schema.gql ) type Query { trip(id: String): Trip @topic(name: \"trip\", keyArgument: \"id\") } type Trip { id: String!, vehicleId: String!, vehicle: Vehicle @topic(name: \"vehicle\", keyField: \"vehicleId\") route: [Status] } type Vehicle { id: String!, name: String!, maxRange: Int! } type Subscription { statusUpdates: Status @topic(name: \"status\") } type Status { statusId: String tripId: String vehicleId: String position: Position batteryLevel: Int distance: Int timestamp: Int } type Position { lat: Float lon: Float } quick gateway create car-sharing quick gateway apply car-sharing -f ./schema.gql","title":"Gateway"},{"location":"user/examples/real-time-monitoring/#topics","text":"Next, create all required topics. The command expects the topic name as well as the type or schema of key and value. Since the values are complex, you need to reference the GraphQL types. quick topic create vehicle -k string -v schema --schema car-sharing.Vehicle quick topic create status -k string -v schema --schema car-sharing.Status quick topic create trip -k string -v schema --schema car-sharing.Trip","title":"Topics"},{"location":"user/examples/real-time-monitoring/#application","text":"Then, start the Kafka Streams application. Quick supports running dockerized applications. quick app deploy trip-aggregator \\ --registry bakdata \\ --image quick-demo-monitoring-trip-aggregator \\ --tag latest \\ --args input-topics = status output-topic = trip For more detailed information, call quick app deploy -h or see the reference . The bakdata image registry can be found here .","title":"Application"},{"location":"user/examples/real-time-monitoring/#go-live","text":"When all resources are up, you can start to ingest data into the system. For this, checkout the examples git repository . Quick supports the ingest through a REST-API . For example, the following snippet shows a command ingesting new vehicles into the vehicle topic. curl -X POST --url $QUICK_URL /ingest/vehicle \\ --header \"content-type: application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./simulator/data/vehicles.json\" Example data are contained in carsharing/simulator/data . You may also follow the steps described there to create your own dataset. You can now start the simulation by sending data to the status topic. The script requires the environment variables QUICK_URL and QUICK_API_KEY set and the python requirements installed. python -m car_sharing_simulator.simulator With the simulation running, you can use queries and subscriptions. Subscriptions target the url ws://${QUICK_HOST}/gatway/car-sharing/graphql-ws . If you are using Altair, you can follow this setup . subscription { statusUpdates { statusId tripId vehicleId position { lat lon } batteryLevel distance timestamp } } For example, a subscription can yield the following results: statusId tripId vehicleId position.lat position.lon batteryLevel distance timestamp drj02vln8nwvwp5goc 2i8wnx o0338h 13.422029 52.50517 75 24942 1616808550 271m5qzgno3lrh0bn6 blnd1l eikegb 13.293791 52.54985 75 26312 1616808550 02xhrscvc6o0vijyk8 jkehob jis2t3 13.262929 52.54061 86 33972 1616808550 8clm8g1cu50tasdje8 5vfevl uae6rs 13.454952 52.48825 79 50281 1616808550 ru3bcvq4t08rko7n4i vkzhze 2vn7p2 13.424133 52.485806 70 118558 1616808550 h27j9qbpnim6v1l62x x7rsxx xc9bwi 13.411969 52.54107 54 147317 1616808550 k77v3tnu38n14n9unu 6a8t0o bkoi9p 13.505628 52.57557 82 29753 1616808550 f0so763cwocqmronef mikdho 1sjhjr 13.285142 52.49432 41 168217 1616808550 367iyqn9x7xcls7lwv f4ialb 06zmlu 13.351915 52.472813 67 69773 1616808550 kqtlcsiz08cjxjhk3h mdoh37 wu3qia 13.293555 52.536884 45 172664 1616808550 oxi6tmcg9kied6svuc uwz5xq 3q0q0d 13.398802 52.572403 47 102869 1616808550 9rodzbkwqllqqbc3d3 voxul7 v6k3ou 13.444397 52.46356 91 9592 1616808551 ... ... ... ... ... ... ... ... Inspect a single trip using the following query: { trip(id: \"jvae2u\") { id vehicle { name maxRange } route { statusId position { lat lon } statusId distance timestamp } } } Exemplary results { \"data\" : { \"trip\" : { \"id\" : \"jvae2u\" , \"vehicle\" : { \"name\" : \"BMW i3\" , \"maxRange\" : 396 }, \"route\" : [ { \"statusId\" : \"qw05eq3h8ct4x7q2p0\" , \"position\" : { \"lat\" : 13.393371 , \"lon\" : 52.52579 }, \"distance\" : 180625 , \"timestamp\" : \"1616789646\" }, [ ... ], { \"statusId\" : \"oebajab2xrgvdgo30d\" , \"position\" : { \"lat\" : 13.426252 , \"lon\" : 52.534878 }, \"distance\" : 184009 , \"timestamp\" : \"1616790087\" } ] } } }","title":"Go live"},{"location":"user/getting-started/","text":"Getting started \u00b6 The getting started guide gives you an overview of Quick and how to work with it. In Setup Quick , you learn how to deploy Quick's infrastructure and Quick itself. The guide covers both local and cloud environments. Setup Quick CLI explains the installation process of the main tool for interacting with Quick: the CLI. Working with Quick explains the core concepts of Quick by going through an e-commerce example.","title":"Getting started"},{"location":"user/getting-started/#getting-started","text":"The getting started guide gives you an overview of Quick and how to work with it. In Setup Quick , you learn how to deploy Quick's infrastructure and Quick itself. The guide covers both local and cloud environments. Setup Quick CLI explains the installation process of the main tool for interacting with Quick: the CLI. Working with Quick explains the core concepts of Quick by going through an e-commerce example.","title":"Getting started"},{"location":"user/getting-started/setup-cli/","text":"Setup Quick CLI \u00b6 The main tool for administrating Quick is its CLI . Before you can start to work with Quick, you will have to set it up. Installation \u00b6 The first step is to install the Quick CLI. You can do this via pip. Quick CLI works with Python versions 3.7-3.9: pip install --index-url https://test.pypi.org/simple/ \\ --extra-index-url https://pypi.org/simple/ \\ quick-cli The command quick -v lets you verify that the installation was successful. Context configuration \u00b6 Next, you can configure the Quick cluster's host and API key. The CLI's context command manages this configuration. To create a new context named guide , you can run: quick context create \\ --host \" $QUICK_URL \" \\ --key \" $QUICK_API_KEY \" \\ --context guide You can then activate the context with the following command: quick context activate guide","title":"Setup Quick CLI"},{"location":"user/getting-started/setup-cli/#setup-quick-cli","text":"The main tool for administrating Quick is its CLI . Before you can start to work with Quick, you will have to set it up.","title":"Setup Quick CLI"},{"location":"user/getting-started/setup-cli/#installation","text":"The first step is to install the Quick CLI. You can do this via pip. Quick CLI works with Python versions 3.7-3.9: pip install --index-url https://test.pypi.org/simple/ \\ --extra-index-url https://pypi.org/simple/ \\ quick-cli The command quick -v lets you verify that the installation was successful.","title":"Installation"},{"location":"user/getting-started/setup-cli/#context-configuration","text":"Next, you can configure the Quick cluster's host and API key. The CLI's context command manages this configuration. To create a new context named guide , you can run: quick context create \\ --host \" $QUICK_URL \" \\ --key \" $QUICK_API_KEY \" \\ --context guide You can then activate the context with the following command: quick context activate guide","title":"Context configuration"},{"location":"user/getting-started/setup-quick/","text":"Setup Quick \u00b6 In this part, you will set up a Quick cluster. This includes: optionally creating a local Kubernetes cluster running Apache Kafka and Confluent's Schema Registry deploying Quick Prerequisites \u00b6 k3d (Version 5.3.0+) and Docker (Version >= v20.10.5) or an existing Kubernetes cluster (>= 1.21.0) kubectl (Compatible with server version 1.21.0) Helm (Version 3.8.0+) Setup Kubernetes with k3d \u00b6 If you don't have access to an existing Kubernetes cluster, this section will guide you through creating a local cluster. We recommend the lightweight Kubernetes distribution k3s for this. k3d is a wrapper around k3s in Docker that lets you get started fast. You can install it with k3d's installation script: wget -q -O - https://raw.githubusercontent.com/k3d-io/k3d/v5.3.0/install.sh | bash For other ways of installing k3d, you can have a look at their installation guide . Attention k3s includes Traefik as a load balancer. If you want to use a different Kubernetes distribution, you might have to install Traefik separately. For more information, please refer to the Traefik deployment section. With k3d installed, you can create a new cluster called quick : k3d cluster create quick Note This automatically configures kubectl to connect to the local cluster by modifying your ~/.kube/config . In case you manually set the KUBECONFIG variable or don't want that k3d modifies your config, k3d offers many other options . After the command has run, you can check the cluster status with kubectl get pods -n kube-system . When all returned elements have a STATUS of Running or Completed , you can create a connection to the load balancer. For that, open a new terminal and run: bash/zsh fish export QUICK_PORT = 8000 kubectl port-forward -n kube-system deployment/traefik $QUICK_PORT :8000 set QUICK_PORT 8000 kubectl port-forward -n kube-system deployment/traefik $QUICK_PORT :8000 This terminal session has to remain open to keep the connection alive. Further, you can choose a different port if it's already used. In the following, the guide will use the variables QUICK_HOST and QUICK_URL to refer to the load balancer. Set them like this: bash/zsh fish export QUICK_HOST = \"localhost: $QUICK_PORT \" export QUICK_URL = \"http:// $QUICK_HOST \" set QUICK_HOST \"localhost: $QUICK_PORT \" set QUICK_URL \"http:// $QUICK_HOST \" Traefik (optional) \u00b6 k3s uses Traefik as its load balancer. If you are using k3s as your Kubernetes distribution, you can go directly to the Kafka deployment section. However, if you use another Kubernetes distribution, you can use this guide to deploy Traefik to your Kubernetes cluster. This section provides a step-by-step guide on deploying Traefik to your Kubernetes cluster. Traefik is the Ingress controller Quick needs for load balancing incoming requests. We recommend the official Helm chart to deploy Traefik. Add Traefik Helm repository helm repo add traefik https://helm.traefik.io/traefik && helm repo update Deploy Traefik with Helm helm upgrade --install traefik traefik/traefik \\ --namespace infrastructure Note This guide uses the default values of Traefik's Helm charts for the deployment. For instance, Traefik won't use TLS with this configuration. For more information on how you can enable TLS, please refer to the Traefik documentation . Kafka \u00b6 To deploy Kafka, this guide uses Confluent's Helm Chart. Add Confluent's Helm Chart repository helm repo add confluentinc https://confluentinc.github.io/cp-helm-charts/ && helm repo update Install Kafka, Zookeeper, and the Schema Registry. A single Helm chart installs all three components. Below you can find an example for the --values ./kafka.yaml file configuring the deployment. helm upgrade \\ --install \\ --version 0 .6.1 \\ --values ./kafka.yaml \\ --namespace infrastructure \\ --create-namespace \\ --wait \\ k8kafka confluentinc/cp-helm-charts Kafka Helm Chart Values ( kafka.yaml ) An example value configuration for Confluent's Helm chart. This configuration deploys a single Broker, a Schema Registry and Zookeeper with minimal resources. kafka.yaml cp-zookeeper : enabled : true imageTag : 6.1.1 servers : 1 heapOptions : \"-Xms124M -Xmx124M\" overrideGroupId : k8kafka fullnameOverride : \"k8kafka-cp-zookeeper\" resources : requests : cpu : 50m memory : 0.2G limits : cpu : 250m memory : 0.2G prometheus : jmx : enabled : false cp-kafka : brokers : 1 imageTag : 6.1.1 enabled : true podManagementPolicy : Parallel configurationOverrides : \"auto.create.topics.enable\" : false \"offsets.topic.replication.factor\" : 1 \"transaction.state.log.replication.factor\" : 1 \"transaction.state.log.min.isr\" : 1 resources : requests : cpu : 50m memory : 0.5G limits : cpu : 250m memory : 0.5G prometheus : jmx : enabled : false persistence : enabled : false cp-schema-registry : enabled : true imageTag : 6.1.1 fullnameOverride : \"k8kafka-cp-schema-registry\" overrideGroupId : \"k8kafka\" kafka : bootstrapServers : \"PLAINTEXT://k8kafka-cp-kafka-headless:9092\" resources : requests : cpu : 50m memory : 0.25G limits : cpu : 250m memory : 0.25G prometheus : jmx : enabled : false cp-ksql-server : enabled : false cp-kafka-connect : enabled : false cp-control-center : enabled : false cp-kafka-rest : enabled : false Depending on your system, it can take a couple of minutes before all components are up and running. You can view the status of the created pods by running kubectl get pods -n infrastructure . You should now have Zookeeper, Kafka, and the Schema Registry running in a namespace called infrastructure . In the Kubernetes cluster, you can connect to Kafka with k8kafka-cp-kafka.infrastructure:9092 and the Schema Registry with http://k8kafka-cp-schema-registry.infrastructure:8081 . You are now set to deploy Quick itself. Quick \u00b6 Quick comes with its Helm chart for installing it in Kubernetes clusters. Add the Quick Helm chart repository and update the index: helm repo add quick https://bakdata.github.io/quick && helm repo update Create a random secret key called QUICK_API_KEY : bash/zsh fish export QUICK_API_KEY = \"random-key\" set QUICK_API_KEY \"random-key\" Install Quick with Helm. Below is an example quick.yaml as a configuration for Quick in local clusters. helm upgrade --install quick quick/quick \\ --namespace quick \\ --version 0 .8.0-dev \\ --create-namespace \\ --set apiKey = \" $QUICK_API_KEY \" \\ -f \"./quick.yaml\" Quick Helm Chart Values ( quick.yaml ) An example configuration for local Kubernetes clusters. It lets Quick work with a single Kafka broker and HTTP instead of HTTPS. For more information about Quick's Helm Chart configuration, please see the reference . quick.yaml image : pullPolicy : \"Always\" tag : \"0.8.0-dev\" ingress : ssl : False entrypoint : \"web\" manager : name : \"quick-manager\" replicaCount : 1 ingest : name : \"quick-ingest\" replicaCount : 1 quickConfig : QUICK_DEFAULT_REPLICAS : \"1\" QUICK_KAFKA_BOOTSTRAP_SERVER : k8kafka-cp-kafka.infrastructure:9092 QUICK_KAFKA_INTERNAL_PARTITIONS : \"3\" QUICK_KAFKA_INTERNAL_REPLICATION_FACTOR : \"1\" QUICK_KAFKA_SCHEMA_REGISTRY_URL : http://k8kafka-cp-schema-registry.infrastructure:8081 QUICK_TOPIC_REGISTRY_PARTITIONS : \"3\" QUICK_TOPIC_REGISTRY_REPLICATION_FACTOR : \"1\" QUICK_TOPIC_REGISTRY_SERVICE_NAME : internal-topic-registry QUICK_TOPIC_REGISTRY_TOPIC_NAME : __topic-registry QUICK_SCHEMA_FORMAT : \"Avro\" QUICK_SCHEMA_AVRO_NAMESPACE : \"quick\" You can check the status of Quick by running kubectl get pods -n quick . There should be three running pods: quick-manager , quick-ingest , and internal-topics-registry .","title":"Setup Quick"},{"location":"user/getting-started/setup-quick/#setup-quick","text":"In this part, you will set up a Quick cluster. This includes: optionally creating a local Kubernetes cluster running Apache Kafka and Confluent's Schema Registry deploying Quick","title":"Setup Quick"},{"location":"user/getting-started/setup-quick/#prerequisites","text":"k3d (Version 5.3.0+) and Docker (Version >= v20.10.5) or an existing Kubernetes cluster (>= 1.21.0) kubectl (Compatible with server version 1.21.0) Helm (Version 3.8.0+)","title":"Prerequisites"},{"location":"user/getting-started/setup-quick/#setup-kubernetes-with-k3d","text":"If you don't have access to an existing Kubernetes cluster, this section will guide you through creating a local cluster. We recommend the lightweight Kubernetes distribution k3s for this. k3d is a wrapper around k3s in Docker that lets you get started fast. You can install it with k3d's installation script: wget -q -O - https://raw.githubusercontent.com/k3d-io/k3d/v5.3.0/install.sh | bash For other ways of installing k3d, you can have a look at their installation guide . Attention k3s includes Traefik as a load balancer. If you want to use a different Kubernetes distribution, you might have to install Traefik separately. For more information, please refer to the Traefik deployment section. With k3d installed, you can create a new cluster called quick : k3d cluster create quick Note This automatically configures kubectl to connect to the local cluster by modifying your ~/.kube/config . In case you manually set the KUBECONFIG variable or don't want that k3d modifies your config, k3d offers many other options . After the command has run, you can check the cluster status with kubectl get pods -n kube-system . When all returned elements have a STATUS of Running or Completed , you can create a connection to the load balancer. For that, open a new terminal and run: bash/zsh fish export QUICK_PORT = 8000 kubectl port-forward -n kube-system deployment/traefik $QUICK_PORT :8000 set QUICK_PORT 8000 kubectl port-forward -n kube-system deployment/traefik $QUICK_PORT :8000 This terminal session has to remain open to keep the connection alive. Further, you can choose a different port if it's already used. In the following, the guide will use the variables QUICK_HOST and QUICK_URL to refer to the load balancer. Set them like this: bash/zsh fish export QUICK_HOST = \"localhost: $QUICK_PORT \" export QUICK_URL = \"http:// $QUICK_HOST \" set QUICK_HOST \"localhost: $QUICK_PORT \" set QUICK_URL \"http:// $QUICK_HOST \"","title":"Setup Kubernetes with k3d"},{"location":"user/getting-started/setup-quick/#traefik-optional","text":"k3s uses Traefik as its load balancer. If you are using k3s as your Kubernetes distribution, you can go directly to the Kafka deployment section. However, if you use another Kubernetes distribution, you can use this guide to deploy Traefik to your Kubernetes cluster. This section provides a step-by-step guide on deploying Traefik to your Kubernetes cluster. Traefik is the Ingress controller Quick needs for load balancing incoming requests. We recommend the official Helm chart to deploy Traefik. Add Traefik Helm repository helm repo add traefik https://helm.traefik.io/traefik && helm repo update Deploy Traefik with Helm helm upgrade --install traefik traefik/traefik \\ --namespace infrastructure Note This guide uses the default values of Traefik's Helm charts for the deployment. For instance, Traefik won't use TLS with this configuration. For more information on how you can enable TLS, please refer to the Traefik documentation .","title":"Traefik (optional)"},{"location":"user/getting-started/setup-quick/#kafka","text":"To deploy Kafka, this guide uses Confluent's Helm Chart. Add Confluent's Helm Chart repository helm repo add confluentinc https://confluentinc.github.io/cp-helm-charts/ && helm repo update Install Kafka, Zookeeper, and the Schema Registry. A single Helm chart installs all three components. Below you can find an example for the --values ./kafka.yaml file configuring the deployment. helm upgrade \\ --install \\ --version 0 .6.1 \\ --values ./kafka.yaml \\ --namespace infrastructure \\ --create-namespace \\ --wait \\ k8kafka confluentinc/cp-helm-charts Kafka Helm Chart Values ( kafka.yaml ) An example value configuration for Confluent's Helm chart. This configuration deploys a single Broker, a Schema Registry and Zookeeper with minimal resources. kafka.yaml cp-zookeeper : enabled : true imageTag : 6.1.1 servers : 1 heapOptions : \"-Xms124M -Xmx124M\" overrideGroupId : k8kafka fullnameOverride : \"k8kafka-cp-zookeeper\" resources : requests : cpu : 50m memory : 0.2G limits : cpu : 250m memory : 0.2G prometheus : jmx : enabled : false cp-kafka : brokers : 1 imageTag : 6.1.1 enabled : true podManagementPolicy : Parallel configurationOverrides : \"auto.create.topics.enable\" : false \"offsets.topic.replication.factor\" : 1 \"transaction.state.log.replication.factor\" : 1 \"transaction.state.log.min.isr\" : 1 resources : requests : cpu : 50m memory : 0.5G limits : cpu : 250m memory : 0.5G prometheus : jmx : enabled : false persistence : enabled : false cp-schema-registry : enabled : true imageTag : 6.1.1 fullnameOverride : \"k8kafka-cp-schema-registry\" overrideGroupId : \"k8kafka\" kafka : bootstrapServers : \"PLAINTEXT://k8kafka-cp-kafka-headless:9092\" resources : requests : cpu : 50m memory : 0.25G limits : cpu : 250m memory : 0.25G prometheus : jmx : enabled : false cp-ksql-server : enabled : false cp-kafka-connect : enabled : false cp-control-center : enabled : false cp-kafka-rest : enabled : false Depending on your system, it can take a couple of minutes before all components are up and running. You can view the status of the created pods by running kubectl get pods -n infrastructure . You should now have Zookeeper, Kafka, and the Schema Registry running in a namespace called infrastructure . In the Kubernetes cluster, you can connect to Kafka with k8kafka-cp-kafka.infrastructure:9092 and the Schema Registry with http://k8kafka-cp-schema-registry.infrastructure:8081 . You are now set to deploy Quick itself.","title":"Kafka"},{"location":"user/getting-started/setup-quick/#quick","text":"Quick comes with its Helm chart for installing it in Kubernetes clusters. Add the Quick Helm chart repository and update the index: helm repo add quick https://bakdata.github.io/quick && helm repo update Create a random secret key called QUICK_API_KEY : bash/zsh fish export QUICK_API_KEY = \"random-key\" set QUICK_API_KEY \"random-key\" Install Quick with Helm. Below is an example quick.yaml as a configuration for Quick in local clusters. helm upgrade --install quick quick/quick \\ --namespace quick \\ --version 0 .8.0-dev \\ --create-namespace \\ --set apiKey = \" $QUICK_API_KEY \" \\ -f \"./quick.yaml\" Quick Helm Chart Values ( quick.yaml ) An example configuration for local Kubernetes clusters. It lets Quick work with a single Kafka broker and HTTP instead of HTTPS. For more information about Quick's Helm Chart configuration, please see the reference . quick.yaml image : pullPolicy : \"Always\" tag : \"0.8.0-dev\" ingress : ssl : False entrypoint : \"web\" manager : name : \"quick-manager\" replicaCount : 1 ingest : name : \"quick-ingest\" replicaCount : 1 quickConfig : QUICK_DEFAULT_REPLICAS : \"1\" QUICK_KAFKA_BOOTSTRAP_SERVER : k8kafka-cp-kafka.infrastructure:9092 QUICK_KAFKA_INTERNAL_PARTITIONS : \"3\" QUICK_KAFKA_INTERNAL_REPLICATION_FACTOR : \"1\" QUICK_KAFKA_SCHEMA_REGISTRY_URL : http://k8kafka-cp-schema-registry.infrastructure:8081 QUICK_TOPIC_REGISTRY_PARTITIONS : \"3\" QUICK_TOPIC_REGISTRY_REPLICATION_FACTOR : \"1\" QUICK_TOPIC_REGISTRY_SERVICE_NAME : internal-topic-registry QUICK_TOPIC_REGISTRY_TOPIC_NAME : __topic-registry QUICK_SCHEMA_FORMAT : \"Avro\" QUICK_SCHEMA_AVRO_NAMESPACE : \"quick\" You can check the status of Quick by running kubectl get pods -n quick . There should be three running pods: quick-manager , quick-ingest , and internal-topics-registry .","title":"Quick"},{"location":"user/getting-started/teardown-resources/","text":"Teardown resources \u00b6 This section progresses from single resources to the underlying infrastructure. If you want to delete everything, you can skip deleting single resources. Quick \u00b6 Delete the gateway: quick gateway delete example Delete the topics: quick topic delete purchase quick topic delete product Delete the Helm chart: helm delete quick -n quick Delete the namespace: kubectl delete namespace quick Infrastructure \u00b6 Delete the Helm chart: helm delete k8kafka -n infrastructure Delete the namespace: kubectl delete namespace infrastructure Local Cluster \u00b6 Delete the cluster: k3d cluster delete quick","title":"Teardown resources"},{"location":"user/getting-started/teardown-resources/#teardown-resources","text":"This section progresses from single resources to the underlying infrastructure. If you want to delete everything, you can skip deleting single resources.","title":"Teardown resources"},{"location":"user/getting-started/teardown-resources/#quick","text":"Delete the gateway: quick gateway delete example Delete the topics: quick topic delete purchase quick topic delete product Delete the Helm chart: helm delete quick -n quick Delete the namespace: kubectl delete namespace quick","title":"Quick"},{"location":"user/getting-started/teardown-resources/#infrastructure","text":"Delete the Helm chart: helm delete k8kafka -n infrastructure Delete the namespace: kubectl delete namespace infrastructure","title":"Infrastructure"},{"location":"user/getting-started/teardown-resources/#local-cluster","text":"Delete the cluster: k3d cluster delete quick","title":"Local Cluster"},{"location":"user/getting-started/working-with-quick/","text":"Working with Quick \u00b6 With Quick and Quick CLI installed, you can start working with Quick. This guide looks into different aspects when working with Quick by following an example use case of an e-commerce application: The Gateway is one of Quick's core modules. You start by creating a new gateway, applying a schema, and connecting to the gateway. Topics store events in Quick and let you share data between applications. The guide gives an overview of how you can create and delete topics. The ingest service lets you get data into the platform through a REST API. In Querying data , you connect your gateway and topics. This lets you query the data of topics and create relationships between them. In Range Queries , you can learn how to use range queries, which is a new feature available from version 0.8. It enables you to retrieve values from a given topic according to a specific range of a particular field. The guide closes this section with subscriptions . They let you receive real-time updates from the gateway. Prerequisites \u00b6 A tool for querying GraphQL endpoints. This guide uses gql . You can install it with pip: pip install 'gql[all]==3.1.0' (Optional) jq to pretty-print JSON output. There are many options for installing jq. Please see their download page .","title":"Working with Quick"},{"location":"user/getting-started/working-with-quick/#working-with-quick","text":"With Quick and Quick CLI installed, you can start working with Quick. This guide looks into different aspects when working with Quick by following an example use case of an e-commerce application: The Gateway is one of Quick's core modules. You start by creating a new gateway, applying a schema, and connecting to the gateway. Topics store events in Quick and let you share data between applications. The guide gives an overview of how you can create and delete topics. The ingest service lets you get data into the platform through a REST API. In Querying data , you connect your gateway and topics. This lets you query the data of topics and create relationships between them. In Range Queries , you can learn how to use range queries, which is a new feature available from version 0.8. It enables you to retrieve values from a given topic according to a specific range of a particular field. The guide closes this section with subscriptions . They let you receive real-time updates from the gateway.","title":"Working with Quick"},{"location":"user/getting-started/working-with-quick/#prerequisites","text":"A tool for querying GraphQL endpoints. This guide uses gql . You can install it with pip: pip install 'gql[all]==3.1.0' (Optional) jq to pretty-print JSON output. There are many options for installing jq. Please see their download page .","title":"Prerequisites"},{"location":"user/getting-started/working-with-quick/gateway/","text":"Gateway \u00b6 Creating gateways \u00b6 One of the core parts of Quick is the gateway. As the GraphQL interface, it holds the schema describing your data and lets you query it. The first step when working with gateways is to create a new one: quick gateway create example The example parameter defines the name of your gateway. Since you can have many gateways, you will need the name when applying a new schema or querying data from it. It will take a couple of seconds before the gateway is ready. You can run quick gateway describe example to check the gateway's status. It should output: Name: example Replicas: 1 Tag: 0.8.0-dev The GraphQL schema \u00b6 After the gateway finished starting, you can apply your first schema. This guide uses an e-commerce application as an example. You can start with a basic schema like this: schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase } type Purchase { purchaseId : String ! productId : Int ! userId : Int ! amount : Int price : Price } type Product { productId : Int ! name : String description : String price : Price } type Price { total : Float currency : String } The central type is Purchase , describing a user buying a product. It links the Product type through its field productId and a nested type Price . The Query type is special in GraphQL since it's a root type that functions as an entry point. The schema defines a query field findPurchase , that takes a purchaseId and returns a Purchase . As you may have noticed, some fields have a trailing exclamation mark: Those fields aren't nullable. Attention Every GraphQL schema requires the Query type. The gateway won't parse the schema if you don't specify it. In case you don't need or want one, you can use an empty query: type Query {} . Applying a schema \u00b6 With the GraphQL schema being ready, you can apply it to the created gateway: quick gateway apply example -f schema.gql The example parameter is the name of the newly created gateway that you can reference like this. The -f flag lets you pass the GraphQL schema to the command. Accessing the gateway \u00b6 You can connect to the GraphQL API of the gateway with the address $QUICK_URL/gateway/example/graphql , where example is the name of the gateway you created earlier. The gateway requires the QUICK_API_KEY to be set in the header X-API-Key . You can now use gql to see whether the gateway has the correct schema: gql-cli \" $QUICK_URL /gateway/example/graphql\" \\ -H \"X-API-Key: $QUICK_API_KEY \" \\ --print-schema Among some other types, the schema as defined earlier should be visible.","title":"Gateway"},{"location":"user/getting-started/working-with-quick/gateway/#gateway","text":"","title":"Gateway"},{"location":"user/getting-started/working-with-quick/gateway/#creating-gateways","text":"One of the core parts of Quick is the gateway. As the GraphQL interface, it holds the schema describing your data and lets you query it. The first step when working with gateways is to create a new one: quick gateway create example The example parameter defines the name of your gateway. Since you can have many gateways, you will need the name when applying a new schema or querying data from it. It will take a couple of seconds before the gateway is ready. You can run quick gateway describe example to check the gateway's status. It should output: Name: example Replicas: 1 Tag: 0.8.0-dev","title":"Creating gateways"},{"location":"user/getting-started/working-with-quick/gateway/#the-graphql-schema","text":"After the gateway finished starting, you can apply your first schema. This guide uses an e-commerce application as an example. You can start with a basic schema like this: schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase } type Purchase { purchaseId : String ! productId : Int ! userId : Int ! amount : Int price : Price } type Product { productId : Int ! name : String description : String price : Price } type Price { total : Float currency : String } The central type is Purchase , describing a user buying a product. It links the Product type through its field productId and a nested type Price . The Query type is special in GraphQL since it's a root type that functions as an entry point. The schema defines a query field findPurchase , that takes a purchaseId and returns a Purchase . As you may have noticed, some fields have a trailing exclamation mark: Those fields aren't nullable. Attention Every GraphQL schema requires the Query type. The gateway won't parse the schema if you don't specify it. In case you don't need or want one, you can use an empty query: type Query {} .","title":"The GraphQL schema"},{"location":"user/getting-started/working-with-quick/gateway/#applying-a-schema","text":"With the GraphQL schema being ready, you can apply it to the created gateway: quick gateway apply example -f schema.gql The example parameter is the name of the newly created gateway that you can reference like this. The -f flag lets you pass the GraphQL schema to the command.","title":"Applying a schema"},{"location":"user/getting-started/working-with-quick/gateway/#accessing-the-gateway","text":"You can connect to the GraphQL API of the gateway with the address $QUICK_URL/gateway/example/graphql , where example is the name of the gateway you created earlier. The gateway requires the QUICK_API_KEY to be set in the header X-API-Key . You can now use gql to see whether the gateway has the correct schema: gql-cli \" $QUICK_URL /gateway/example/graphql\" \\ -H \"X-API-Key: $QUICK_API_KEY \" \\ --print-schema Among some other types, the schema as defined earlier should be visible.","title":"Accessing the gateway"},{"location":"user/getting-started/working-with-quick/ingest-data/","text":"Ingest data \u00b6 With the topics created, you can now move data into Quick. For that, Quick offers a REST API. You can find the REST API of the ingest service under $QUICK_URL/ingest . You send a POST request to $QUICK_URL/ingest/product with a JSON list of key-value pairs in the body. As with the gateway, you also have to set the X-API-Key header to QUICK_API_KEY . Using curl, you can create new products like this: curl --request POST --url \" $QUICK_URL /ingest/product\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./products.json\" Here is an example of the products.json file: Example products.json products.json [ { \"key\" : 123 , \"value\" : { \"productId\" : 123 , \"name\" : \"T-Shirt\" , \"description\" : \"black\" , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : 456 , \"value\" : { \"productId\" : 456 , \"name\" : \"Jeans\" , \"description\" : \"Non-stretch denim\" , \"price\" : { \"total\" : 79.99 , \"currency\" : \"EURO\" } } }, { \"key\" : 789 , \"value\" : { \"productId\" : 789 , \"name\" : \"Shoes\" , \"description\" : \"Sneaker\" , \"price\" : { \"total\" : 99.99 , \"currency\" : \"DOLLAR\" } } } ] As explained in topics , Quick enforces data to conform to the defined types. For example, the following product is invalid because the price isn't a complex type: invalid-product.json { \"key\" : 456 , \"value\" : { \"name\" : \"T-Shirt\" , \"description\" : \"black\" , \"price\" : 19.99 } } When you try to ingest it, the ingest service will throw an error: curl --request POST --url \" $QUICK_URL /ingest/product\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./invalid-product.json\" You can now also ingest data for purchases: curl --request POST --url \" $QUICK_URL /ingest/purchase\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./purchases.json\" Use the following example of the purchases.json file as an example: Example purchases.json purchases.json [ { \"key\" : \"abc\" , \"value\" : { \"purchaseId\" : \"abc\" , \"productId\" : 123 , \"userId\" : 1 , \"amount\" : 1 , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : \"def\" , \"value\" : { \"purchaseId\" : \"def\" , \"productId\" : 123 , \"userId\" : 2 , \"amount\" : 2 , \"price\" : { \"total\" : 30.00 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : \"ghi\" , \"value\" : { \"purchaseId\" : \"ghi\" , \"productId\" : 456 , \"userId\" : 2 , \"amount\" : 1 , \"price\" : { \"total\" : 79.99 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : \"jkl\" , \"value\" : { \"purchaseId\" : \"jkl\" , \"productId\" : 789 , \"userId\" : 2 , \"amount\" : 1 , \"price\" : { \"total\" : 99.99 , \"currency\" : \"DOLLAR\" } } } ]","title":"Ingest data"},{"location":"user/getting-started/working-with-quick/ingest-data/#ingest-data","text":"With the topics created, you can now move data into Quick. For that, Quick offers a REST API. You can find the REST API of the ingest service under $QUICK_URL/ingest . You send a POST request to $QUICK_URL/ingest/product with a JSON list of key-value pairs in the body. As with the gateway, you also have to set the X-API-Key header to QUICK_API_KEY . Using curl, you can create new products like this: curl --request POST --url \" $QUICK_URL /ingest/product\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./products.json\" Here is an example of the products.json file: Example products.json products.json [ { \"key\" : 123 , \"value\" : { \"productId\" : 123 , \"name\" : \"T-Shirt\" , \"description\" : \"black\" , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : 456 , \"value\" : { \"productId\" : 456 , \"name\" : \"Jeans\" , \"description\" : \"Non-stretch denim\" , \"price\" : { \"total\" : 79.99 , \"currency\" : \"EURO\" } } }, { \"key\" : 789 , \"value\" : { \"productId\" : 789 , \"name\" : \"Shoes\" , \"description\" : \"Sneaker\" , \"price\" : { \"total\" : 99.99 , \"currency\" : \"DOLLAR\" } } } ] As explained in topics , Quick enforces data to conform to the defined types. For example, the following product is invalid because the price isn't a complex type: invalid-product.json { \"key\" : 456 , \"value\" : { \"name\" : \"T-Shirt\" , \"description\" : \"black\" , \"price\" : 19.99 } } When you try to ingest it, the ingest service will throw an error: curl --request POST --url \" $QUICK_URL /ingest/product\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./invalid-product.json\" You can now also ingest data for purchases: curl --request POST --url \" $QUICK_URL /ingest/purchase\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./purchases.json\" Use the following example of the purchases.json file as an example: Example purchases.json purchases.json [ { \"key\" : \"abc\" , \"value\" : { \"purchaseId\" : \"abc\" , \"productId\" : 123 , \"userId\" : 1 , \"amount\" : 1 , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : \"def\" , \"value\" : { \"purchaseId\" : \"def\" , \"productId\" : 123 , \"userId\" : 2 , \"amount\" : 2 , \"price\" : { \"total\" : 30.00 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : \"ghi\" , \"value\" : { \"purchaseId\" : \"ghi\" , \"productId\" : 456 , \"userId\" : 2 , \"amount\" : 1 , \"price\" : { \"total\" : 79.99 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : \"jkl\" , \"value\" : { \"purchaseId\" : \"jkl\" , \"productId\" : 789 , \"userId\" : 2 , \"amount\" : 1 , \"price\" : { \"total\" : 99.99 , \"currency\" : \"DOLLAR\" } } } ]","title":"Ingest data"},{"location":"user/getting-started/working-with-quick/query-data/","text":"Query data \u00b6 To query your data, you have to tell Quick how to connect your schema with your topics. Quick uses GraphQL directives to represent this information. You can imagine them like annotations and attributes in programming languages: They add meta information to a schema element form which Quick derives extra functionalities. The @topic directive is the most important when working with Quick. It connects elements in your schema to Apache Kafka topics. Query by key \u00b6 In the first step, you connect the Query field findPurchase from the gateway schema to the purchase topic. You can simply change the existing schema : schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) } # The rest of the schema remains unchanged This tells Quick to look up purchases in the purchase topic. The keyArgument defines that it should return the purchase with the key specified by the argument purchaseId . You have to re-apply the schema to update Quick: quick gateway apply example -f schema.gql You can now query the topic. In a GraphQL query, you must select all fields you want to retrieve recursively. This query starts with the findPurchase field and passes an argument for the purchaseId . It then selects the fields of Purchase that the gateway should return, including the nested type Price 's fields. In this example, the query drops the fields purchaseId and userId . find-purchase-query.gql { findPurchase ( purchaseId : \"abc\" ) { productId amount price { total currency } } } You can run the query with gql-cli and optionally pipe it to jq : gql-cli \" $QUICK_URL /gateway/example/graphql\" \\ -H \"X-API-Key: $QUICK_API_KEY \" \\ < find-purchase-query.gql This command should return a JSON object of the data: { \"findPurchase\" : { \"productId\" : 123 , \"amount\" : 1 , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" } } } Query lists \u00b6 Quick also lets you query a list of elements. You can add the following allPurchases field to the query: schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) allPurchases : [ Purchase !] @topic ( name : \"purchase\" ) } # The rest of the schema remains unchanged allPurchases differs from findPurchase in two ways. First, it doesn't have an argument and no keyArgument specified in the @topic directive. Second, it returns [Purchase!] instead of Purchase . The brackets indicate a list of purchases that aren't null because of the exclamation mark. After applying the schema again, you can also query all purchases: all-purchases-query.gql { allPurchases { productId userId } } gql-cli \" $QUICK_URL /gateway/example/graphql\" \\ -H \"X-API-Key: $QUICK_API_KEY \" \\ < all-purchases-query.gql Query connected topics \u00b6 As you may have noticed, there is a relationship between Purchase and Product in that Purchase has a field productId . What if you want to have the information for the product when querying a purchase? Quick supports this also through the @topic directive. schema.gql 1 2 3 4 5 6 7 8 9 10 11 12 # The query remains unchanged type Purchase { purchaseId : String ! productId : Int ! userId : Int ! amount : Int price : Price product : Product @topic ( name : \"product\" , keyField : \"productId\" ) } # The rest of the schema remains unchanged The last line is new: The Purchase now has a new field product of Type Product . The directive uses the keyField argument to define their relationship: The productId holds the value that Quick should resolve through the product topic. With this, you can query a purchase and directly access the related product information: purchase-with-product-query.gql { findPurchase ( purchaseId : \"abc\" ) { amount price { total currency } product { productId name description } } } gql-cli \" $QUICK_URL /gateway/example/graphql\" \\ -H \"X-API-Key: $QUICK_API_KEY \" \\ < purchase-with-product-query.gql This query returns the following data: { \"findPurchase\" : { \"amount\" : 1 , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" }, \"product\" : { \"productId\" : 123 , \"name\" : \"T-Shirt\" , \"description\" : \"black\" } } }","title":"Query data"},{"location":"user/getting-started/working-with-quick/query-data/#query-data","text":"To query your data, you have to tell Quick how to connect your schema with your topics. Quick uses GraphQL directives to represent this information. You can imagine them like annotations and attributes in programming languages: They add meta information to a schema element form which Quick derives extra functionalities. The @topic directive is the most important when working with Quick. It connects elements in your schema to Apache Kafka topics.","title":"Query data"},{"location":"user/getting-started/working-with-quick/query-data/#query-by-key","text":"In the first step, you connect the Query field findPurchase from the gateway schema to the purchase topic. You can simply change the existing schema : schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) } # The rest of the schema remains unchanged This tells Quick to look up purchases in the purchase topic. The keyArgument defines that it should return the purchase with the key specified by the argument purchaseId . You have to re-apply the schema to update Quick: quick gateway apply example -f schema.gql You can now query the topic. In a GraphQL query, you must select all fields you want to retrieve recursively. This query starts with the findPurchase field and passes an argument for the purchaseId . It then selects the fields of Purchase that the gateway should return, including the nested type Price 's fields. In this example, the query drops the fields purchaseId and userId . find-purchase-query.gql { findPurchase ( purchaseId : \"abc\" ) { productId amount price { total currency } } } You can run the query with gql-cli and optionally pipe it to jq : gql-cli \" $QUICK_URL /gateway/example/graphql\" \\ -H \"X-API-Key: $QUICK_API_KEY \" \\ < find-purchase-query.gql This command should return a JSON object of the data: { \"findPurchase\" : { \"productId\" : 123 , \"amount\" : 1 , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" } } }","title":"Query by key"},{"location":"user/getting-started/working-with-quick/query-data/#query-lists","text":"Quick also lets you query a list of elements. You can add the following allPurchases field to the query: schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) allPurchases : [ Purchase !] @topic ( name : \"purchase\" ) } # The rest of the schema remains unchanged allPurchases differs from findPurchase in two ways. First, it doesn't have an argument and no keyArgument specified in the @topic directive. Second, it returns [Purchase!] instead of Purchase . The brackets indicate a list of purchases that aren't null because of the exclamation mark. After applying the schema again, you can also query all purchases: all-purchases-query.gql { allPurchases { productId userId } } gql-cli \" $QUICK_URL /gateway/example/graphql\" \\ -H \"X-API-Key: $QUICK_API_KEY \" \\ < all-purchases-query.gql","title":"Query lists"},{"location":"user/getting-started/working-with-quick/query-data/#query-connected-topics","text":"As you may have noticed, there is a relationship between Purchase and Product in that Purchase has a field productId . What if you want to have the information for the product when querying a purchase? Quick supports this also through the @topic directive. schema.gql 1 2 3 4 5 6 7 8 9 10 11 12 # The query remains unchanged type Purchase { purchaseId : String ! productId : Int ! userId : Int ! amount : Int price : Price product : Product @topic ( name : \"product\" , keyField : \"productId\" ) } # The rest of the schema remains unchanged The last line is new: The Purchase now has a new field product of Type Product . The directive uses the keyField argument to define their relationship: The productId holds the value that Quick should resolve through the product topic. With this, you can query a purchase and directly access the related product information: purchase-with-product-query.gql { findPurchase ( purchaseId : \"abc\" ) { amount price { total currency } product { productId name description } } } gql-cli \" $QUICK_URL /gateway/example/graphql\" \\ -H \"X-API-Key: $QUICK_API_KEY \" \\ < purchase-with-product-query.gql This query returns the following data: { \"findPurchase\" : { \"amount\" : 1 , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" }, \"product\" : { \"productId\" : 123 , \"name\" : \"T-Shirt\" , \"description\" : \"black\" } } }","title":"Query connected topics"},{"location":"user/getting-started/working-with-quick/range-query/","text":"Range queries \u00b6 We now extend the e-commerce example with user ratings. Thus, users can then rank their purchases. This allows the company to find purchases that did not satisfy customers. It could then provide promo codes to the unhappy ones. The company could fetch all purchases and filter them accordingly to find disappointing purchases. However, range queries allow you to specify a specific range of bad ratings (say, from 1 to 4 on a 10-point grading scale) and receive the corresponding records immediately. To integrate range queries into your application, you must take the following steps: Modify your GraphQL schema and define a range in the query. Apply the schema to the gateway. Configure your topic with the range information. Create and execute the range query as defined in step (1). Define a range in the GraphQL query type \u00b6 To introduce range queries, we will extend the previous schema as follows: schema.gql type Query { userRatings ( userId : Int ratingFrom : Int ratingTo : Int ) : [ UserRating ] @topic ( name : \"user-rating-range\" , keyArgument : \"userId\" , rangeFrom : \"ratingFrom\" , rangeTo : \"ratingTo\" ) } type UserRating { userId : Int ! purchaseId : String ! purchase : Purchase @topic ( name : \"purchase\" , keyField : \"purchaseId\" ) rating : Int } Let's start with the new type called UserRating . It describes a numerical rating a given user assigns to a specific purchase previously made (identified by purchaseId ). However, the most notable changes are in the Query type. First, ( userRatings ) has new fields: ratingFrom and ratingTo . Second, the @topic directive has changed: In the query userRatings , you declare the two fields that describe your desired range (here, the rating range). These field values are later assigned to two new parameters of the @topic directive, rangeFrom and rangeTo respectively. In our example, ratingFrom and ratingTo follow the naming scheme field From and field To where field is the field declared in the topic creation command (see later step 3). Following this convention is not mandatory. You can name the parameters that define your range as you wish. However, we think that following this pattern increases readability. When you execute a range query, you receive a list of entries. Therefore, the return type of the query is a list of UserRating . Apply the schema to the gateway \u00b6 Just like before, you need to apply the modified schema to the gateway as follows: quick gateway apply example -f schema.gql Configure your topic with the range information \u00b6 To use range queries, you must set the --range-field parameter when creating the topic. Under the hood, Quick creates additional data structures that enable the execution of range queries. Use the Quick CLI as follows: quick topic create user-rating-range --key int --value schema --schema example.UserRating --range-field rating Note that --range-field links a particular field you can later use for range queries. In our example, the rating field of the UserRating is linked with a range. Tha changes in the Query described above refer to this field you define here with --range-field . --range-field is an optional flag. If you do not specify it, Quick can solely return values for a given key. If you specify it, Quick will return values for a given key and a range of desired values. That is, it executes point queries and range queries. Note the constraints on the values (which you define via the --value option): The value has to be a complex type, i.e., Avro or Proto . The range field type has to be Long or Int . If you are interested in details of the query processing, visit the developer section on ranges . Execute the query \u00b6 Before executing our range query, we need some data ;) You can send purchases and ratings into Quick using the ingest service . If you followed the previous parts of this guide, you should already have data in the purchase topic. If you didn't, please complete the section about ingesting data and add some purchases: The command below sends ratings to the user-rating-range topic. curl --request POST --url \" $QUICK_URL /ingest/user-rating-range\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./ratings.json\" Here is an example of the ratings.json file: Example ratings.json [ { \"key\": 1, \"value\": { \"userId\": 1, \"purchaseId\": \"abc\", \"rating\": 7 } }, { \"key\": 2, \"value\": { \"userId\": 2, \"purchaseId\": \"def\", \"rating\": 2 } }, { \"key\": 2, \"value\": { \"userId\": 2, \"purchaseId\": \"ghi\", \"rating\": 6 } }, { \"key\": 2, \"value\": { \"userId\": 2, \"purchaseId\": \"jkl\", \"rating\": 1 } } ] Let's now find purchases the client with userId=2 was unsatisfied with. Assuming that a disappointing purchase has a rating lower than 5, you can execute the following query to obtain the results. query { userRatings ( userId : 2 , ratingFrom : 1 , ratingTo : 4 ) { userId rating purchase { purchaseId productId price { total currency } } } } Here you go - this is the list of poorly rated purchases. [ { \"userId\" : 2 , \"rating\" : 2 , \"purchase\" : { \"purchaseId\" : \"def\" , \"productId\" : 123 , \"price\" : { \"total\" : 30 , \"currency\" : \"DOLLAR\" } } }, { \"userId\" : 2 , \"rating\" : 4 , \"purchase\" : { \"purchaseId\" : \"jkl\" , \"productId\" : 456 , \"price\" : { \"total\" : 99.99 , \"currency\" : \"DOLLAR\" } } } ] Limitations \u00b6 The following listing describes the limitations of the current range queries implementation: Defining ranges over several fields isn't supported. A range can only be defined on a field whose type is Int or Long . Changing the field associated with a given range index isn't supported.","title":"Range queries"},{"location":"user/getting-started/working-with-quick/range-query/#range-queries","text":"We now extend the e-commerce example with user ratings. Thus, users can then rank their purchases. This allows the company to find purchases that did not satisfy customers. It could then provide promo codes to the unhappy ones. The company could fetch all purchases and filter them accordingly to find disappointing purchases. However, range queries allow you to specify a specific range of bad ratings (say, from 1 to 4 on a 10-point grading scale) and receive the corresponding records immediately. To integrate range queries into your application, you must take the following steps: Modify your GraphQL schema and define a range in the query. Apply the schema to the gateway. Configure your topic with the range information. Create and execute the range query as defined in step (1).","title":"Range queries"},{"location":"user/getting-started/working-with-quick/range-query/#define-a-range-in-the-graphql-query-type","text":"To introduce range queries, we will extend the previous schema as follows: schema.gql type Query { userRatings ( userId : Int ratingFrom : Int ratingTo : Int ) : [ UserRating ] @topic ( name : \"user-rating-range\" , keyArgument : \"userId\" , rangeFrom : \"ratingFrom\" , rangeTo : \"ratingTo\" ) } type UserRating { userId : Int ! purchaseId : String ! purchase : Purchase @topic ( name : \"purchase\" , keyField : \"purchaseId\" ) rating : Int } Let's start with the new type called UserRating . It describes a numerical rating a given user assigns to a specific purchase previously made (identified by purchaseId ). However, the most notable changes are in the Query type. First, ( userRatings ) has new fields: ratingFrom and ratingTo . Second, the @topic directive has changed: In the query userRatings , you declare the two fields that describe your desired range (here, the rating range). These field values are later assigned to two new parameters of the @topic directive, rangeFrom and rangeTo respectively. In our example, ratingFrom and ratingTo follow the naming scheme field From and field To where field is the field declared in the topic creation command (see later step 3). Following this convention is not mandatory. You can name the parameters that define your range as you wish. However, we think that following this pattern increases readability. When you execute a range query, you receive a list of entries. Therefore, the return type of the query is a list of UserRating .","title":"Define a range in the GraphQL query type"},{"location":"user/getting-started/working-with-quick/range-query/#apply-the-schema-to-the-gateway","text":"Just like before, you need to apply the modified schema to the gateway as follows: quick gateway apply example -f schema.gql","title":"Apply the schema to the gateway"},{"location":"user/getting-started/working-with-quick/range-query/#configure-your-topic-with-the-range-information","text":"To use range queries, you must set the --range-field parameter when creating the topic. Under the hood, Quick creates additional data structures that enable the execution of range queries. Use the Quick CLI as follows: quick topic create user-rating-range --key int --value schema --schema example.UserRating --range-field rating Note that --range-field links a particular field you can later use for range queries. In our example, the rating field of the UserRating is linked with a range. Tha changes in the Query described above refer to this field you define here with --range-field . --range-field is an optional flag. If you do not specify it, Quick can solely return values for a given key. If you specify it, Quick will return values for a given key and a range of desired values. That is, it executes point queries and range queries. Note the constraints on the values (which you define via the --value option): The value has to be a complex type, i.e., Avro or Proto . The range field type has to be Long or Int . If you are interested in details of the query processing, visit the developer section on ranges .","title":"Configure your topic with the range information"},{"location":"user/getting-started/working-with-quick/range-query/#execute-the-query","text":"Before executing our range query, we need some data ;) You can send purchases and ratings into Quick using the ingest service . If you followed the previous parts of this guide, you should already have data in the purchase topic. If you didn't, please complete the section about ingesting data and add some purchases: The command below sends ratings to the user-rating-range topic. curl --request POST --url \" $QUICK_URL /ingest/user-rating-range\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./ratings.json\" Here is an example of the ratings.json file: Example ratings.json [ { \"key\": 1, \"value\": { \"userId\": 1, \"purchaseId\": \"abc\", \"rating\": 7 } }, { \"key\": 2, \"value\": { \"userId\": 2, \"purchaseId\": \"def\", \"rating\": 2 } }, { \"key\": 2, \"value\": { \"userId\": 2, \"purchaseId\": \"ghi\", \"rating\": 6 } }, { \"key\": 2, \"value\": { \"userId\": 2, \"purchaseId\": \"jkl\", \"rating\": 1 } } ] Let's now find purchases the client with userId=2 was unsatisfied with. Assuming that a disappointing purchase has a rating lower than 5, you can execute the following query to obtain the results. query { userRatings ( userId : 2 , ratingFrom : 1 , ratingTo : 4 ) { userId rating purchase { purchaseId productId price { total currency } } } } Here you go - this is the list of poorly rated purchases. [ { \"userId\" : 2 , \"rating\" : 2 , \"purchase\" : { \"purchaseId\" : \"def\" , \"productId\" : 123 , \"price\" : { \"total\" : 30 , \"currency\" : \"DOLLAR\" } } }, { \"userId\" : 2 , \"rating\" : 4 , \"purchase\" : { \"purchaseId\" : \"jkl\" , \"productId\" : 456 , \"price\" : { \"total\" : 99.99 , \"currency\" : \"DOLLAR\" } } } ]","title":"Execute the query"},{"location":"user/getting-started/working-with-quick/range-query/#limitations","text":"The following listing describes the limitations of the current range queries implementation: Defining ranges over several fields isn't supported. A range can only be defined on a field whose type is Int or Long . Changing the field associated with a given range index isn't supported.","title":"Limitations"},{"location":"user/getting-started/working-with-quick/subscriptions/","text":"Subscriptions \u00b6 In Query data you have learned to use the @topic directive to query data. This section explains how to get real-time updates of your data. Extending the schema \u00b6 Like the Query type, the Subscription type works as an entry point for GraphQL. To create a new subscription, you follow the same approach as with adding a new query: You add a field to the corresponding type. In the example schema , this can look like this: schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) allPurchases : [ Purchase !] @topic ( name : \"purchase\" ) } type Subscription { purchases : Purchase @topic ( name : \"purchase\" ) } type Purchase { purchaseId : String ! productId : Int ! userId : Int ! product : Product @topic ( name : \"product\" , keyField : \"productId\" ) amount : Int price : Price } type Product { productId : Int ! name : String description : String price : Price } type Price { total : Float currency : String } Don't forget to re-apply the schema to update Quick: quick gateway apply example -f schema.gql Compared to the latest version of the schema , this schema now has a new type, Subscription . The field purchases creates a new subscription. Whenever Quick receives a new element in the purchase topic, it emits an event. Note, however, that compared to the query fields, the field neither takes a key argument nor returns a list of purchases. This is because the stream contains purchases with any key, but only one at a time. It's also possible to include a key argument in a subscription. Quick then filters the stream, and you only receive updates for the given key. Altair Setup \u00b6 The gql-cli doesn't support authentication for subscriptions. We, therefore, recommend using Altair . After you have installed it, you need to set it up. Note that Altair doesn't have access to the variables; therefore, you must replace them with the appropriate values. In the field Enter URL , enter $QUICK_URL/gateway/example/graphql In the left menu, click on \"Set Headers\" and add a new header with key X-API-Key and the value of $QUICK_API_KEY In the left menu, click on \"Subscription URL\" Set the URL to ws://$QUICK_HOST/gateway/example/graphql-ws . Note that the URL uses ws as protocol and has -ws suffix. Set the connection parameters (where $QUICK_API_KEY is your key) { \"X-API-Key\" : \"$QUICK_API_KEY\" } Running the subscription \u00b6 To subscribe to the purchase events, you can run the following query in Altair: subscription.gql subscription { purchases { product { name description } amount price { total currency } } } You can press the Run subscription button to start the subscription. You can now ingest new data into the purchase topic and will receive them in your subscription. You can test this by using the purchases.json from the ingest data section . For example, ingest the following purchase: subscription-purchase.json { \"key\" : \"aj\" , \"value\" : { \"purchaseId\" : \"aj\" , \"productId\" : 123 , \"userId\" : 2 , \"amount\" : 2 , \"price\" : { \"total\" : 29.99 , \"currency\" : \"DOLLAR\" } } } curl --request POST --url \" $QUICK_URL /ingest/purchase\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./subscription-purchase.json\" The subscription should emit the following event: { \"data\" : { \"purchases\" : { \"product\" : { \"name\" : \"T-Shirt\" , \"description\" : \"black\" }, \"amount\" : 2 , \"price\" : { \"total\" : 29.99 , \"currency\" : \"DOLLAR\" } } } } Again, you can see that Quick automatically extends the data with the product information.","title":"Subscriptions"},{"location":"user/getting-started/working-with-quick/subscriptions/#subscriptions","text":"In Query data you have learned to use the @topic directive to query data. This section explains how to get real-time updates of your data.","title":"Subscriptions"},{"location":"user/getting-started/working-with-quick/subscriptions/#extending-the-schema","text":"Like the Query type, the Subscription type works as an entry point for GraphQL. To create a new subscription, you follow the same approach as with adding a new query: You add a field to the corresponding type. In the example schema , this can look like this: schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) allPurchases : [ Purchase !] @topic ( name : \"purchase\" ) } type Subscription { purchases : Purchase @topic ( name : \"purchase\" ) } type Purchase { purchaseId : String ! productId : Int ! userId : Int ! product : Product @topic ( name : \"product\" , keyField : \"productId\" ) amount : Int price : Price } type Product { productId : Int ! name : String description : String price : Price } type Price { total : Float currency : String } Don't forget to re-apply the schema to update Quick: quick gateway apply example -f schema.gql Compared to the latest version of the schema , this schema now has a new type, Subscription . The field purchases creates a new subscription. Whenever Quick receives a new element in the purchase topic, it emits an event. Note, however, that compared to the query fields, the field neither takes a key argument nor returns a list of purchases. This is because the stream contains purchases with any key, but only one at a time. It's also possible to include a key argument in a subscription. Quick then filters the stream, and you only receive updates for the given key.","title":"Extending the schema"},{"location":"user/getting-started/working-with-quick/subscriptions/#altair-setup","text":"The gql-cli doesn't support authentication for subscriptions. We, therefore, recommend using Altair . After you have installed it, you need to set it up. Note that Altair doesn't have access to the variables; therefore, you must replace them with the appropriate values. In the field Enter URL , enter $QUICK_URL/gateway/example/graphql In the left menu, click on \"Set Headers\" and add a new header with key X-API-Key and the value of $QUICK_API_KEY In the left menu, click on \"Subscription URL\" Set the URL to ws://$QUICK_HOST/gateway/example/graphql-ws . Note that the URL uses ws as protocol and has -ws suffix. Set the connection parameters (where $QUICK_API_KEY is your key) { \"X-API-Key\" : \"$QUICK_API_KEY\" }","title":"Altair Setup"},{"location":"user/getting-started/working-with-quick/subscriptions/#running-the-subscription","text":"To subscribe to the purchase events, you can run the following query in Altair: subscription.gql subscription { purchases { product { name description } amount price { total currency } } } You can press the Run subscription button to start the subscription. You can now ingest new data into the purchase topic and will receive them in your subscription. You can test this by using the purchases.json from the ingest data section . For example, ingest the following purchase: subscription-purchase.json { \"key\" : \"aj\" , \"value\" : { \"purchaseId\" : \"aj\" , \"productId\" : 123 , \"userId\" : 2 , \"amount\" : 2 , \"price\" : { \"total\" : 29.99 , \"currency\" : \"DOLLAR\" } } } curl --request POST --url \" $QUICK_URL /ingest/purchase\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./subscription-purchase.json\" The subscription should emit the following event: { \"data\" : { \"purchases\" : { \"product\" : { \"name\" : \"T-Shirt\" , \"description\" : \"black\" }, \"amount\" : 2 , \"price\" : { \"total\" : 29.99 , \"currency\" : \"DOLLAR\" } } } } Again, you can see that Quick automatically extends the data with the product information.","title":"Running the subscription"},{"location":"user/getting-started/working-with-quick/topics/","text":"Topics \u00b6 With the initial schema applied to the gateway, you can create new topics. Because they're responsible for storing all data in Apache Kafka, topics are a fundamental part of Quick. Creating new topics \u00b6 Recalling the schema from the previous section, there are two types of data: Purchase and Product . The application should be able to store the data of both types. Therefore, the next step is to create the corresponding topics. First, you create the topic for Purchase by running: quick topic create purchase \\ --key-type string --value-type schema --schema example.Purchase The first parameter is purchase , the topic's name you create. The key-type and value-type options define the key and value types, respectively. Quick ensures that data ingested into this topic conforms to these types. If you'd try to ingest data with a number as the key into the purchase topic, Quick throws an error. Next to primitives types like string , Quick also supports complex types defined by schema . When using the schema option, you have to tell Quick what this schema should look like. You can do this by referencing a type of GraphQL schema applied to a gateway. In this case, you want first to reference the gateway, here called example . In example , the Purchase type corresponds to the data in this topic. Therefore, the --schema option is example.Purchase . You can now also create the product topic and a price topic: quick topic create product --key-type long --value-type schema --schema example.Product && quick topic create price --key-type long --value-type schema --schema example.Price In contrast to the purchase topic, this topic has a key type long . Topic information \u00b6 The Quick CLI comes with commands to view the current state of topics in Quick. First, you can take a look at existing topics: quick topic list Next, you can also view more detailed information about a topic: quick topic describe purchase This command returns the types and schema of the topic. Deleting topics \u00b6 You can also delete topics. For example, the price topic is no longer needed, and you want to remove it: quick topic delete price","title":"Topics"},{"location":"user/getting-started/working-with-quick/topics/#topics","text":"With the initial schema applied to the gateway, you can create new topics. Because they're responsible for storing all data in Apache Kafka, topics are a fundamental part of Quick.","title":"Topics"},{"location":"user/getting-started/working-with-quick/topics/#creating-new-topics","text":"Recalling the schema from the previous section, there are two types of data: Purchase and Product . The application should be able to store the data of both types. Therefore, the next step is to create the corresponding topics. First, you create the topic for Purchase by running: quick topic create purchase \\ --key-type string --value-type schema --schema example.Purchase The first parameter is purchase , the topic's name you create. The key-type and value-type options define the key and value types, respectively. Quick ensures that data ingested into this topic conforms to these types. If you'd try to ingest data with a number as the key into the purchase topic, Quick throws an error. Next to primitives types like string , Quick also supports complex types defined by schema . When using the schema option, you have to tell Quick what this schema should look like. You can do this by referencing a type of GraphQL schema applied to a gateway. In this case, you want first to reference the gateway, here called example . In example , the Purchase type corresponds to the data in this topic. Therefore, the --schema option is example.Purchase . You can now also create the product topic and a price topic: quick topic create product --key-type long --value-type schema --schema example.Product && quick topic create price --key-type long --value-type schema --schema example.Price In contrast to the purchase topic, this topic has a key type long .","title":"Creating new topics"},{"location":"user/getting-started/working-with-quick/topics/#topic-information","text":"The Quick CLI comes with commands to view the current state of topics in Quick. First, you can take a look at existing topics: quick topic list Next, you can also view more detailed information about a topic: quick topic describe purchase This command returns the types and schema of the topic.","title":"Topic information"},{"location":"user/getting-started/working-with-quick/topics/#deleting-topics","text":"You can also delete topics. For example, the price topic is no longer needed, and you want to remove it: quick topic delete price","title":"Deleting topics"},{"location":"user/reference/breaking-changes/","text":"Breaking changes \u00b6 0.7 \u00b6 Avro configuration \u00b6 The configuration QUICK_AVRO_NAMESPACE is now called QUICK_SCHEMA_AVRO_NAMESPACE . avro.namespace was removed from the Helm chart. Instead, use QUICK_SCHEMA_AVRO_NAMESPACE in quickConfig .","title":"Breaking changes"},{"location":"user/reference/breaking-changes/#breaking-changes","text":"","title":"Breaking changes"},{"location":"user/reference/breaking-changes/#07","text":"","title":"0.7"},{"location":"user/reference/breaking-changes/#avro-configuration","text":"The configuration QUICK_AVRO_NAMESPACE is now called QUICK_SCHEMA_AVRO_NAMESPACE . avro.namespace was removed from the Helm chart. Instead, use QUICK_SCHEMA_AVRO_NAMESPACE in quickConfig .","title":"Avro configuration"},{"location":"user/reference/cli-commands/","text":"Quick CLI \u00b6 Commands \u00b6 quick \u00b6 Control your Quick deployment Usage: quick [-h] command [options ...] ... Available commands: context : Manage quick configuration topic : Manage topics gateway : Manage gateways mirror : Manage mirrors app : Manage streams applications quick context \u00b6 Manage quick configuration Usage: quick context [-h] command [options ...] ... Available commands: create : Create a new context describe : Display a context configuration list : List all context configurations activate : Activate context quick context create \u00b6 Create a new context Usage: quick context create [-h] [--host HOST] [--key API-KEY] [--context CONTEXT] [--debug] Optional: --host : Name of the host (prompted if not given) --key : API key of this quick instance (prompted if not given) --context : Name of the context (defaults to host) --debug : Enable debug output quick context describe \u00b6 Display a context configuration Usage: quick context describe [-h] [--context CONTEXT] [--debug] Optional: --context : Select context (defaults to current one) --debug : Enable debug output quick context list \u00b6 List all context configurations Usage: quick context list [-h] [--debug] Optional: --debug : Enable debug output quick context activate \u00b6 Activate context Usage: quick context activate [-h] [--debug] NAME Required: name : Name of the context to activate Optional: --debug : Enable debug output quick topic \u00b6 Manage topics Usage: quick topic [-h] command [options ...] ... Available commands: create : Create a new topic delete : Delete a topic list : List all topics describe : Display information for a topic quick topic create \u00b6 Create a new topic Usage: quick topic create [-h] -k TYPE -v TYPE [-s SCHEMA] [--immutable] [--retention-time RETENTION_TIME] [--range-field RANGE_FIELD] [--context CONTEXT] [--debug] NAME Required: name : The name of the topic -k, --key-type : The key type of the topic -v, --value-type : The value type of the topic Optional: -s, --schema : The location of the schema file or std in --immutable : An immutable topic does not allow ingesting the same key twice (default: False) --retention-time : Retention time of data in the topic in (if not given, the data is kept indefinitely) --range-field : The field name, which the range index should be built on --context : Context of quick --debug : Enable debug output quick topic delete \u00b6 Delete a topic Usage: quick topic delete [-h] [--context CONTEXT] [--debug] TOPIC Required: topic : Topic to delete Optional: --context : Context of quick --debug : Enable debug output quick topic list \u00b6 List all topics Usage: quick topic list [-h] [--context CONTEXT] [--debug] Optional: --context : Context of quick --debug : Enable debug output quick topic describe \u00b6 Display information for a topic Usage: quick topic describe [-h] [--context CONTEXT] [--debug] NAME Required: name : The name of the topic. Optional: --context : Context of quick --debug : Enable debug output quick gateway \u00b6 Manage gateways Usage: quick gateway [-h] command [options ...] ... Available commands: create : Create a gateway delete : Delete a gateway apply : Apply a new schema to a gateway list : List all gateways describe : Display information about a gateway quick gateway create \u00b6 Create a gateway Usage: quick gateway create [-h] [--replicas REPLICAS] [--tag TAG] [--context CONTEXT] [--debug] NAME Required: gateway_name : Name of the gateway Optional: --replicas : Number of replicas --tag : Docker image tag (defaults to currently installed tag) --context : Context of quick --debug : Enable debug output quick gateway delete \u00b6 Delete a gateway Usage: quick gateway delete [-h] [--context CONTEXT] [--debug] NAME Required: gateway_name : Name of the gateway Optional: --context : Context of quick --debug : Enable debug output quick gateway apply \u00b6 Apply a new schema to a gateway Usage: quick gateway apply [-h] -f FILE [--context CONTEXT] [--debug] NAME Required: gateway : Name of the gateway -f, --file : Location of the schema file or std in Optional: --context : Context of quick --debug : Enable debug output quick gateway list \u00b6 List all gateways Usage: quick gateway list [-h] [--context CONTEXT] [--debug] Optional: --context : Context of quick --debug : Enable debug output quick gateway describe \u00b6 Display information about a gateway Usage: quick gateway describe [-h] [--context CONTEXT] [--debug] NAME Required: name : The name of the gateway. Optional: --context : Context of quick --debug : Enable debug output quick mirror \u00b6 Mirrors make topics queryable. With these commands, you can control which topic can be queried through gateway. Usage: quick mirror [-h] command [options ...] ... Available commands: create : Mirror a Kafka topic delete : Delete a mirror quick mirror create \u00b6 Create a mirror for a topic and make it queryable through a gateway Usage: quick mirror create [-h] [--tag TAG] [--replicas REPLICAS] [--range-field RANGE_FIELD] [--context CONTEXT] [--debug] TOPIC Required: topic : Topic to mirror Optional: --tag : Docker image tag (defaults to currently installed tag) --replicas : Number of replicas (default: 1) --range-field : The field name, which the range index should be built on --context : Context of quick --debug : Enable debug output quick mirror delete \u00b6 Delete a mirror Usage: quick mirror delete [-h] [--context CONTEXT] [--debug] TOPIC Required: mirror : Topic to delete mirror from Optional: --context : Context of quick --debug : Enable debug output quick app \u00b6 Streams applications are Kafka Streams applications processing your data stream. You can deploy them to the quick cluster. Usage: quick app [-h] command [options ...] ... Available commands: deploy : Deploy a new application delete : Delete an application quick app deploy \u00b6 Deploy a new application. The application must be provided as a Docker image. You can specify the registry. Usage: quick app deploy [-h] --registry REGISTRY_URL --image IMAGE --tag TAG [--image-pull-secret IMAGE_PULL_SECRET] [--replicas REPLICAS] [--args [ARG=VALUE ...]] [--port PORT] [--context CONTEXT] [--debug] NAME Required: name : Name of the application (must be unique) --registry : URL to container registry --image : Name of the image --tag : Docker image tag Optional: --image-pull-secret : A secret in a string format for pulling an image from a private registry --replicas : Number of replicas --args : CLI arguments of the application (broker and schema registry not required) --port : The container port of the application --context : Context of quick --debug : Enable debug output quick app delete \u00b6 Delete an application. This stops the running Streams application and removes all its state. Usage: quick app delete [-h] [--context CONTEXT] [--debug] name Required: name : Name of the application Optional: --context : Context of quick --debug : Enable debug output","title":"Quick CLI"},{"location":"user/reference/cli-commands/#quick-cli","text":"","title":"Quick CLI"},{"location":"user/reference/cli-commands/#commands","text":"","title":"Commands"},{"location":"user/reference/cli-commands/#quick","text":"Control your Quick deployment Usage: quick [-h] command [options ...] ... Available commands: context : Manage quick configuration topic : Manage topics gateway : Manage gateways mirror : Manage mirrors app : Manage streams applications","title":"quick"},{"location":"user/reference/cli-commands/#quick-context","text":"Manage quick configuration Usage: quick context [-h] command [options ...] ... Available commands: create : Create a new context describe : Display a context configuration list : List all context configurations activate : Activate context","title":"quick context"},{"location":"user/reference/cli-commands/#quick-context-create","text":"Create a new context Usage: quick context create [-h] [--host HOST] [--key API-KEY] [--context CONTEXT] [--debug] Optional: --host : Name of the host (prompted if not given) --key : API key of this quick instance (prompted if not given) --context : Name of the context (defaults to host) --debug : Enable debug output","title":"quick context create"},{"location":"user/reference/cli-commands/#quick-context-describe","text":"Display a context configuration Usage: quick context describe [-h] [--context CONTEXT] [--debug] Optional: --context : Select context (defaults to current one) --debug : Enable debug output","title":"quick context describe"},{"location":"user/reference/cli-commands/#quick-context-list","text":"List all context configurations Usage: quick context list [-h] [--debug] Optional: --debug : Enable debug output","title":"quick context list"},{"location":"user/reference/cli-commands/#quick-context-activate","text":"Activate context Usage: quick context activate [-h] [--debug] NAME Required: name : Name of the context to activate Optional: --debug : Enable debug output","title":"quick context activate"},{"location":"user/reference/cli-commands/#quick-topic","text":"Manage topics Usage: quick topic [-h] command [options ...] ... Available commands: create : Create a new topic delete : Delete a topic list : List all topics describe : Display information for a topic","title":"quick topic"},{"location":"user/reference/cli-commands/#quick-topic-create","text":"Create a new topic Usage: quick topic create [-h] -k TYPE -v TYPE [-s SCHEMA] [--immutable] [--retention-time RETENTION_TIME] [--range-field RANGE_FIELD] [--context CONTEXT] [--debug] NAME Required: name : The name of the topic -k, --key-type : The key type of the topic -v, --value-type : The value type of the topic Optional: -s, --schema : The location of the schema file or std in --immutable : An immutable topic does not allow ingesting the same key twice (default: False) --retention-time : Retention time of data in the topic in (if not given, the data is kept indefinitely) --range-field : The field name, which the range index should be built on --context : Context of quick --debug : Enable debug output","title":"quick topic create"},{"location":"user/reference/cli-commands/#quick-topic-delete","text":"Delete a topic Usage: quick topic delete [-h] [--context CONTEXT] [--debug] TOPIC Required: topic : Topic to delete Optional: --context : Context of quick --debug : Enable debug output","title":"quick topic delete"},{"location":"user/reference/cli-commands/#quick-topic-list","text":"List all topics Usage: quick topic list [-h] [--context CONTEXT] [--debug] Optional: --context : Context of quick --debug : Enable debug output","title":"quick topic list"},{"location":"user/reference/cli-commands/#quick-topic-describe","text":"Display information for a topic Usage: quick topic describe [-h] [--context CONTEXT] [--debug] NAME Required: name : The name of the topic. Optional: --context : Context of quick --debug : Enable debug output","title":"quick topic describe"},{"location":"user/reference/cli-commands/#quick-gateway","text":"Manage gateways Usage: quick gateway [-h] command [options ...] ... Available commands: create : Create a gateway delete : Delete a gateway apply : Apply a new schema to a gateway list : List all gateways describe : Display information about a gateway","title":"quick gateway"},{"location":"user/reference/cli-commands/#quick-gateway-create","text":"Create a gateway Usage: quick gateway create [-h] [--replicas REPLICAS] [--tag TAG] [--context CONTEXT] [--debug] NAME Required: gateway_name : Name of the gateway Optional: --replicas : Number of replicas --tag : Docker image tag (defaults to currently installed tag) --context : Context of quick --debug : Enable debug output","title":"quick gateway create"},{"location":"user/reference/cli-commands/#quick-gateway-delete","text":"Delete a gateway Usage: quick gateway delete [-h] [--context CONTEXT] [--debug] NAME Required: gateway_name : Name of the gateway Optional: --context : Context of quick --debug : Enable debug output","title":"quick gateway delete"},{"location":"user/reference/cli-commands/#quick-gateway-apply","text":"Apply a new schema to a gateway Usage: quick gateway apply [-h] -f FILE [--context CONTEXT] [--debug] NAME Required: gateway : Name of the gateway -f, --file : Location of the schema file or std in Optional: --context : Context of quick --debug : Enable debug output","title":"quick gateway apply"},{"location":"user/reference/cli-commands/#quick-gateway-list","text":"List all gateways Usage: quick gateway list [-h] [--context CONTEXT] [--debug] Optional: --context : Context of quick --debug : Enable debug output","title":"quick gateway list"},{"location":"user/reference/cli-commands/#quick-gateway-describe","text":"Display information about a gateway Usage: quick gateway describe [-h] [--context CONTEXT] [--debug] NAME Required: name : The name of the gateway. Optional: --context : Context of quick --debug : Enable debug output","title":"quick gateway describe"},{"location":"user/reference/cli-commands/#quick-mirror","text":"Mirrors make topics queryable. With these commands, you can control which topic can be queried through gateway. Usage: quick mirror [-h] command [options ...] ... Available commands: create : Mirror a Kafka topic delete : Delete a mirror","title":"quick mirror"},{"location":"user/reference/cli-commands/#quick-mirror-create","text":"Create a mirror for a topic and make it queryable through a gateway Usage: quick mirror create [-h] [--tag TAG] [--replicas REPLICAS] [--range-field RANGE_FIELD] [--context CONTEXT] [--debug] TOPIC Required: topic : Topic to mirror Optional: --tag : Docker image tag (defaults to currently installed tag) --replicas : Number of replicas (default: 1) --range-field : The field name, which the range index should be built on --context : Context of quick --debug : Enable debug output","title":"quick mirror create"},{"location":"user/reference/cli-commands/#quick-mirror-delete","text":"Delete a mirror Usage: quick mirror delete [-h] [--context CONTEXT] [--debug] TOPIC Required: mirror : Topic to delete mirror from Optional: --context : Context of quick --debug : Enable debug output","title":"quick mirror delete"},{"location":"user/reference/cli-commands/#quick-app","text":"Streams applications are Kafka Streams applications processing your data stream. You can deploy them to the quick cluster. Usage: quick app [-h] command [options ...] ... Available commands: deploy : Deploy a new application delete : Delete an application","title":"quick app"},{"location":"user/reference/cli-commands/#quick-app-deploy","text":"Deploy a new application. The application must be provided as a Docker image. You can specify the registry. Usage: quick app deploy [-h] --registry REGISTRY_URL --image IMAGE --tag TAG [--image-pull-secret IMAGE_PULL_SECRET] [--replicas REPLICAS] [--args [ARG=VALUE ...]] [--port PORT] [--context CONTEXT] [--debug] NAME Required: name : Name of the application (must be unique) --registry : URL to container registry --image : Name of the image --tag : Docker image tag Optional: --image-pull-secret : A secret in a string format for pulling an image from a private registry --replicas : Number of replicas --args : CLI arguments of the application (broker and schema registry not required) --port : The container port of the application --context : Context of quick --debug : Enable debug output","title":"quick app deploy"},{"location":"user/reference/cli-commands/#quick-app-delete","text":"Delete an application. This stops the running Streams application and removes all its state. Usage: quick app delete [-h] [--context CONTEXT] [--debug] name Required: name : Name of the application Optional: --context : Context of quick --debug : Enable debug output","title":"quick app delete"},{"location":"user/reference/configuration/","text":"Quick configuration \u00b6 Kafka \u00b6 Environment Variable Required Description QUICK_KAFKA_BOOTSTRAP_SERVER Kafka address to connect to QUICK_KAFKA_SCHEMA_REGISTRY_URL Schema Registry URL to connect to QUICK_KAFKA_APPLICATION_ID Application id to use QUICK_KAFKA_INTERNAL_PARITITIONS Number of partitions new topics are created with QUICK_KAFKA_INTERNAL_REPLICATION_FACTOR Replication factor of Kafka topics Mirror \u00b6 Environment Variable Required Description QUICK_MIRROR_PREFIX Prefix of Kubernetes deployments for mirror deployments Schema \u00b6 Environment Variable Required Description QUICK_SCHEMA_FORMAT Schema format Quick should use. Valid values: Avro (default), Protobuf QUICK_SCHEMA_AVRO_NAMESPACE (if format is Avro) Namespace for Avro schemas generated by Quick from GraphQL QUICK_SCHEMA_PROTOBUF_PACKAGE (if format is Protobuf) Package name for Protobuf schemas generated by Quick from GraphQL Topic Registry \u00b6 Environment Variable Required Description QUICK_TOPIC_REGISTRY_TOPIC_NAME Topic backing the topic registry QUICK_TOPIC_REGISTRY_SERVICE_NAME Service name of the topic registry QUICK_TOPIC_REGISTRY_PARTITIONS Partition count of the topic backing the topic registry QUICK_TOPIC_REGISTRY_REPLICATION_FACTOR Replication factor of the topic backing the topic registry Deployment \u00b6 Environment Variable Required Description QUICK_DOCKER_REGISTRY Docker registry for use Quick images QUICK_DEFAULT_IMAGE_TAG Default image tag of Quick images to deploy QUICK_DEFAULT_REPLICAS Default amount of replicas for Quick deployments QUICK_INGRESS_HOST Host for Kubernetes Ingress objects for gateways QUICK_INGRESS_SSL Flag indicating whether the ingress should use SSL QUICK_INGRESS_ENTRYPOINT Traefik's entrypoint for ingress QUICK_MANAGER_UPDATE_MANAGED_IMAGES Flag indicating whether the manager should ensure deployments have the same image tag QUICK_MANAGER_CREATE_TOPIC_REGISTRY Flag if manager should deploy a topic registry Applications Specification \u00b6 Environment Variable Required Description QUICK_APPLICATIONS_SPEC_IMAGE_PULL_POLICY Image pull policy of the deployed applications by Quick. Valid values: Always (default), IfNotPresent, Never QUICK_APPLICATIONS_SPEC_RESOURCES_MEMORY_LIMIT Memory limit for deployments QUICK_APPLICATIONS_SPEC_RESOURCES_MEMORY_REQUEST Memory request for deployments QUICK_APPLICATIONS_SPEC_RESOURCES_CPU_LIMIT Cpu limit for deployments QUICK_APPLICATIONS_SPEC_RESOURCES_CPU_REQUEST Cpu requests for deployments Gateway \u00b6 Environment Variable Required Description QUICK_SCHEMA_PATH The path where the schema file is located","title":"Quick configuration"},{"location":"user/reference/configuration/#quick-configuration","text":"","title":"Quick configuration"},{"location":"user/reference/configuration/#kafka","text":"Environment Variable Required Description QUICK_KAFKA_BOOTSTRAP_SERVER Kafka address to connect to QUICK_KAFKA_SCHEMA_REGISTRY_URL Schema Registry URL to connect to QUICK_KAFKA_APPLICATION_ID Application id to use QUICK_KAFKA_INTERNAL_PARITITIONS Number of partitions new topics are created with QUICK_KAFKA_INTERNAL_REPLICATION_FACTOR Replication factor of Kafka topics","title":"Kafka"},{"location":"user/reference/configuration/#mirror","text":"Environment Variable Required Description QUICK_MIRROR_PREFIX Prefix of Kubernetes deployments for mirror deployments","title":"Mirror"},{"location":"user/reference/configuration/#schema","text":"Environment Variable Required Description QUICK_SCHEMA_FORMAT Schema format Quick should use. Valid values: Avro (default), Protobuf QUICK_SCHEMA_AVRO_NAMESPACE (if format is Avro) Namespace for Avro schemas generated by Quick from GraphQL QUICK_SCHEMA_PROTOBUF_PACKAGE (if format is Protobuf) Package name for Protobuf schemas generated by Quick from GraphQL","title":"Schema"},{"location":"user/reference/configuration/#topic-registry","text":"Environment Variable Required Description QUICK_TOPIC_REGISTRY_TOPIC_NAME Topic backing the topic registry QUICK_TOPIC_REGISTRY_SERVICE_NAME Service name of the topic registry QUICK_TOPIC_REGISTRY_PARTITIONS Partition count of the topic backing the topic registry QUICK_TOPIC_REGISTRY_REPLICATION_FACTOR Replication factor of the topic backing the topic registry","title":"Topic Registry"},{"location":"user/reference/configuration/#deployment","text":"Environment Variable Required Description QUICK_DOCKER_REGISTRY Docker registry for use Quick images QUICK_DEFAULT_IMAGE_TAG Default image tag of Quick images to deploy QUICK_DEFAULT_REPLICAS Default amount of replicas for Quick deployments QUICK_INGRESS_HOST Host for Kubernetes Ingress objects for gateways QUICK_INGRESS_SSL Flag indicating whether the ingress should use SSL QUICK_INGRESS_ENTRYPOINT Traefik's entrypoint for ingress QUICK_MANAGER_UPDATE_MANAGED_IMAGES Flag indicating whether the manager should ensure deployments have the same image tag QUICK_MANAGER_CREATE_TOPIC_REGISTRY Flag if manager should deploy a topic registry","title":"Deployment"},{"location":"user/reference/configuration/#applications-specification","text":"Environment Variable Required Description QUICK_APPLICATIONS_SPEC_IMAGE_PULL_POLICY Image pull policy of the deployed applications by Quick. Valid values: Always (default), IfNotPresent, Never QUICK_APPLICATIONS_SPEC_RESOURCES_MEMORY_LIMIT Memory limit for deployments QUICK_APPLICATIONS_SPEC_RESOURCES_MEMORY_REQUEST Memory request for deployments QUICK_APPLICATIONS_SPEC_RESOURCES_CPU_LIMIT Cpu limit for deployments QUICK_APPLICATIONS_SPEC_RESOURCES_CPU_REQUEST Cpu requests for deployments","title":"Applications Specification"},{"location":"user/reference/configuration/#gateway","text":"Environment Variable Required Description QUICK_SCHEMA_PATH The path where the schema file is located","title":"Gateway"},{"location":"user/reference/dependency-versions/","text":"Dependency versions \u00b6 Component Version Quick 0.8.0-dev Kubernetes 1.22 Kafka 2.7 - 3.2 Schema Registry 6.1 - 7.2 Traefik 2.4 - 2.8.4 Quick CLI 0.8.0-dev Python (Quick CLI) 3.7-3.9","title":"Dependency versions"},{"location":"user/reference/dependency-versions/#dependency-versions","text":"Component Version Quick 0.8.0-dev Kubernetes 1.22 Kafka 2.7 - 3.2 Schema Registry 6.1 - 7.2 Traefik 2.4 - 2.8.4 Quick CLI 0.8.0-dev Python (Quick CLI) 3.7-3.9","title":"Dependency versions"},{"location":"user/reference/graphql-support/","text":"GraphQL support \u00b6 This section provides information about the supported and unsupported GraphQL types in Quick. Furthermore, it describes the GraphQL extensions that are introduced in Quick. GraphQL supported types \u00b6 Currently, Quick supports the following GraphQL types: The mandatory Query type, The optional Mutation type and the corresponding Input type, Basic Types with field declarations as well as type modifiers, for example: type Character { name:String!, appearsIn: [Episode!] } , All scalar types: Int , String , Float , Boolean , ID together with field's arguments, for example: total(moreThan: Int = 50): Float , Enumerations ( enum ), Subscriptions ( subscription ). Thus, the following types are not supported: Interfaces ( interface ), Unions ( union ), Custom scalars, for example: scalar MyCustomScalar . GraphQL extensions \u00b6 Enums \u00b6 RestDirectiveMethod \u00b6 enum RestDirectiveMethod { GET , POST } Directives \u00b6 @topic \u00b6 directive @topic( name: String! , # Name of the topic. keyArgument: String , # The argument which contains the key. This also supports arguments from parents. keyField: String # The field which contains the key. This can be used when the key is part of a different mirror. rangeFrom: Int # The lower bound (inclusive) of a range over a specific field. rangeTo: Int # The upper bound (exclusive) of the range over the given field (the same as above). ) on FIELD_DEFINITION @rest \u00b6 directive @rest( url: String! # url of the rest service pathParameter: [String!] # list of the arguments that should be included in the list queryParameter: [String!] # list of arguments that should be included as query parameter in the form of `argumentName=value` bodyParameter: String # argument which represents a body. This cannot be a scalar httpMethod: RestDirectiveMethod = GET # The HTTP method used when calling the rest service ) on FIELD_DEFINITION","title":"GraphQL support"},{"location":"user/reference/graphql-support/#graphql-support","text":"This section provides information about the supported and unsupported GraphQL types in Quick. Furthermore, it describes the GraphQL extensions that are introduced in Quick.","title":"GraphQL support"},{"location":"user/reference/graphql-support/#graphql-supported-types","text":"Currently, Quick supports the following GraphQL types: The mandatory Query type, The optional Mutation type and the corresponding Input type, Basic Types with field declarations as well as type modifiers, for example: type Character { name:String!, appearsIn: [Episode!] } , All scalar types: Int , String , Float , Boolean , ID together with field's arguments, for example: total(moreThan: Int = 50): Float , Enumerations ( enum ), Subscriptions ( subscription ). Thus, the following types are not supported: Interfaces ( interface ), Unions ( union ), Custom scalars, for example: scalar MyCustomScalar .","title":"GraphQL supported types"},{"location":"user/reference/graphql-support/#graphql-extensions","text":"","title":"GraphQL extensions"},{"location":"user/reference/graphql-support/#enums","text":"","title":"Enums"},{"location":"user/reference/graphql-support/#restdirectivemethod","text":"enum RestDirectiveMethod { GET , POST }","title":"RestDirectiveMethod"},{"location":"user/reference/graphql-support/#directives","text":"","title":"Directives"},{"location":"user/reference/graphql-support/#topic","text":"directive @topic( name: String! , # Name of the topic. keyArgument: String , # The argument which contains the key. This also supports arguments from parents. keyField: String # The field which contains the key. This can be used when the key is part of a different mirror. rangeFrom: Int # The lower bound (inclusive) of a range over a specific field. rangeTo: Int # The upper bound (exclusive) of the range over the given field (the same as above). ) on FIELD_DEFINITION","title":"@topic"},{"location":"user/reference/graphql-support/#rest","text":"directive @rest( url: String! # url of the rest service pathParameter: [String!] # list of the arguments that should be included in the list queryParameter: [String!] # list of arguments that should be included as query parameter in the form of `argumentName=value` bodyParameter: String # argument which represents a body. This cannot be a scalar httpMethod: RestDirectiveMethod = GET # The HTTP method used when calling the rest service ) on FIELD_DEFINITION","title":"@rest"},{"location":"user/reference/helm-chart/","text":"Quick Helm chart \u00b6 Below you can find the default value.yaml of Quick's Helm chart. image : # The base repository of the images repository : bakdata # The version of quick to deploy tag : \"0.8.0-dev\" # The image pull policy of manager and ingest service pullPolicy : \"Always\" # These configurations apply to both the helm chart ingresses and the gateway ingresses ingress : # Whether the ingress uses ssl ssl : true # Which entrypoint Traefik should use # This must match the ssl configuration: By default, websecure means ssl=true and web ssl=false entrypoint : \"websecure\" # Host of the ingress # This must be set when using a domain and can be empty when using an ip address host : \"\" # Configuration for the manager deployment manager : name : \"quick-manager\" replicaCount : 1 podAnnotations : {} # Configuration for the ingest service deployment ingest : # This value is also set as an enviornment variable for quick services so that they know how to connect to this service name : \"quick-ingest\" replicaCount : 1 podAnnotations : {} # The logging config quick should use, mainly for debugging purposes # If empty, loglevel is set to info # see https://logging.apache.org/log4j/2.x/manual/configuration.html#YAML log4jConfig : {} # The api key securing all APIs # This should be set through the CLI apiKey : \"\" # Environment variables configuring all services of quick # see the reference for more detailed information quickConfig : QUICK_KAFKA_BOOTSTRAP_SERVER : quick-kafka.default.svc.cluster.local:9092 QUICK_KAFKA_SCHEMA_REGISTRY_URL : http://quick-sr-schema-registry.default.svc.cluster.local:8081 QUICK_KAFKA_INTERNAL_PARTITIONS : \"3\" QUICK_KAFKA_INTERNAL_REPLICATION_FACTOR : \"1\" QUICK_TOPIC_REGISTRY_SERVICE_NAME : internal-topic-registry QUICK_TOPIC_REGISTRY_TOPIC_NAME : __topic-registry QUICK_TOPIC_REGISTRY_PARTITIONS : \"3\" QUICK_TOPIC_REGISTRY_REPLICATION_FACTOR : \"1\" QUICK_SCHEMA_FORMAT : \"Avro\" # The namespace used for created avro namespaces # see https://avro.apache.org/docs/current/spec.html QUICK_SCHEMA_AVRO_NAMESPACE : \"\" # For Protobuf # QUICK_SCHEMA_FORMAT: \"Protobuf\" # QUICK_SCHEMA_PROTOBUF_PACKAGE: \"\"","title":"Quick Helm chart"},{"location":"user/reference/helm-chart/#quick-helm-chart","text":"Below you can find the default value.yaml of Quick's Helm chart. image : # The base repository of the images repository : bakdata # The version of quick to deploy tag : \"0.8.0-dev\" # The image pull policy of manager and ingest service pullPolicy : \"Always\" # These configurations apply to both the helm chart ingresses and the gateway ingresses ingress : # Whether the ingress uses ssl ssl : true # Which entrypoint Traefik should use # This must match the ssl configuration: By default, websecure means ssl=true and web ssl=false entrypoint : \"websecure\" # Host of the ingress # This must be set when using a domain and can be empty when using an ip address host : \"\" # Configuration for the manager deployment manager : name : \"quick-manager\" replicaCount : 1 podAnnotations : {} # Configuration for the ingest service deployment ingest : # This value is also set as an enviornment variable for quick services so that they know how to connect to this service name : \"quick-ingest\" replicaCount : 1 podAnnotations : {} # The logging config quick should use, mainly for debugging purposes # If empty, loglevel is set to info # see https://logging.apache.org/log4j/2.x/manual/configuration.html#YAML log4jConfig : {} # The api key securing all APIs # This should be set through the CLI apiKey : \"\" # Environment variables configuring all services of quick # see the reference for more detailed information quickConfig : QUICK_KAFKA_BOOTSTRAP_SERVER : quick-kafka.default.svc.cluster.local:9092 QUICK_KAFKA_SCHEMA_REGISTRY_URL : http://quick-sr-schema-registry.default.svc.cluster.local:8081 QUICK_KAFKA_INTERNAL_PARTITIONS : \"3\" QUICK_KAFKA_INTERNAL_REPLICATION_FACTOR : \"1\" QUICK_TOPIC_REGISTRY_SERVICE_NAME : internal-topic-registry QUICK_TOPIC_REGISTRY_TOPIC_NAME : __topic-registry QUICK_TOPIC_REGISTRY_PARTITIONS : \"3\" QUICK_TOPIC_REGISTRY_REPLICATION_FACTOR : \"1\" QUICK_SCHEMA_FORMAT : \"Avro\" # The namespace used for created avro namespaces # see https://avro.apache.org/docs/current/spec.html QUICK_SCHEMA_AVRO_NAMESPACE : \"\" # For Protobuf # QUICK_SCHEMA_FORMAT: \"Protobuf\" # QUICK_SCHEMA_PROTOBUF_PACKAGE: \"\"","title":"Quick Helm chart"}]}