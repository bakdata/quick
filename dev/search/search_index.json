{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"changelog/","text":"Changelog \u00b6 0.4.0 (2022-02-02) \u00b6 Full Changelog Implemented enhancements: GraphQL Ingest Service #473 Use different namespace for Avro schemata #422 Batch requests to mirror applications #143 Support for List Arguments #6 Fixed bugs: Create a better error message when applying a schema to a Gateway and the topic is still not existing #487 Fix deletion #468 Race condititon in release CI #464 Miscellaneous: Refactor Quick Resources #452 0.3.0 (2021-09-30) \u00b6 Full Changelog Implemented enhancements: Create container port and service for streams applications #434 Upgrade images of dynamically created resources #411 Allow inclusion of arbitrary REST endpoints in GraphQL #398 Annotate resources created by manager #389 Fixed bugs: Remove tls section from ingress #445 Recreating topic fails #430 Update manager k8s templates #423 Default configuration: Gateway doesn't read existing schema after restart #407 Incremental build fails #383 (Continuous) Integration and Deployment: Version terraform modules in main repository #419 Update documentation branch in CI #397 Automatically create changelog commit #390 0.2.2 (2021-08-10) \u00b6 Full Changelog Fixed bugs: Cannot create topic containg Long types #408 NPE while scheduled call for deleting jobs #405 Namespaced Kubernetes Ingress not working for k8s v1.18.x #388 (Continuous) Integration and Deployment: Switch to central traefik instance #410 0.2.1 (2021-07-30) \u00b6 Full Changelog Implemented enhancements: Support applying schema to gateway during creation #174 Fixed bugs: Unhelpful error message when referencing not existing gateway #384 (Continuous) Integration and Deployment: Store Helm charts in a repository #391 0.2.0 (2021-07-22) \u00b6 Full Changelog Implemented enhancements: Define topic schema based on gateway #349 Custom schema registry #200 Support GraphQL variables #159 Communication Protocol between Gateway and Applications #5 Fixed bugs: Outdated OpenAPI spec #392 Snapshot image uses incorrect tag #362 Topic creation fails #355 Topic is created Kafka if the Schema is incomplete #352 Mismatch between API and OpenAPI specification #346 Delete topic not always deleting all subjects #113 Updated dependencies: Upgrade to Kafka 2.7 and streams-bootstrap 1.7 #351 Testing: E2E Loadtest #328 (Continuous) Integration and Deployment: Refactor the release workflow #385 Miscellaneous: Extract mirror client #380 Move http client and object mapper into one class #379 Arguments should not be required for application deployment #345 Add default query field if query is empty #218 0.1.2 (2021-05-02) \u00b6 Full Changelog Implemented enhancements: Implement get topic data endpoint #320 Persist gateway definition #311 List gateways #301 Add liveness and readiness probe #286 List topics #175 Support for default values #150 Pre-Join Queries on Demand #9 Fixed bugs: Topics not removed from Kafka when deletion job is done #323 Subscribing multiple times leads to errors #315 Updated dependencies: Update Micronaut to 2.3 #297 Testing: Add test case for existing topics error #341 Update @MicronautTest annotation #339 Miscellaneous: Remove built-in applications #329 Refactor (custom) application deployment endpoint #289 0.1.1 (2021-01-25) \u00b6 Full Changelog Implemented enhancements: Expose management endpoints on different port #285 Expose Micrometer metrics #284 Add title for fallback error #270 Collect metrics per namespaces #269 Handle wrong gateway name when applying defintion #212 Enable SSL #87 Fixed bugs: Use ErrorMessage for wrong content-type errors #306 Token Propgation not working anymore #304 Unhandled exception when ingesting wrong type of key #303 Value is sent multiple times in subscription with modification #294 Wrong deployment name for custom applications #287 Create and push branch image task fails in the CI (Jib Job) #275 Check gateway existence #271 Creating an existing topic causes mirror to fail #263 Uninformative error message when ingesting invalid data into topic #262 Ingestion and SSL #258 Deletion of not existing topics yields internal server error #254 Security fixes: Secure GraphQL WS endpoint #273 SSL Certificates #259 Documentation updates: Remove video examples from documentation #299 Update ReadMe #173 (Continuous) Integration and Deployment: Migrate to GCR #199 Change main branch name tag to a static name #165 Automatically create release commit #141 0.1.0 (2021-01-09) \u00b6 Full Changelog Implemented enhancements: Correctly propagate AvroTypeException #224 Use static IP addresses for external facing LBs #207 Delete internal topics #194 Mount log4j properties from config map #190 Cache build artifacts #189 Support deploying in namespaces #179 Use manager default tag for deploying mirror and gateway #172 Consider usage of edge router #152 Add code & test coverage tool #149 Use ConfigMap instead of injecting configs in Manager #146 Development cluster setup with single Kafka instance #137 Support release step in CI #134 Add docker registry to CI #119 Improve error handling #117 Require authentication for ingest service API #110 Require authentication for gateway API #109 Delete mirror application when topic is deleted #108 Rollback topic when registry fails #103 Allow omitting objectName in definition for single field #84 Automatically create missing mirror apps #78 Documentation in GraphQL schema #28 Support subscriptions #7 Fixed bugs: Secure GraphQL endpoints in gateway #260 Deletion Job can not enject parameter [host] #250 Applying definition.yaml responses in Bad request #247 \"No available services for ID\" #215 Traefik not working as expected #178 After error in topic creation, topic still created in Quick and cannot be deleted #166 Fix tag replacement of Github package registry #164 Query all for primitives does not work #100 Updated dependencies: Update to Micronaut 2.0 #157 Update to Kafka 2.5 #156 Testing: Integration tests for authentication #111 Test login functionality #106 (Continuous) Integration and Deployment: Upgrade to env files in CI #226 Add custom Realm to Keycloak #203 Migrate to GitHub Container Registry for Docker images #192 Rerun CI tasks after converting a \"Draft PR\" to \"ready to review\" #191 Deactivate integration tests for draft PRs #186 Add Keycloak Deployment #148 Use GitHub docker registry in dev deployment #142 Delete image tags from registry #140 Restrict manager's cluster role to minimal access #71 Miscellaneous: Remove Graphiql #265 Disable exactly one in applications #233 Use yaml files for k8s resources #162 Remove serde for primitives #160 Merge client credential flow and refresh token flow into a single endpoint #127 0.0.1 (2020-07-27) \u00b6 Full Changelog Implemented enhancements: Single ingest endpoint #121 Topic Registry #118 Implement Logout functionality #114 Delete deployments via the manager #102 Setup CI/CD #96 Immutable topics #90 Time to live option for values in topics #89 Require authentication for REST calls #86 Add user management endpoints: login #85 Support deletion of key-value pairs #81 Support deletion of topics #79 Support fetching all values of a sate store #69 Offer endpoint to fetch all values in store #56 Implement sum application #49 Implement chart application #48 Support field resolution in hierarchial schemas #47 Set topic types in manager #46 Centralized service for topic types #45 Support deployments in Docker environment #30 Support join of argument #29 Kubernetes deployments in Manager API #18 Remove redundant SerDe Deduction #11 Gateway Scaling #10 Testing Framework #8 HTTP Ingest Service #4 Fixed bugs: Modifications for nested fields not working #129 Use LoadBalancer as external gateway service #99 Map load balancer ports to 80 #98 Multiple counter applications have the same unique app id #75 Application does not exit properly on exception #74 Creating two GraphQL types from the same application output results in error #62 Use type prefix for pod name #61 Miscellaneous: QuickSerde should always return a GenericRecord #55 Remove quick config and API #27","title":"Changelog"},{"location":"changelog/#changelog","text":"","title":"Changelog"},{"location":"changelog/#040-2022-02-02","text":"Full Changelog Implemented enhancements: GraphQL Ingest Service #473 Use different namespace for Avro schemata #422 Batch requests to mirror applications #143 Support for List Arguments #6 Fixed bugs: Create a better error message when applying a schema to a Gateway and the topic is still not existing #487 Fix deletion #468 Race condititon in release CI #464 Miscellaneous: Refactor Quick Resources #452","title":"0.4.0 (2022-02-02)"},{"location":"changelog/#030-2021-09-30","text":"Full Changelog Implemented enhancements: Create container port and service for streams applications #434 Upgrade images of dynamically created resources #411 Allow inclusion of arbitrary REST endpoints in GraphQL #398 Annotate resources created by manager #389 Fixed bugs: Remove tls section from ingress #445 Recreating topic fails #430 Update manager k8s templates #423 Default configuration: Gateway doesn't read existing schema after restart #407 Incremental build fails #383 (Continuous) Integration and Deployment: Version terraform modules in main repository #419 Update documentation branch in CI #397 Automatically create changelog commit #390","title":"0.3.0 (2021-09-30)"},{"location":"changelog/#022-2021-08-10","text":"Full Changelog Fixed bugs: Cannot create topic containg Long types #408 NPE while scheduled call for deleting jobs #405 Namespaced Kubernetes Ingress not working for k8s v1.18.x #388 (Continuous) Integration and Deployment: Switch to central traefik instance #410","title":"0.2.2 (2021-08-10)"},{"location":"changelog/#021-2021-07-30","text":"Full Changelog Implemented enhancements: Support applying schema to gateway during creation #174 Fixed bugs: Unhelpful error message when referencing not existing gateway #384 (Continuous) Integration and Deployment: Store Helm charts in a repository #391","title":"0.2.1 (2021-07-30)"},{"location":"changelog/#020-2021-07-22","text":"Full Changelog Implemented enhancements: Define topic schema based on gateway #349 Custom schema registry #200 Support GraphQL variables #159 Communication Protocol between Gateway and Applications #5 Fixed bugs: Outdated OpenAPI spec #392 Snapshot image uses incorrect tag #362 Topic creation fails #355 Topic is created Kafka if the Schema is incomplete #352 Mismatch between API and OpenAPI specification #346 Delete topic not always deleting all subjects #113 Updated dependencies: Upgrade to Kafka 2.7 and streams-bootstrap 1.7 #351 Testing: E2E Loadtest #328 (Continuous) Integration and Deployment: Refactor the release workflow #385 Miscellaneous: Extract mirror client #380 Move http client and object mapper into one class #379 Arguments should not be required for application deployment #345 Add default query field if query is empty #218","title":"0.2.0 (2021-07-22)"},{"location":"changelog/#012-2021-05-02","text":"Full Changelog Implemented enhancements: Implement get topic data endpoint #320 Persist gateway definition #311 List gateways #301 Add liveness and readiness probe #286 List topics #175 Support for default values #150 Pre-Join Queries on Demand #9 Fixed bugs: Topics not removed from Kafka when deletion job is done #323 Subscribing multiple times leads to errors #315 Updated dependencies: Update Micronaut to 2.3 #297 Testing: Add test case for existing topics error #341 Update @MicronautTest annotation #339 Miscellaneous: Remove built-in applications #329 Refactor (custom) application deployment endpoint #289","title":"0.1.2 (2021-05-02)"},{"location":"changelog/#011-2021-01-25","text":"Full Changelog Implemented enhancements: Expose management endpoints on different port #285 Expose Micrometer metrics #284 Add title for fallback error #270 Collect metrics per namespaces #269 Handle wrong gateway name when applying defintion #212 Enable SSL #87 Fixed bugs: Use ErrorMessage for wrong content-type errors #306 Token Propgation not working anymore #304 Unhandled exception when ingesting wrong type of key #303 Value is sent multiple times in subscription with modification #294 Wrong deployment name for custom applications #287 Create and push branch image task fails in the CI (Jib Job) #275 Check gateway existence #271 Creating an existing topic causes mirror to fail #263 Uninformative error message when ingesting invalid data into topic #262 Ingestion and SSL #258 Deletion of not existing topics yields internal server error #254 Security fixes: Secure GraphQL WS endpoint #273 SSL Certificates #259 Documentation updates: Remove video examples from documentation #299 Update ReadMe #173 (Continuous) Integration and Deployment: Migrate to GCR #199 Change main branch name tag to a static name #165 Automatically create release commit #141","title":"0.1.1 (2021-01-25)"},{"location":"changelog/#010-2021-01-09","text":"Full Changelog Implemented enhancements: Correctly propagate AvroTypeException #224 Use static IP addresses for external facing LBs #207 Delete internal topics #194 Mount log4j properties from config map #190 Cache build artifacts #189 Support deploying in namespaces #179 Use manager default tag for deploying mirror and gateway #172 Consider usage of edge router #152 Add code & test coverage tool #149 Use ConfigMap instead of injecting configs in Manager #146 Development cluster setup with single Kafka instance #137 Support release step in CI #134 Add docker registry to CI #119 Improve error handling #117 Require authentication for ingest service API #110 Require authentication for gateway API #109 Delete mirror application when topic is deleted #108 Rollback topic when registry fails #103 Allow omitting objectName in definition for single field #84 Automatically create missing mirror apps #78 Documentation in GraphQL schema #28 Support subscriptions #7 Fixed bugs: Secure GraphQL endpoints in gateway #260 Deletion Job can not enject parameter [host] #250 Applying definition.yaml responses in Bad request #247 \"No available services for ID\" #215 Traefik not working as expected #178 After error in topic creation, topic still created in Quick and cannot be deleted #166 Fix tag replacement of Github package registry #164 Query all for primitives does not work #100 Updated dependencies: Update to Micronaut 2.0 #157 Update to Kafka 2.5 #156 Testing: Integration tests for authentication #111 Test login functionality #106 (Continuous) Integration and Deployment: Upgrade to env files in CI #226 Add custom Realm to Keycloak #203 Migrate to GitHub Container Registry for Docker images #192 Rerun CI tasks after converting a \"Draft PR\" to \"ready to review\" #191 Deactivate integration tests for draft PRs #186 Add Keycloak Deployment #148 Use GitHub docker registry in dev deployment #142 Delete image tags from registry #140 Restrict manager's cluster role to minimal access #71 Miscellaneous: Remove Graphiql #265 Disable exactly one in applications #233 Use yaml files for k8s resources #162 Remove serde for primitives #160 Merge client credential flow and refresh token flow into a single endpoint #127","title":"0.1.0 (2021-01-09)"},{"location":"changelog/#001-2020-07-27","text":"Full Changelog Implemented enhancements: Single ingest endpoint #121 Topic Registry #118 Implement Logout functionality #114 Delete deployments via the manager #102 Setup CI/CD #96 Immutable topics #90 Time to live option for values in topics #89 Require authentication for REST calls #86 Add user management endpoints: login #85 Support deletion of key-value pairs #81 Support deletion of topics #79 Support fetching all values of a sate store #69 Offer endpoint to fetch all values in store #56 Implement sum application #49 Implement chart application #48 Support field resolution in hierarchial schemas #47 Set topic types in manager #46 Centralized service for topic types #45 Support deployments in Docker environment #30 Support join of argument #29 Kubernetes deployments in Manager API #18 Remove redundant SerDe Deduction #11 Gateway Scaling #10 Testing Framework #8 HTTP Ingest Service #4 Fixed bugs: Modifications for nested fields not working #129 Use LoadBalancer as external gateway service #99 Map load balancer ports to 80 #98 Multiple counter applications have the same unique app id #75 Application does not exit properly on exception #74 Creating two GraphQL types from the same application output results in error #62 Use type prefix for pod name #61 Miscellaneous: QuickSerde should always return a GenericRecord #55 Remove quick config and API #27","title":"0.0.1 (2020-07-27)"},{"location":"developer/architecture/","text":"Architecture \u00b6 Quick has the following high-level architecture: The system is deployed in Kubernetes. We use Traefik is an ingress load balancer, that can route to the manager, ingest service and gateways. Since Quick central functionality is built on top of Kafka, we also use it to store any metadata. Traefik \u00b6 We deploy Traefik with a LoadBalancer service, and hence a public IP. The host should be set before the deployment. The deployment contains the respective TLS certificate. For internal routing, Traefik is configured through two K8s resources: Ingress and Middleware . An ingress defines a path to service mapping, e.g. demo.d9p.io/manager should go to the manager service. The ingress is annotated with a middleware: apiVersion : networking.k8s.io/v1 kind : Ingress metadata : annotations : traefik.ingress.kubernetes.io/router.middlewares : quick-demo-service-stripprefix@kubernetescrd We use the middleware to strip prefixes from the path. For instance, we can access GraphQL of the gateway demo through https://demo.d9p.io/gateway/demo/graphql . The middleware ensures that Traefik forwards this request to http://quick-gateway-demo/graphql . For gateways, the manager has to deploy these resources. Manager \u00b6 The manager handles user requests from the CLI . Most tasks are therefore based on k8s resources. For new resource, we use a templating engine that creates the respective yaml strings. The strings are then loaded into fabric8io k8s client's models and sent to the k8s API. Additionally the manger has administrative-like tasks: * deployment of topic registry at start up * deletion of succeeded jobs Ingest Service \u00b6 The ingest service is a HTTP service for ingesting data into a Kafka topic. As this requires the use of serializers for the keys and values, we need to know which to use. The ingest service requests (and caches) this information from the topic registry. Further, when a topic is marked as immutable in the topic registry, the ingest service first checks its mirror. Common \u00b6 All our subprojects share a library called common . The package contains code that is used throughout the projects, including: exception-handling configs security (API-Key) API models","title":"Architecture"},{"location":"developer/architecture/#architecture","text":"Quick has the following high-level architecture: The system is deployed in Kubernetes. We use Traefik is an ingress load balancer, that can route to the manager, ingest service and gateways. Since Quick central functionality is built on top of Kafka, we also use it to store any metadata.","title":"Architecture"},{"location":"developer/architecture/#traefik","text":"We deploy Traefik with a LoadBalancer service, and hence a public IP. The host should be set before the deployment. The deployment contains the respective TLS certificate. For internal routing, Traefik is configured through two K8s resources: Ingress and Middleware . An ingress defines a path to service mapping, e.g. demo.d9p.io/manager should go to the manager service. The ingress is annotated with a middleware: apiVersion : networking.k8s.io/v1 kind : Ingress metadata : annotations : traefik.ingress.kubernetes.io/router.middlewares : quick-demo-service-stripprefix@kubernetescrd We use the middleware to strip prefixes from the path. For instance, we can access GraphQL of the gateway demo through https://demo.d9p.io/gateway/demo/graphql . The middleware ensures that Traefik forwards this request to http://quick-gateway-demo/graphql . For gateways, the manager has to deploy these resources.","title":"Traefik"},{"location":"developer/architecture/#manager","text":"The manager handles user requests from the CLI . Most tasks are therefore based on k8s resources. For new resource, we use a templating engine that creates the respective yaml strings. The strings are then loaded into fabric8io k8s client's models and sent to the k8s API. Additionally the manger has administrative-like tasks: * deployment of topic registry at start up * deletion of succeeded jobs","title":"Manager"},{"location":"developer/architecture/#ingest-service","text":"The ingest service is a HTTP service for ingesting data into a Kafka topic. As this requires the use of serializers for the keys and values, we need to know which to use. The ingest service requests (and caches) this information from the topic registry. Further, when a topic is marked as immutable in the topic registry, the ingest service first checks its mirror.","title":"Ingest Service"},{"location":"developer/architecture/#common","text":"All our subprojects share a library called common . The package contains code that is used throughout the projects, including: exception-handling configs security (API-Key) API models","title":"Common"},{"location":"developer/cli/","text":"CLI \u00b6 Our CLI is written in Python. It contains two modules. quick_client is the REST API client for the manager. It is automatically generated as explained in Development - OpenAPI quick is a CLI wrapper for the REST API client. Development \u00b6 Setup \u00b6 We use poetry as build system. You can simply run poetry install in the project directory. By default, this creates a new virtual environment with all runtime and dev dependencies installed. Note You can run poetry config virtualenvs.path <PATH> to set the path where virtualenvs are created. To create a new version and install it, run: poetry build -f wheel && \\ pip install ./dist/quick_cli-0.1.3-py3-none-any.whl --force-reinstall If you want to add a new dependency, make sure to commit the updated poetry.lock file. Code Quality \u00b6 We use flake8, isort and black for formatting and linting of the project. You can use the provided pre-commit-config, to make sure your PRs pass. For that install the hooks with pre-commit install (making them run before each commit). You can also run them manually with pre-commit run --all-files . Currently, mypy is excluded from pre-commit. However, feel free to run mypy . and fix possible errors. Documentation \u00b6 We provide a argparse-to-markdown script for generating the CLI's documentation. The created file is commands.md . After updating commands, please update it with the following command: python quick/generate_docs.py > commands.md Architecture \u00b6 Our CLI uses Python's ArgParse . We follow a OOP approach for defining new subcommands. There are two base-classes: Group A Group is a subcommand that contains again one more child subcommands. The subcommands are defined in its sub_parser field. Attention A new top level group (i.e., used as quick <new-group> ) must be added the COMMANDS list in commands/__init__.py . Command A Command is a subcommand that executes an action. You can override the add_args method, that allows to add new required and optional arguments. The execute method contains the logic for the command action. This approach using base classes allows us to define common behavior, like recurring arguments (e.g., --debug ) and setup configurations.","title":"CLI"},{"location":"developer/cli/#cli","text":"Our CLI is written in Python. It contains two modules. quick_client is the REST API client for the manager. It is automatically generated as explained in Development - OpenAPI quick is a CLI wrapper for the REST API client.","title":"CLI"},{"location":"developer/cli/#development","text":"","title":"Development"},{"location":"developer/cli/#setup","text":"We use poetry as build system. You can simply run poetry install in the project directory. By default, this creates a new virtual environment with all runtime and dev dependencies installed. Note You can run poetry config virtualenvs.path <PATH> to set the path where virtualenvs are created. To create a new version and install it, run: poetry build -f wheel && \\ pip install ./dist/quick_cli-0.1.3-py3-none-any.whl --force-reinstall If you want to add a new dependency, make sure to commit the updated poetry.lock file.","title":"Setup"},{"location":"developer/cli/#code-quality","text":"We use flake8, isort and black for formatting and linting of the project. You can use the provided pre-commit-config, to make sure your PRs pass. For that install the hooks with pre-commit install (making them run before each commit). You can also run them manually with pre-commit run --all-files . Currently, mypy is excluded from pre-commit. However, feel free to run mypy . and fix possible errors.","title":"Code Quality"},{"location":"developer/cli/#documentation","text":"We provide a argparse-to-markdown script for generating the CLI's documentation. The created file is commands.md . After updating commands, please update it with the following command: python quick/generate_docs.py > commands.md","title":"Documentation"},{"location":"developer/cli/#architecture","text":"Our CLI uses Python's ArgParse . We follow a OOP approach for defining new subcommands. There are two base-classes: Group A Group is a subcommand that contains again one more child subcommands. The subcommands are defined in its sub_parser field. Attention A new top level group (i.e., used as quick <new-group> ) must be added the COMMANDS list in commands/__init__.py . Command A Command is a subcommand that executes an action. You can override the add_args method, that allows to add new required and optional arguments. The execute method contains the logic for the command action. This approach using base classes allows us to define common behavior, like recurring arguments (e.g., --debug ) and setup configurations.","title":"Architecture"},{"location":"developer/contributing/","text":"Contributing \u00b6 Code Quality \u00b6 We use a number of plugins for ensuring our code quality. Most of them run during the compilation of the project. Any warnings or errors should be addressed before merging. Checkstyle \u00b6 We use Checkstyle to enforce our coding style. The configuration is located in the config/checkstyle/checkstyle.xml . It is based on Google's Java coding style. You can download the Checkstyle Plugin in the IntelliJ Plugin Store. By importing the checkstyle.xml as code style, the reformat action Ctrl + Alt + L works with it. Further, you can run Gradle tasks checkstyleMain and checkstyleTest . This lists problems in the shell and creates a HTML report, that is located in build/reports/checkstyle/ . Error Prone \u00b6 Error Prone extends the Java Compiler to catch common mistakes. It is enabled by default when compiling with Gradle. Attention Lombok and Error Prone don't work that well together. There might be some false-positives when Lombok is used. If possible, use @SuppressWarning . Otherwise, disable the check completely in the QuickCodeQualityPlugin . Furthermore, Error Prone throws an IndexOutOfBounds exception for the pattern UnusedVariable when a Lombok annotation adds an field that is unused. That may usually happen with @Sl4j . In such cases, simply remove the annoation - it is unused anyways. IntelliJ Setup \u00b6 To add the plugin, start the IDE and find the Plugins dialog. Browse Repositories, choose Category: Build, and find the Error-prone plugin. Right-click and choose \u201cDownload and install\u201d. The IDE will restart after you\u2019ve exited these dialogs. To enable Error Prone, choose Settings | Compiler | Java Compiler | Use compiler: Javac with error-prone and also make sure Settings | Compiler | Use external build is NOT selected. NullAway \u00b6 NullAway is a tool to help eliminate NullPointerExceptions (NPEs) in your Java code. It is built as a plugin to Error Prone. With NullAway, we assume that a variable is never null unless there is a @Nullable annotation. Attention @Nullable has it origin in the JSR 305, that has been dormant since 2012. Therefore, using javax.annotation.Nullable is problematic. We chose to use edu.umd.cs.findbugs.annotations.NonNull instead. Jacoco \u00b6 We use Jacoco for test coverage. The ReporterPlugin creates the task codeCoverageReport that creates a test report in build/reports/jacoco . There is a html report for manual inspection and a xml report that can be exported to Sonarqube. Sonarqube \u00b6 TODO: Add version for open-source Issues \u00b6 We use GitHub issues to keep track of our tasks. An issues should always have one or more labels . Pull Request Workflow \u00b6 Our master branch is protected, i.e., you cannot push directly to it. We use a workflow similar to GitHub Flow , except that we squash Pull Requests (PRs). You start by creating a new local branch, commit the changes, and create a PR in GitHub. Don't wait till the end with creating the PR and try to keep it small(ish). Git Branch \u00b6 The branch should have meaningful name and roughly follow the scheme TYPE / COMPONENT / TOPIC . For example, when working on the new feature in the manager, feature/mananger/new-feature could be used. You can drop TYPE and/or COMPONENT if they are not applicable. The name carries some importance because it is used in our CI for tagging the images created for the PR. For example, the branch feature/mananger/new-feature can be deployed with the tag feature-manager-new-feature . it helps finding your way in git. Pull Request \u00b6 Some general guidelines with regards to Pull Requests: Use a meaningful title (not the default branch name) and add a short description for non-trivial changes. Publish your branch early on, and create a draft PR in case it is not ready. This allows for early feedback and helps. prevent misunderstandings. Don't worry too much about commits to the branch, they are getting squashed regardless. Keep your branch up-to-date with master, otherwise it cannot be merged. If applicable, link the issue the PR closes. Add a meaningful commit message when merging the PR. For example, you can use the PR description. Be careful with dependent branches/PRs. Otherwise reviewers might have a hard time getting through the diff. See the next section for more information. Dependent Pull Requests \u00b6 Squashing merge commits is great for having a clean commit history in master. It is sometimes however troublesome when dealing with dependent features. The StackOverflow answer Hold on, skip merging explains the preferred workflow in such situations. Release Process \u00b6 We follow SemVer versioning. A new release can be created by manually triggering the GitHub Action workflow Create release . You can specify the scope of the release, i.e., major, minor or patch. The process: creates a git tag adds a changelog entry creates a GitHub Release with the changelog entry pushes a new Docker image adds the corresponding Helm chart to the GitHub release adds the reference to the new Helm chart to the Helm Repository for minor and major releases, creates a new version in the documentation Changelog \u00b6 We use the github-changelog-generator for automatically creating our changelog. You can find the used configuration in the release workflow . We only include closed issued but not pull requests. In case a closed issue should not be included, label it with invalid .","title":"Contributing"},{"location":"developer/contributing/#contributing","text":"","title":"Contributing"},{"location":"developer/contributing/#code-quality","text":"We use a number of plugins for ensuring our code quality. Most of them run during the compilation of the project. Any warnings or errors should be addressed before merging.","title":"Code Quality"},{"location":"developer/contributing/#checkstyle","text":"We use Checkstyle to enforce our coding style. The configuration is located in the config/checkstyle/checkstyle.xml . It is based on Google's Java coding style. You can download the Checkstyle Plugin in the IntelliJ Plugin Store. By importing the checkstyle.xml as code style, the reformat action Ctrl + Alt + L works with it. Further, you can run Gradle tasks checkstyleMain and checkstyleTest . This lists problems in the shell and creates a HTML report, that is located in build/reports/checkstyle/ .","title":"Checkstyle"},{"location":"developer/contributing/#error-prone","text":"Error Prone extends the Java Compiler to catch common mistakes. It is enabled by default when compiling with Gradle. Attention Lombok and Error Prone don't work that well together. There might be some false-positives when Lombok is used. If possible, use @SuppressWarning . Otherwise, disable the check completely in the QuickCodeQualityPlugin . Furthermore, Error Prone throws an IndexOutOfBounds exception for the pattern UnusedVariable when a Lombok annotation adds an field that is unused. That may usually happen with @Sl4j . In such cases, simply remove the annoation - it is unused anyways.","title":"Error Prone"},{"location":"developer/contributing/#intellij-setup","text":"To add the plugin, start the IDE and find the Plugins dialog. Browse Repositories, choose Category: Build, and find the Error-prone plugin. Right-click and choose \u201cDownload and install\u201d. The IDE will restart after you\u2019ve exited these dialogs. To enable Error Prone, choose Settings | Compiler | Java Compiler | Use compiler: Javac with error-prone and also make sure Settings | Compiler | Use external build is NOT selected.","title":"IntelliJ Setup"},{"location":"developer/contributing/#nullaway","text":"NullAway is a tool to help eliminate NullPointerExceptions (NPEs) in your Java code. It is built as a plugin to Error Prone. With NullAway, we assume that a variable is never null unless there is a @Nullable annotation. Attention @Nullable has it origin in the JSR 305, that has been dormant since 2012. Therefore, using javax.annotation.Nullable is problematic. We chose to use edu.umd.cs.findbugs.annotations.NonNull instead.","title":"NullAway"},{"location":"developer/contributing/#jacoco","text":"We use Jacoco for test coverage. The ReporterPlugin creates the task codeCoverageReport that creates a test report in build/reports/jacoco . There is a html report for manual inspection and a xml report that can be exported to Sonarqube.","title":"Jacoco"},{"location":"developer/contributing/#sonarqube","text":"TODO: Add version for open-source","title":"Sonarqube"},{"location":"developer/contributing/#issues","text":"We use GitHub issues to keep track of our tasks. An issues should always have one or more labels .","title":"Issues"},{"location":"developer/contributing/#pull-request-workflow","text":"Our master branch is protected, i.e., you cannot push directly to it. We use a workflow similar to GitHub Flow , except that we squash Pull Requests (PRs). You start by creating a new local branch, commit the changes, and create a PR in GitHub. Don't wait till the end with creating the PR and try to keep it small(ish).","title":"Pull Request Workflow"},{"location":"developer/contributing/#git-branch","text":"The branch should have meaningful name and roughly follow the scheme TYPE / COMPONENT / TOPIC . For example, when working on the new feature in the manager, feature/mananger/new-feature could be used. You can drop TYPE and/or COMPONENT if they are not applicable. The name carries some importance because it is used in our CI for tagging the images created for the PR. For example, the branch feature/mananger/new-feature can be deployed with the tag feature-manager-new-feature . it helps finding your way in git.","title":"Git Branch"},{"location":"developer/contributing/#pull-request","text":"Some general guidelines with regards to Pull Requests: Use a meaningful title (not the default branch name) and add a short description for non-trivial changes. Publish your branch early on, and create a draft PR in case it is not ready. This allows for early feedback and helps. prevent misunderstandings. Don't worry too much about commits to the branch, they are getting squashed regardless. Keep your branch up-to-date with master, otherwise it cannot be merged. If applicable, link the issue the PR closes. Add a meaningful commit message when merging the PR. For example, you can use the PR description. Be careful with dependent branches/PRs. Otherwise reviewers might have a hard time getting through the diff. See the next section for more information.","title":"Pull Request"},{"location":"developer/contributing/#dependent-pull-requests","text":"Squashing merge commits is great for having a clean commit history in master. It is sometimes however troublesome when dealing with dependent features. The StackOverflow answer Hold on, skip merging explains the preferred workflow in such situations.","title":"Dependent Pull Requests"},{"location":"developer/contributing/#release-process","text":"We follow SemVer versioning. A new release can be created by manually triggering the GitHub Action workflow Create release . You can specify the scope of the release, i.e., major, minor or patch. The process: creates a git tag adds a changelog entry creates a GitHub Release with the changelog entry pushes a new Docker image adds the corresponding Helm chart to the GitHub release adds the reference to the new Helm chart to the Helm Repository for minor and major releases, creates a new version in the documentation","title":"Release Process"},{"location":"developer/contributing/#changelog","text":"We use the github-changelog-generator for automatically creating our changelog. You can find the used configuration in the release workflow . We only include closed issued but not pull requests. In case a closed issue should not be included, label it with invalid .","title":"Changelog"},{"location":"developer/development/","text":"Development \u00b6 Tests \u00b6 We differentiate between unit tests and integration tests in our test suite. The latter has a custom annotation @IntegrationTest that should be used to mark those types of tests. We do not run them for draft PRs to keep the feedback loop. Build Logic \u00b6 We use custom Gradle build logic to orchestrate our builds. It is located in the build-logic directory and referenced by includeBuild(\"build-logic\") in settings.gradle.kts . The build-logic contains two modules: convention and libraries. Convention \u00b6 The convention module configures conventions and plugins that can be applied to a subproject. base-dependencies This convention applies dependencies that are used throughout all quick subprojects. Among others, this includes our logging setup and test dependencies. http-service This adds micronaut dependencies for running a http service. It allows configuring whether the service is secured. BasePlugin The BasePlugin is applied to all quick projects. It configures Java, Compiler Settings, Lombok and more. QuickJibPlugin The plugin applies Google's Jib plugin and the sets the image location. QuickCodeQualityPlugin Plugin that ensures the project's code quality. This includes checkstyle, errorprone, nullaway and jacoco. See Contributing - Code Quality for detailed information. ReporterPlugin The reporter plugin is applied to the root project. It allows the aggregation of data from subproject. For example, we use this to collect and merge Jacoco test coverage for the whole project. See Operations - Registry for more information. Libraries \u00b6 The libraries module holds all information about all dependencies. This makes sure they are defined at a common place. OpenAPI \u00b6 The manager API is specified in the openapi directory . We use the OpenAPI generator (Version 4.3.1) to generate our python client . java -jar openapi-generator-cli.jar generate \\ -i quick/openapi/spec/Quick-Manager-v1.yaml \\ -g python \\ -o quick-cli/ \\ -p = generateSourceCodeOnly = true,packageName = quick_client \\ --global-property apiTests = false,modelTests = false,modelDocs = false This assumes the following directory structure: quick-project \u251c\u2500\u2500 openapi-generator-cli.jar \u251c\u2500\u2500 quick \u2514\u2500\u2500 quick-cli Documentation \u00b6 The documentation is part of the main repository. It is built with mkdocs-materialize . mkdocs generates static websites from markdown files. You can find all related files in the docs directory. Local Development \u00b6 mkdocs is a Python project. You can install all required dependencies with the provided requirements.txt . For local development, run mkdocs serve from the docs directory. Then you can view a live version of the documentation on http://localhost:8000 . mkdocs is configured by the mkdocs.yaml file. The markdown files themselves are in their own docs directory, because mkdocs expects the files in a subdirectory. Build \u00b6 We deploy our built documentation to the gh-pages branch. For versioning, we use mike . As suggested by mike , we omit the patch from the documentation version. To push a new version, run: mike deploy x.y latest This command also sets x.y as latest. With that, /latest redirects to /x.y . If you just update an older release, omit latest , e.g.: mike deploy x.y We also want to redirect / to /latest/ , which then redirects to /x.y/ . This was done with: mike set-default latest It creates an index.html in the root, which redirect to /latest/ . Unless the file was deleted, there is no need to run the command above. Note These commands should only be ran locally for testig purposes. Therefore, we drop the --push flag here. Deployment \u00b6 As described, mike pushes to the gh-pages branch. GitHub automatically hosts the branch on bakdata.github.io/quick .","title":"Development"},{"location":"developer/development/#development","text":"","title":"Development"},{"location":"developer/development/#tests","text":"We differentiate between unit tests and integration tests in our test suite. The latter has a custom annotation @IntegrationTest that should be used to mark those types of tests. We do not run them for draft PRs to keep the feedback loop.","title":"Tests"},{"location":"developer/development/#build-logic","text":"We use custom Gradle build logic to orchestrate our builds. It is located in the build-logic directory and referenced by includeBuild(\"build-logic\") in settings.gradle.kts . The build-logic contains two modules: convention and libraries.","title":"Build Logic"},{"location":"developer/development/#convention","text":"The convention module configures conventions and plugins that can be applied to a subproject. base-dependencies This convention applies dependencies that are used throughout all quick subprojects. Among others, this includes our logging setup and test dependencies. http-service This adds micronaut dependencies for running a http service. It allows configuring whether the service is secured. BasePlugin The BasePlugin is applied to all quick projects. It configures Java, Compiler Settings, Lombok and more. QuickJibPlugin The plugin applies Google's Jib plugin and the sets the image location. QuickCodeQualityPlugin Plugin that ensures the project's code quality. This includes checkstyle, errorprone, nullaway and jacoco. See Contributing - Code Quality for detailed information. ReporterPlugin The reporter plugin is applied to the root project. It allows the aggregation of data from subproject. For example, we use this to collect and merge Jacoco test coverage for the whole project. See Operations - Registry for more information.","title":"Convention"},{"location":"developer/development/#libraries","text":"The libraries module holds all information about all dependencies. This makes sure they are defined at a common place.","title":"Libraries"},{"location":"developer/development/#openapi","text":"The manager API is specified in the openapi directory . We use the OpenAPI generator (Version 4.3.1) to generate our python client . java -jar openapi-generator-cli.jar generate \\ -i quick/openapi/spec/Quick-Manager-v1.yaml \\ -g python \\ -o quick-cli/ \\ -p = generateSourceCodeOnly = true,packageName = quick_client \\ --global-property apiTests = false,modelTests = false,modelDocs = false This assumes the following directory structure: quick-project \u251c\u2500\u2500 openapi-generator-cli.jar \u251c\u2500\u2500 quick \u2514\u2500\u2500 quick-cli","title":"OpenAPI"},{"location":"developer/development/#documentation","text":"The documentation is part of the main repository. It is built with mkdocs-materialize . mkdocs generates static websites from markdown files. You can find all related files in the docs directory.","title":"Documentation"},{"location":"developer/development/#local-development","text":"mkdocs is a Python project. You can install all required dependencies with the provided requirements.txt . For local development, run mkdocs serve from the docs directory. Then you can view a live version of the documentation on http://localhost:8000 . mkdocs is configured by the mkdocs.yaml file. The markdown files themselves are in their own docs directory, because mkdocs expects the files in a subdirectory.","title":"Local Development"},{"location":"developer/development/#build","text":"We deploy our built documentation to the gh-pages branch. For versioning, we use mike . As suggested by mike , we omit the patch from the documentation version. To push a new version, run: mike deploy x.y latest This command also sets x.y as latest. With that, /latest redirects to /x.y . If you just update an older release, omit latest , e.g.: mike deploy x.y We also want to redirect / to /latest/ , which then redirects to /x.y/ . This was done with: mike set-default latest It creates an index.html in the root, which redirect to /latest/ . Unless the file was deleted, there is no need to run the command above. Note These commands should only be ran locally for testig purposes. Therefore, we drop the --push flag here.","title":"Build"},{"location":"developer/development/#deployment","text":"As described, mike pushes to the gh-pages branch. GitHub automatically hosts the branch on bakdata.github.io/quick .","title":"Deployment"},{"location":"developer/operations/","text":"Operations \u00b6 Tools \u00b6 A list of tools we use: Gradle gcloud kubectl (recommendation: k9s ) Terraform Helm Poetry Kubernetes Cluster \u00b6 All internal quick deployments (dev, test, demo, personal...) are on the bakdata dev cluster. Yannick can give you access. Make also sure you are in the #bakdata-dev-cluster channel in Slack. To configure your ~/.kube/config , run: gcloud container clusters get-credentials gcp-bakdata-dev-cluster \\ --region us-east1 \\ --project gcp-bakdata-cluster Each deployment has its own namespace, commonly prefixed with quick- . Container Registry \u00b6 All our images are located in our Docker Hub Registry . To configure docker inside the CI, use the secrets DOCKERHUB_USERNAME and DOCKERHUB_TOKEN in a workflow to login: - name: Login to Docker Hub uses: docker/login-action@v1 with: username: ${{ inputs.username }} password: ${{ inputs.token }} Once you have docker configured you can tag and push images using jib: ./gradlew -Pversion=<image-tag> jib Artifact Registry (Helm) \u00b6 All artifacts are located in our Google Artifact Registry us-east1-docker.pkg.dev/d9p-quick . You can access it through the web console . We currently only use it for helm chart artifacts. To configure your local helm (in case you want to push manually), run: gcloud auth configure-docker us-east1-docker.pkg.dev export HELM_EXPERIMENTAL_OCI = 1 export DOCKER_CONFIG = \"~/.docker\" export HELM_REGISTRY_CONFIG = \" ${ DOCKER_CONFIG } /config.json\" To configure helm inside the CI, use the following command to login: - name: Login to Helm registry run: | gcloud auth print-access-token | helm registry login -u oauth2accesstoken \\ --password-stdin https://us-east1-docker.pkg.dev shell: bash Once you have helm configured you can save and push helm charts by running: helm chart save <chart-name> us-east1-docker.pkg.dev/d9p-quick/helm-charts-dev/<chart-name> helm chart push us-east1-docker.pkg.dev/d9p-quick/helm-charts-dev/<chart-name>:<chart-version> If you want to push a helm chart for production, then you can replace helm-charts-dev with helm-charts . Warning The container registry is in a different Google Cloud project than the development cluster. Hence, we need to configure an image-pull secret. CI \u00b6 Our CI runs on top of GitHub Actions. The workflows can be found in .github/workflows . The main workflow ci.yaml has the following tasks: build & test project push image to registry For a PR branch, the image tag is the branch name. For the master branch, the image tag is the latest release version incremented by one patch version and a -dev suffix. For example, if the current version is 0.5.3 , pushes an image with the tag 0.5.3-dev . Our CI also provides a release workflow. See release process for more information. Helm Chart \u00b6 The deployment of quick in Kubernetes is done with Helm. The chart is part of the main repository and is pushed into our Google Artifact Registry . Infrastructure \u00b6 The infrastructure for each deployment can be found in quick-deployments .","title":"Operations"},{"location":"developer/operations/#operations","text":"","title":"Operations"},{"location":"developer/operations/#tools","text":"A list of tools we use: Gradle gcloud kubectl (recommendation: k9s ) Terraform Helm Poetry","title":"Tools"},{"location":"developer/operations/#kubernetes-cluster","text":"All internal quick deployments (dev, test, demo, personal...) are on the bakdata dev cluster. Yannick can give you access. Make also sure you are in the #bakdata-dev-cluster channel in Slack. To configure your ~/.kube/config , run: gcloud container clusters get-credentials gcp-bakdata-dev-cluster \\ --region us-east1 \\ --project gcp-bakdata-cluster Each deployment has its own namespace, commonly prefixed with quick- .","title":"Kubernetes Cluster"},{"location":"developer/operations/#container-registry","text":"All our images are located in our Docker Hub Registry . To configure docker inside the CI, use the secrets DOCKERHUB_USERNAME and DOCKERHUB_TOKEN in a workflow to login: - name: Login to Docker Hub uses: docker/login-action@v1 with: username: ${{ inputs.username }} password: ${{ inputs.token }} Once you have docker configured you can tag and push images using jib: ./gradlew -Pversion=<image-tag> jib","title":"Container Registry"},{"location":"developer/operations/#artifact-registry-helm","text":"All artifacts are located in our Google Artifact Registry us-east1-docker.pkg.dev/d9p-quick . You can access it through the web console . We currently only use it for helm chart artifacts. To configure your local helm (in case you want to push manually), run: gcloud auth configure-docker us-east1-docker.pkg.dev export HELM_EXPERIMENTAL_OCI = 1 export DOCKER_CONFIG = \"~/.docker\" export HELM_REGISTRY_CONFIG = \" ${ DOCKER_CONFIG } /config.json\" To configure helm inside the CI, use the following command to login: - name: Login to Helm registry run: | gcloud auth print-access-token | helm registry login -u oauth2accesstoken \\ --password-stdin https://us-east1-docker.pkg.dev shell: bash Once you have helm configured you can save and push helm charts by running: helm chart save <chart-name> us-east1-docker.pkg.dev/d9p-quick/helm-charts-dev/<chart-name> helm chart push us-east1-docker.pkg.dev/d9p-quick/helm-charts-dev/<chart-name>:<chart-version> If you want to push a helm chart for production, then you can replace helm-charts-dev with helm-charts . Warning The container registry is in a different Google Cloud project than the development cluster. Hence, we need to configure an image-pull secret.","title":"Artifact Registry (Helm)"},{"location":"developer/operations/#ci","text":"Our CI runs on top of GitHub Actions. The workflows can be found in .github/workflows . The main workflow ci.yaml has the following tasks: build & test project push image to registry For a PR branch, the image tag is the branch name. For the master branch, the image tag is the latest release version incremented by one patch version and a -dev suffix. For example, if the current version is 0.5.3 , pushes an image with the tag 0.5.3-dev . Our CI also provides a release workflow. See release process for more information.","title":"CI"},{"location":"developer/operations/#helm-chart","text":"The deployment of quick in Kubernetes is done with Helm. The chart is part of the main repository and is pushed into our Google Artifact Registry .","title":"Helm Chart"},{"location":"developer/operations/#infrastructure","text":"The infrastructure for each deployment can be found in quick-deployments .","title":"Infrastructure"},{"location":"user/","text":"Quick user guide \u00b6 What is Quick? \u00b6 Quick orchestrates your data as real-time stream of events. It helps you to run and maintain your apps on your data streams, and exposes GraphQL APIs connecting the data streams to applications and devices. User guide \u00b6 The user guide is split into three parts: Getting Started Examples Reference If you have never worked with Quick, we suggest jumping into the getting started section . It gives an overview of how to set up Quick and its CLI, and show the first steps when working with it. The guide also provides examples showcasing more complex use cases of Quick. The reference describes Quick's different parts in depth.","title":"Quick user guide"},{"location":"user/#quick-user-guide","text":"","title":"Quick user guide"},{"location":"user/#what-is-quick","text":"Quick orchestrates your data as real-time stream of events. It helps you to run and maintain your apps on your data streams, and exposes GraphQL APIs connecting the data streams to applications and devices.","title":"What is Quick?"},{"location":"user/#user-guide","text":"The user guide is split into three parts: Getting Started Examples Reference If you have never worked with Quick, we suggest jumping into the getting started section . It gives an overview of how to set up Quick and its CLI, and show the first steps when working with it. The guide also provides examples showcasing more complex use cases of Quick. The reference describes Quick's different parts in depth.","title":"User guide"},{"location":"user/examples/","text":"Examples \u00b6 The examples showcase more complex use cases of Quick. TinyURL is an application for shortening long URLs. This example shows you how you can use applications to transform a data stream. It also uses immutable topics to ensure the same key is not created twice.","title":"Examples"},{"location":"user/examples/#examples","text":"The examples showcase more complex use cases of Quick. TinyURL is an application for shortening long URLs. This example shows you how you can use applications to transform a data stream. It also uses immutable topics to ensure the same key is not created twice.","title":"Examples"},{"location":"user/examples/TinyURL/","text":"TinyURL \u00b6 TinyURL is an application that shortens any given URL to a tiny one. For example, shortening URLs is helpful for people posting on Twitter. This example shows a step-by-step guide on how to run your TinyURL application with Quick. Prerequisites \u00b6 A running Quick instance. See the Setup Quick section. You should have quick-cli installed and initialized. See the Setup Quick CLI section. Setup and installation \u00b6 Use the quick-cli to create a new topic called tiny-url . This topic stores the tokens as its key along with the URLs as its value. quick topic create tiny-url --key string --value string --immutable Note the --immutable flag. This flag determines that the topic is immutable, so there will be no duplicate keys. For this example, we created a simple Kafka-Streams application to create a count over the fetched URLs by the users. You can find the source code of the counter application here . The diagram below shows the topology of the Kafka-Streams application. The topology uses a source topic called track-fetcher and a sink topic called count-fetch : You can create both topics with the following commands: quick topic create track-fetch --key string --value string && quick topic create count-fetch --key string --value long Now that you created the topics, it's time to deploy the counter application: quick app deploy tiny-url-counter \\ --registry bakdata \\ --image quick-demo-tinyurl \\ --tag 1 .0.0 \\ --args input-topics = track-fetch output-topic = count-fetch productive = false Then create a new gateway using this command: quick gateway create tiny-url-gateway Note: When you create a gateway, it might take some time until the gateway is running. Apply the GraphQL schema on the tiny-url-gateway by using the following command: quick gateway apply tiny-url-gateway -f schema.gql Ingest and fetch TinyURLs \u00b6 After successfully setting up the application, topics, and gateway, it's time to create a TinyURL. To do so, you just ingest a key-value (token as the key and URL as value) in the tiny-url topic: curl --request POST --url \" $QUICK_URL /ingest/tiny-url/\" \\ --header 'content-type: application/json' \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data '{\"key\": \"d9p\", \"value\": \"https://www.d9p.io\"}' Now you can simulate a scenario where the user fetches a URL with its token by running the command below: curl --request POST --url \" $QUICK_URL /ingest/track-fetch/\" \\ --header 'content-type: application/json' \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data '{\"key\": \"d9p\", \"value\": \"\"}' Then the counter counts how many times the same key was ingested in the input topic and outputs the number as a value in the output topic. Query results \u00b6 Imagine a scenario where the users fetched the token d9p URL twice. Query the data and see the results: query { fetchCountOfToken ( token : \"d9p\" ) { url count } } The output should be: { \"data\" : { \"fetchCountOfToken\" : { \"url\" : \"https://www.d9p.io\" , \"count\" : 2 } } } Teardown resources \u00b6 To delete all the resources, follow these steps: Delete counter application: quick app delete tiny-url-counter Delete topics: quick topic delete tiny-url && quick topic delete track-fetch && quick topic delete count-fetch Delete gateway: quick gateway delete tiny-url-gateway","title":"TinyURL"},{"location":"user/examples/TinyURL/#tinyurl","text":"TinyURL is an application that shortens any given URL to a tiny one. For example, shortening URLs is helpful for people posting on Twitter. This example shows a step-by-step guide on how to run your TinyURL application with Quick.","title":"TinyURL"},{"location":"user/examples/TinyURL/#prerequisites","text":"A running Quick instance. See the Setup Quick section. You should have quick-cli installed and initialized. See the Setup Quick CLI section.","title":"Prerequisites"},{"location":"user/examples/TinyURL/#setup-and-installation","text":"Use the quick-cli to create a new topic called tiny-url . This topic stores the tokens as its key along with the URLs as its value. quick topic create tiny-url --key string --value string --immutable Note the --immutable flag. This flag determines that the topic is immutable, so there will be no duplicate keys. For this example, we created a simple Kafka-Streams application to create a count over the fetched URLs by the users. You can find the source code of the counter application here . The diagram below shows the topology of the Kafka-Streams application. The topology uses a source topic called track-fetcher and a sink topic called count-fetch : You can create both topics with the following commands: quick topic create track-fetch --key string --value string && quick topic create count-fetch --key string --value long Now that you created the topics, it's time to deploy the counter application: quick app deploy tiny-url-counter \\ --registry bakdata \\ --image quick-demo-tinyurl \\ --tag 1 .0.0 \\ --args input-topics = track-fetch output-topic = count-fetch productive = false Then create a new gateway using this command: quick gateway create tiny-url-gateway Note: When you create a gateway, it might take some time until the gateway is running. Apply the GraphQL schema on the tiny-url-gateway by using the following command: quick gateway apply tiny-url-gateway -f schema.gql","title":"Setup and installation"},{"location":"user/examples/TinyURL/#ingest-and-fetch-tinyurls","text":"After successfully setting up the application, topics, and gateway, it's time to create a TinyURL. To do so, you just ingest a key-value (token as the key and URL as value) in the tiny-url topic: curl --request POST --url \" $QUICK_URL /ingest/tiny-url/\" \\ --header 'content-type: application/json' \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data '{\"key\": \"d9p\", \"value\": \"https://www.d9p.io\"}' Now you can simulate a scenario where the user fetches a URL with its token by running the command below: curl --request POST --url \" $QUICK_URL /ingest/track-fetch/\" \\ --header 'content-type: application/json' \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data '{\"key\": \"d9p\", \"value\": \"\"}' Then the counter counts how many times the same key was ingested in the input topic and outputs the number as a value in the output topic.","title":"Ingest and fetch TinyURLs"},{"location":"user/examples/TinyURL/#query-results","text":"Imagine a scenario where the users fetched the token d9p URL twice. Query the data and see the results: query { fetchCountOfToken ( token : \"d9p\" ) { url count } } The output should be: { \"data\" : { \"fetchCountOfToken\" : { \"url\" : \"https://www.d9p.io\" , \"count\" : 2 } } }","title":"Query results"},{"location":"user/examples/TinyURL/#teardown-resources","text":"To delete all the resources, follow these steps: Delete counter application: quick app delete tiny-url-counter Delete topics: quick topic delete tiny-url && quick topic delete track-fetch && quick topic delete count-fetch Delete gateway: quick gateway delete tiny-url-gateway","title":"Teardown resources"},{"location":"user/getting-started/","text":"Getting started \u00b6 The getting started guide gives you an overview of Quick and how to work with it. In Setup Quick , you learn how to deploy Quick's infrastructure and Quick itself. The guide covers both local and cloud environments. Setup Quick CLI explains the installation process of the main tool for interacting with Quick: the CLI. Working with Quick explains the core concepts of Quick by going through an e-commerce example.","title":"Getting started"},{"location":"user/getting-started/#getting-started","text":"The getting started guide gives you an overview of Quick and how to work with it. In Setup Quick , you learn how to deploy Quick's infrastructure and Quick itself. The guide covers both local and cloud environments. Setup Quick CLI explains the installation process of the main tool for interacting with Quick: the CLI. Working with Quick explains the core concepts of Quick by going through an e-commerce example.","title":"Getting started"},{"location":"user/getting-started/setup-cli/","text":"Setup Quick CLI \u00b6 The main tool for administrating Quick is its CLI . Before you can start to work with Quick, you will have to set it up. Installation \u00b6 The first step is to install the Quick CLI. You can do this via pip. Quick CLI works with Python versions 3.7-3.9: pip install --index-url https://test.pypi.org/simple/ \\ --extra-index-url https://pypi.org/simple/ \\ quick-cli The command quick -v lets you verify that the installation was successful. Context configuration \u00b6 Next, you can configure the Quick cluster's host and API key. The CLI's context command manages this configuration. To create a new context named guide , you can run: quick context create \\ --host \" $QUICK_URL \" \\ --key \" $QUICK_API_KEY \" \\ --context guide You can then activate the context with the following command: quick context activate guide","title":"Setup Quick CLI"},{"location":"user/getting-started/setup-cli/#setup-quick-cli","text":"The main tool for administrating Quick is its CLI . Before you can start to work with Quick, you will have to set it up.","title":"Setup Quick CLI"},{"location":"user/getting-started/setup-cli/#installation","text":"The first step is to install the Quick CLI. You can do this via pip. Quick CLI works with Python versions 3.7-3.9: pip install --index-url https://test.pypi.org/simple/ \\ --extra-index-url https://pypi.org/simple/ \\ quick-cli The command quick -v lets you verify that the installation was successful.","title":"Installation"},{"location":"user/getting-started/setup-cli/#context-configuration","text":"Next, you can configure the Quick cluster's host and API key. The CLI's context command manages this configuration. To create a new context named guide , you can run: quick context create \\ --host \" $QUICK_URL \" \\ --key \" $QUICK_API_KEY \" \\ --context guide You can then activate the context with the following command: quick context activate guide","title":"Context configuration"},{"location":"user/getting-started/setup-quick/","text":"Setup Quick \u00b6 In this part, you will set up a Quick cluster. This includes: optionally creating a local Kubernetes cluster running Apache Kafka and Confluent's Schema Registry deploying Quick Prerequisites \u00b6 k3d (Version 5.3.0+) and Docker (Version >= v20.10.5) or an existing Kubernetes cluster (>= 1.21.0) kubectl (Compatible with server version 1.21.0) Helm (Version 3.8.0+) Setup Kubernetes with k3d \u00b6 If you don't have access to an existing Kubernetes cluster, this section will guide you through creating a local cluster. We recommend the lightweight Kubernetes distribution k3s for this. k3d is a wrapper around k3s in Docker, that lets you get started fast. You can install it with k3d's installation script: wget -q -O - https://raw.githubusercontent.com/k3d-io/k3d/v5.3.0/install.sh | bash For other ways of installing k3d, you can have a look at their installation guide . Attention k3s includes Traefik as a loadbalancer. In case you want to use a different Kubernetes distribution, you might have to install Traefik separately. For more information, please refer to the Traefik deployment section. With k3d installed, you can create a new cluster called quick : k3d cluster create quick Note This automatically configures kubectl to connect to the local cluster by modifying your ~/.kube/config . In case you manually set the KUBECONFIG variable or don't want that k3d modifies your config, k3d offers many other options . After the command ran, you can check the cluster status with kubectl get pods -n kube-system . When all returned elements have a STATUS of Running or Completed , you can query the load balancer address: kubectl get services --namespace kube-system traefik --output jsonpath = '{.status.loadBalancer.ingress[0].ip}' In the following, the guide will use the variable QUICK_URL to refer to the loadbalancer address. You can set it depending on your shell: bash/zsh fish export QUICK_HOST = \" $( kubectl get services --namespace kube-system traefik --output jsonpath = '{.status.loadBalancer.ingress[0].ip}' ) \" export QUICK_URL = \"http:// $QUICK_HOST \" set QUICK_HOST \" $( kubectl get services --namespace kube-system traefik --output jsonpath = '{.status.loadBalancer.ingress[0].ip}' ) \" set QUICK_URL \"http:// $QUICK_HOST \" Traefik (optional) \u00b6 k3s uses Traefik by default as its loadbalancer. If you are using k3s as your Kubernetes distribution, you can go directly to the Kafka deployment section. However, if you are using another Kubernetes distribution, you can use this guide to deploy Traefik to your Kubernetes cluster. This section provides a step-by-step guide on how to deploy Traefik to your Kubernetes cluster. Traefik is the Ingress controller Quick needs for load balancing incoming requests. We recommend the official Helm chart to deploy Traefik. Add Traefik Helm repository helm repo add traefik https://helm.traefik.io/traefik && helm repo update Deploy Traefik with Helm helm upgrade --install traefik traefik/traefik \\ --namespace infrastructure Note This guide uses the default values of Traefik's Helm charts for the deployment. For instance, Traefik won't use TLS with this configuration. For more information on how you can enable TLS, please refer to the Traefik documentation . Kafka \u00b6 To deploy Kafka, this guide uses Confluent's Helm Chart. Add Confluent's Helm Chart repository helm repo add confluentinc https://confluentinc.github.io/cp-helm-charts/ && helm repo update Install Kafka, Zookeeper and the Schema Registry. A single Helm chart installs all three components. Below you can find an example for the --values ./kafka.yaml file configuring the deployment. helm upgrade \\ --install \\ --version 0 .6.1 \\ --values ./kafka.yaml \\ --namespace infrastructure \\ --create-namespace \\ --wait \\ k8kafka confluentinc/cp-helm-charts Kafka Helm Chart Values ( kafka.yaml ) An example value configuration for Confluent's Helm chart. This configuration deploys a single Broker, a Schema Registry and Zookeeper with minimal resources. kafka.yaml cp-zookeeper : enabled : true imageTag : 6.1.1 servers : 1 heapOptions : \"-Xms124M -Xmx124M\" overrideGroupId : k8kafka fullnameOverride : \"k8kafka-cp-zookeeper\" resources : requests : cpu : 50m memory : 0.2G limits : cpu : 250m memory : 0.2G prometheus : jmx : enabled : false cp-kafka : brokers : 1 imageTag : 6.1.1 enabled : true podManagementPolicy : Parallel configurationOverrides : \"auto.create.topics.enable\" : false \"offsets.topic.replication.factor\" : 1 \"transaction.state.log.replication.factor\" : 1 \"transaction.state.log.min.isr\" : 1 resources : requests : cpu : 50m memory : 0.5G limits : cpu : 250m memory : 0.5G prometheus : jmx : enabled : false persistence : enabled : false cp-schema-registry : enabled : true imageTag : 6.1.1 fullnameOverride : \"k8kafka-cp-schema-registry\" overrideGroupId : \"k8kafka\" kafka : bootstrapServers : \"PLAINTEXT://k8kafka-cp-kafka-headless:9092\" resources : requests : cpu : 50m memory : 0.25G limits : cpu : 250m memory : 0.25G prometheus : jmx : enabled : false cp-ksql-server : enabled : false cp-kafka-connect : enabled : false cp-control-center : enabled : false cp-kafka-rest : enabled : false Depending on your system, it can take a couple of minutes before all components are up and running. You can view the status of the created pods by running kubectl get pods -n infrastructure . You should now have Zookeeper, Kafka and the Schema Registry running in a namespace called infrastructure . In the Kubernetes cluster, you can connect to Kafka with k8kafka-cp-kafka.infrastructure:9092 and the Schema Registry with http://k8kafka-cp-schema-registry.infrastructure:8081 . You are now set to deploy Quick itself. Quick \u00b6 Quick comes with its own Helm chart for installing it in Kubernetes clusters. Add the Quick Helm chart repository and update the index: helm repo add quick https://bakdata.github.io/quick && helm repo update Crate a random secret key called QUICK_API_KEY : bash/zsh fish export QUICK_API_KEY = \"random-key\" set QUICK_API_KEY \"random-key\" Install Quick with Helm. Below is an example quick.yaml as a configuration for Quick in local clusters. helm upgrade --install quick quick/quick \\ --namespace quick \\ --version 0 .4.1-dev \\ --create-namespace \\ --set apiKey = \" $QUICK_API_KEY \" \\ -f \"./quick.yaml\" Quick Helm Chart Values ( quick.yaml ) An example configuration for local Kubernetes clusters. It lets Quick work with a single Kafka broker and HTTP instead of HTTPS. For more information about the configuration of Quick's Helm Chart, please see the reference . quick.yaml image : pullPolicy : \"Always\" tag : \"0.4.1-dev\" ingress : ssl : False entrypoint : \"web\" avro : namespace : \"quick\" manager : name : \"quick-manager\" replicaCount : 1 ingest : name : \"quick-ingest\" replicaCount : 1 quickConfig : QUICK_DEFAULT_REPLICAS : \"1\" QUICK_KAFKA_BOOTSTRAP_SERVER : k8kafka-cp-kafka.infrastructure:9092 QUICK_KAFKA_INTERNAL_PARTITIONS : \"3\" QUICK_KAFKA_INTERNAL_REPLICATION_FACTOR : \"1\" QUICK_KAFKA_SCHEMA_REGISTRY_URL : http://k8kafka-cp-schema-registry.infrastructure:8081 QUICK_TOPIC_REGISTRY_PARTITIONS : \"3\" QUICK_TOPIC_REGISTRY_REPLICATION_FACTOR : \"1\" QUICK_TOPIC_REGISTRY_SERVICE_NAME : internal-topic-registry QUICK_TOPIC_REGISTRY_TOPIC_NAME : __topic-registry You can check the status of Quick by running kubectl get pods -n quick . There should be three running pods: quick-manager , quick-ingest and internal-topics-registry .","title":"Setup Quick"},{"location":"user/getting-started/setup-quick/#setup-quick","text":"In this part, you will set up a Quick cluster. This includes: optionally creating a local Kubernetes cluster running Apache Kafka and Confluent's Schema Registry deploying Quick","title":"Setup Quick"},{"location":"user/getting-started/setup-quick/#prerequisites","text":"k3d (Version 5.3.0+) and Docker (Version >= v20.10.5) or an existing Kubernetes cluster (>= 1.21.0) kubectl (Compatible with server version 1.21.0) Helm (Version 3.8.0+)","title":"Prerequisites"},{"location":"user/getting-started/setup-quick/#setup-kubernetes-with-k3d","text":"If you don't have access to an existing Kubernetes cluster, this section will guide you through creating a local cluster. We recommend the lightweight Kubernetes distribution k3s for this. k3d is a wrapper around k3s in Docker, that lets you get started fast. You can install it with k3d's installation script: wget -q -O - https://raw.githubusercontent.com/k3d-io/k3d/v5.3.0/install.sh | bash For other ways of installing k3d, you can have a look at their installation guide . Attention k3s includes Traefik as a loadbalancer. In case you want to use a different Kubernetes distribution, you might have to install Traefik separately. For more information, please refer to the Traefik deployment section. With k3d installed, you can create a new cluster called quick : k3d cluster create quick Note This automatically configures kubectl to connect to the local cluster by modifying your ~/.kube/config . In case you manually set the KUBECONFIG variable or don't want that k3d modifies your config, k3d offers many other options . After the command ran, you can check the cluster status with kubectl get pods -n kube-system . When all returned elements have a STATUS of Running or Completed , you can query the load balancer address: kubectl get services --namespace kube-system traefik --output jsonpath = '{.status.loadBalancer.ingress[0].ip}' In the following, the guide will use the variable QUICK_URL to refer to the loadbalancer address. You can set it depending on your shell: bash/zsh fish export QUICK_HOST = \" $( kubectl get services --namespace kube-system traefik --output jsonpath = '{.status.loadBalancer.ingress[0].ip}' ) \" export QUICK_URL = \"http:// $QUICK_HOST \" set QUICK_HOST \" $( kubectl get services --namespace kube-system traefik --output jsonpath = '{.status.loadBalancer.ingress[0].ip}' ) \" set QUICK_URL \"http:// $QUICK_HOST \"","title":"Setup Kubernetes with k3d"},{"location":"user/getting-started/setup-quick/#traefik-optional","text":"k3s uses Traefik by default as its loadbalancer. If you are using k3s as your Kubernetes distribution, you can go directly to the Kafka deployment section. However, if you are using another Kubernetes distribution, you can use this guide to deploy Traefik to your Kubernetes cluster. This section provides a step-by-step guide on how to deploy Traefik to your Kubernetes cluster. Traefik is the Ingress controller Quick needs for load balancing incoming requests. We recommend the official Helm chart to deploy Traefik. Add Traefik Helm repository helm repo add traefik https://helm.traefik.io/traefik && helm repo update Deploy Traefik with Helm helm upgrade --install traefik traefik/traefik \\ --namespace infrastructure Note This guide uses the default values of Traefik's Helm charts for the deployment. For instance, Traefik won't use TLS with this configuration. For more information on how you can enable TLS, please refer to the Traefik documentation .","title":"Traefik (optional)"},{"location":"user/getting-started/setup-quick/#kafka","text":"To deploy Kafka, this guide uses Confluent's Helm Chart. Add Confluent's Helm Chart repository helm repo add confluentinc https://confluentinc.github.io/cp-helm-charts/ && helm repo update Install Kafka, Zookeeper and the Schema Registry. A single Helm chart installs all three components. Below you can find an example for the --values ./kafka.yaml file configuring the deployment. helm upgrade \\ --install \\ --version 0 .6.1 \\ --values ./kafka.yaml \\ --namespace infrastructure \\ --create-namespace \\ --wait \\ k8kafka confluentinc/cp-helm-charts Kafka Helm Chart Values ( kafka.yaml ) An example value configuration for Confluent's Helm chart. This configuration deploys a single Broker, a Schema Registry and Zookeeper with minimal resources. kafka.yaml cp-zookeeper : enabled : true imageTag : 6.1.1 servers : 1 heapOptions : \"-Xms124M -Xmx124M\" overrideGroupId : k8kafka fullnameOverride : \"k8kafka-cp-zookeeper\" resources : requests : cpu : 50m memory : 0.2G limits : cpu : 250m memory : 0.2G prometheus : jmx : enabled : false cp-kafka : brokers : 1 imageTag : 6.1.1 enabled : true podManagementPolicy : Parallel configurationOverrides : \"auto.create.topics.enable\" : false \"offsets.topic.replication.factor\" : 1 \"transaction.state.log.replication.factor\" : 1 \"transaction.state.log.min.isr\" : 1 resources : requests : cpu : 50m memory : 0.5G limits : cpu : 250m memory : 0.5G prometheus : jmx : enabled : false persistence : enabled : false cp-schema-registry : enabled : true imageTag : 6.1.1 fullnameOverride : \"k8kafka-cp-schema-registry\" overrideGroupId : \"k8kafka\" kafka : bootstrapServers : \"PLAINTEXT://k8kafka-cp-kafka-headless:9092\" resources : requests : cpu : 50m memory : 0.25G limits : cpu : 250m memory : 0.25G prometheus : jmx : enabled : false cp-ksql-server : enabled : false cp-kafka-connect : enabled : false cp-control-center : enabled : false cp-kafka-rest : enabled : false Depending on your system, it can take a couple of minutes before all components are up and running. You can view the status of the created pods by running kubectl get pods -n infrastructure . You should now have Zookeeper, Kafka and the Schema Registry running in a namespace called infrastructure . In the Kubernetes cluster, you can connect to Kafka with k8kafka-cp-kafka.infrastructure:9092 and the Schema Registry with http://k8kafka-cp-schema-registry.infrastructure:8081 . You are now set to deploy Quick itself.","title":"Kafka"},{"location":"user/getting-started/setup-quick/#quick","text":"Quick comes with its own Helm chart for installing it in Kubernetes clusters. Add the Quick Helm chart repository and update the index: helm repo add quick https://bakdata.github.io/quick && helm repo update Crate a random secret key called QUICK_API_KEY : bash/zsh fish export QUICK_API_KEY = \"random-key\" set QUICK_API_KEY \"random-key\" Install Quick with Helm. Below is an example quick.yaml as a configuration for Quick in local clusters. helm upgrade --install quick quick/quick \\ --namespace quick \\ --version 0 .4.1-dev \\ --create-namespace \\ --set apiKey = \" $QUICK_API_KEY \" \\ -f \"./quick.yaml\" Quick Helm Chart Values ( quick.yaml ) An example configuration for local Kubernetes clusters. It lets Quick work with a single Kafka broker and HTTP instead of HTTPS. For more information about the configuration of Quick's Helm Chart, please see the reference . quick.yaml image : pullPolicy : \"Always\" tag : \"0.4.1-dev\" ingress : ssl : False entrypoint : \"web\" avro : namespace : \"quick\" manager : name : \"quick-manager\" replicaCount : 1 ingest : name : \"quick-ingest\" replicaCount : 1 quickConfig : QUICK_DEFAULT_REPLICAS : \"1\" QUICK_KAFKA_BOOTSTRAP_SERVER : k8kafka-cp-kafka.infrastructure:9092 QUICK_KAFKA_INTERNAL_PARTITIONS : \"3\" QUICK_KAFKA_INTERNAL_REPLICATION_FACTOR : \"1\" QUICK_KAFKA_SCHEMA_REGISTRY_URL : http://k8kafka-cp-schema-registry.infrastructure:8081 QUICK_TOPIC_REGISTRY_PARTITIONS : \"3\" QUICK_TOPIC_REGISTRY_REPLICATION_FACTOR : \"1\" QUICK_TOPIC_REGISTRY_SERVICE_NAME : internal-topic-registry QUICK_TOPIC_REGISTRY_TOPIC_NAME : __topic-registry You can check the status of Quick by running kubectl get pods -n quick . There should be three running pods: quick-manager , quick-ingest and internal-topics-registry .","title":"Quick"},{"location":"user/getting-started/teardown-resources/","text":"Teardown resources \u00b6 This section progresses from single resources to the underlying infrastructure. In case you want to delete everything, you can skip deleting single resources. Quick \u00b6 Delete the gateway: quick gateway delete example Delete the topics: quick topic delete purchase quick topic delete product Delete the Helm chart: helm delete quick -n quick Delete the namespace: kubectl delete namespace quick Infrastructure \u00b6 Delete the Helm chart: helm delete k8kafka -n infrastructure Delete the namespace: kubectl delete namespace infrastructure Local Cluster \u00b6 Delete the cluster: k3d cluster delete quick","title":"Teardown resources"},{"location":"user/getting-started/teardown-resources/#teardown-resources","text":"This section progresses from single resources to the underlying infrastructure. In case you want to delete everything, you can skip deleting single resources.","title":"Teardown resources"},{"location":"user/getting-started/teardown-resources/#quick","text":"Delete the gateway: quick gateway delete example Delete the topics: quick topic delete purchase quick topic delete product Delete the Helm chart: helm delete quick -n quick Delete the namespace: kubectl delete namespace quick","title":"Quick"},{"location":"user/getting-started/teardown-resources/#infrastructure","text":"Delete the Helm chart: helm delete k8kafka -n infrastructure Delete the namespace: kubectl delete namespace infrastructure","title":"Infrastructure"},{"location":"user/getting-started/teardown-resources/#local-cluster","text":"Delete the cluster: k3d cluster delete quick","title":"Local Cluster"},{"location":"user/getting-started/working-with-quick/","text":"Working with Quick \u00b6 With Quick and Quick CLI installed, you can start working with Quick. This guide looks into different aspects when working with Quick by following an example use case of an e-commerce application: The Gateway is one of Quick's core modules. You start by creating a new gateway, applying a schema to it and connecting to the gateway. Topics store events in Quick and connect processing block. The guide gives an overview of how you can create and delete topics. The ingest service lets you get data into the platform through a REST API. In Querying data , you connect your gateway and topics. This lets you query the data of topics and create relationships between them. The guide closes this section with subscriptions . They let you receive real-time updates from the gateway. Prerequisites \u00b6 A tool for querying GraphQL endpoints. This guide uses gql . You can install it with pip: pip install 'gql[all]==3.1.0' (Optional) jq to pretty-print JSON output. There are a lot of options for installing jq, see their download page .","title":"Working with Quick"},{"location":"user/getting-started/working-with-quick/#working-with-quick","text":"With Quick and Quick CLI installed, you can start working with Quick. This guide looks into different aspects when working with Quick by following an example use case of an e-commerce application: The Gateway is one of Quick's core modules. You start by creating a new gateway, applying a schema to it and connecting to the gateway. Topics store events in Quick and connect processing block. The guide gives an overview of how you can create and delete topics. The ingest service lets you get data into the platform through a REST API. In Querying data , you connect your gateway and topics. This lets you query the data of topics and create relationships between them. The guide closes this section with subscriptions . They let you receive real-time updates from the gateway.","title":"Working with Quick"},{"location":"user/getting-started/working-with-quick/#prerequisites","text":"A tool for querying GraphQL endpoints. This guide uses gql . You can install it with pip: pip install 'gql[all]==3.1.0' (Optional) jq to pretty-print JSON output. There are a lot of options for installing jq, see their download page .","title":"Prerequisites"},{"location":"user/getting-started/working-with-quick/gateway/","text":"Gateway \u00b6 Creating gateways \u00b6 One of the core parts of Quick is the gateway. As the GraphQL interface, it holds the schema describing your data and lets you query it. The first step when working with gateways is to create a new one: quick gateway create example The example parameter defines the name of your gateway. Since you can have many gateways, you will need the name when applying a new schema or querying data from it. It will take a couple of seconds before the gateway is ready. You can run quick gateway describe example to check the status of the gateway. It should output: Name: example Replicas: 1 Tag: 0.4.1-dev The GraphQL schema \u00b6 After the gateway finished starting, you can apply your first schema. This guide uses an e-commerce application as an example. You can start with a basic schema like this: schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase } type Purchase { purchaseId : String ! productId : Int ! userId : Int ! amount : Int price : Price } type Product { productId : Int ! name : String description : String price : Price } type Price { total : Float currency : String } The central type is Purchase describing a user buying a product. It has a link to the Product type through its field productId and a nested type Price . The Query type is unique in GraphQL since it is a root type that functions as an entry point. The schema defines a query field findPurchase , that takes a purchaseId and returns a Purchase . As you may have noticed some fields have a trailing exclamation mark: Those fields aren't nullable. Attention Every GraphQL schema requires the Query type. If you don't specify it, the Gateway won't parse the schema. In case you don't need or want one, you can use an empty query: type Query {} . Applying a schema \u00b6 With the GraphQL schema being ready, you can apply it to the created gateway: quick gateway apply example -f schema.gql The example parameter is the name of the newly created gateway that you can reference like this. The -f flag lets you pass the GraphQL schema to the command. Accessing the gateway \u00b6 You can connect to the GraphQL API of the gateway with the address $QUICK_URL/gateway/example/graphql , where example is the name of the gateway you created earlier. The gateway requires the QUICK_API_KEY to be set in the header X-API-Key . You can now use gql to see whether the gateway has the correct schema: gql-cli \" $QUICK_URL /gateway/example/graphql\" \\ -H \"X-API-Key: $QUICK_API_KEY \" \\ --print-schema Among some other types, the schema as defined earlier should be visible.","title":"Gateway"},{"location":"user/getting-started/working-with-quick/gateway/#gateway","text":"","title":"Gateway"},{"location":"user/getting-started/working-with-quick/gateway/#creating-gateways","text":"One of the core parts of Quick is the gateway. As the GraphQL interface, it holds the schema describing your data and lets you query it. The first step when working with gateways is to create a new one: quick gateway create example The example parameter defines the name of your gateway. Since you can have many gateways, you will need the name when applying a new schema or querying data from it. It will take a couple of seconds before the gateway is ready. You can run quick gateway describe example to check the status of the gateway. It should output: Name: example Replicas: 1 Tag: 0.4.1-dev","title":"Creating gateways"},{"location":"user/getting-started/working-with-quick/gateway/#the-graphql-schema","text":"After the gateway finished starting, you can apply your first schema. This guide uses an e-commerce application as an example. You can start with a basic schema like this: schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase } type Purchase { purchaseId : String ! productId : Int ! userId : Int ! amount : Int price : Price } type Product { productId : Int ! name : String description : String price : Price } type Price { total : Float currency : String } The central type is Purchase describing a user buying a product. It has a link to the Product type through its field productId and a nested type Price . The Query type is unique in GraphQL since it is a root type that functions as an entry point. The schema defines a query field findPurchase , that takes a purchaseId and returns a Purchase . As you may have noticed some fields have a trailing exclamation mark: Those fields aren't nullable. Attention Every GraphQL schema requires the Query type. If you don't specify it, the Gateway won't parse the schema. In case you don't need or want one, you can use an empty query: type Query {} .","title":"The GraphQL schema"},{"location":"user/getting-started/working-with-quick/gateway/#applying-a-schema","text":"With the GraphQL schema being ready, you can apply it to the created gateway: quick gateway apply example -f schema.gql The example parameter is the name of the newly created gateway that you can reference like this. The -f flag lets you pass the GraphQL schema to the command.","title":"Applying a schema"},{"location":"user/getting-started/working-with-quick/gateway/#accessing-the-gateway","text":"You can connect to the GraphQL API of the gateway with the address $QUICK_URL/gateway/example/graphql , where example is the name of the gateway you created earlier. The gateway requires the QUICK_API_KEY to be set in the header X-API-Key . You can now use gql to see whether the gateway has the correct schema: gql-cli \" $QUICK_URL /gateway/example/graphql\" \\ -H \"X-API-Key: $QUICK_API_KEY \" \\ --print-schema Among some other types, the schema as defined earlier should be visible.","title":"Accessing the gateway"},{"location":"user/getting-started/working-with-quick/ingest-data/","text":"Ingest data \u00b6 With the topics created, you can now move data into Quick. For that, Quick offers a REST API. You can find the REST API of the ingest service under $QUICK_URL/ingest . For creating new products, you send a POST request to $QUICK_URL/ingest/product with a JSON list of key-value pairs in the body. As with the gateway, you also have to set the X-API-Key header to QUICK_API_KEY . Using curl, you can create new products like this: curl --request POST --url \" $QUICK_URL /ingest/product\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./products.json\" Here is an example of the products.json file: Example products.json products.json [ { \"key\" : 123 , \"value\" : { \"productId\" : 123 , \"name\" : \"T-Shirt\" , \"description\" : \"black\" , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : 456 , \"value\" : { \"productId\" : 456 , \"name\" : \"Jeans\" , \"description\" : \"Non-stretch denim\" , \"price\" : { \"total\" : 79.99 , \"currency\" : \"EURO\" } } }, { \"key\" : 789 , \"value\" : { \"productId\" : 789 , \"name\" : \"Shoes\" , \"description\" : \"Sneaker\" , \"price\" : { \"total\" : 99.99 , \"currency\" : \"DOLLAR\" } } } ] As explained in topics , Quick enforces data to conform to the defined types. For example, the following product is invalid because the price isn't a complex type: invalid-product.json { \"key\" : 456 , \"value\" : { \"name\" : \"T-Shirt\" , \"description\" : \"black\" , \"price\" : 19.99 } } When you try to ingest it, the ingest service will throw an error: curl --request POST --url \" $QUICK_URL /ingest/product\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./invalid-product.json\" You can now also ingest data for purchases: curl --request POST --url \" $QUICK_URL /ingest/purchase\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./purchases.json\" With the following example of the purchases.json file: Example purchases.json purchases.json [ { \"key\" : \"abc\" , \"value\" : { \"purchaseId\" : \"abc\" , \"productId\" : 123 , \"userId\" : 1 , \"amount\" : 1 , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : \"def\" , \"value\" : { \"purchaseId\" : \"def\" , \"productId\" : 123 , \"userId\" : 2 , \"amount\" : 2 , \"price\" : { \"total\" : 30.00 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : \"ghi\" , \"value\" : { \"purchaseId\" : \"ghi\" , \"productId\" : 456 , \"userId\" : 2 , \"amount\" : 1 , \"price\" : { \"total\" : 79.99 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : \"jkl\" , \"value\" : { \"purchaseId\" : \"jkl\" , \"productId\" : 789 , \"userId\" : 2 , \"amount\" : 1 , \"price\" : { \"total\" : 99.99 , \"currency\" : \"DOLLAR\" } } } ]","title":"Ingest data"},{"location":"user/getting-started/working-with-quick/ingest-data/#ingest-data","text":"With the topics created, you can now move data into Quick. For that, Quick offers a REST API. You can find the REST API of the ingest service under $QUICK_URL/ingest . For creating new products, you send a POST request to $QUICK_URL/ingest/product with a JSON list of key-value pairs in the body. As with the gateway, you also have to set the X-API-Key header to QUICK_API_KEY . Using curl, you can create new products like this: curl --request POST --url \" $QUICK_URL /ingest/product\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./products.json\" Here is an example of the products.json file: Example products.json products.json [ { \"key\" : 123 , \"value\" : { \"productId\" : 123 , \"name\" : \"T-Shirt\" , \"description\" : \"black\" , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : 456 , \"value\" : { \"productId\" : 456 , \"name\" : \"Jeans\" , \"description\" : \"Non-stretch denim\" , \"price\" : { \"total\" : 79.99 , \"currency\" : \"EURO\" } } }, { \"key\" : 789 , \"value\" : { \"productId\" : 789 , \"name\" : \"Shoes\" , \"description\" : \"Sneaker\" , \"price\" : { \"total\" : 99.99 , \"currency\" : \"DOLLAR\" } } } ] As explained in topics , Quick enforces data to conform to the defined types. For example, the following product is invalid because the price isn't a complex type: invalid-product.json { \"key\" : 456 , \"value\" : { \"name\" : \"T-Shirt\" , \"description\" : \"black\" , \"price\" : 19.99 } } When you try to ingest it, the ingest service will throw an error: curl --request POST --url \" $QUICK_URL /ingest/product\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./invalid-product.json\" You can now also ingest data for purchases: curl --request POST --url \" $QUICK_URL /ingest/purchase\" \\ --header \"content-type:application/json\" \\ --header \"X-API-Key: $QUICK_API_KEY \" \\ --data \"@./purchases.json\" With the following example of the purchases.json file: Example purchases.json purchases.json [ { \"key\" : \"abc\" , \"value\" : { \"purchaseId\" : \"abc\" , \"productId\" : 123 , \"userId\" : 1 , \"amount\" : 1 , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : \"def\" , \"value\" : { \"purchaseId\" : \"def\" , \"productId\" : 123 , \"userId\" : 2 , \"amount\" : 2 , \"price\" : { \"total\" : 30.00 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : \"ghi\" , \"value\" : { \"purchaseId\" : \"ghi\" , \"productId\" : 456 , \"userId\" : 2 , \"amount\" : 1 , \"price\" : { \"total\" : 79.99 , \"currency\" : \"DOLLAR\" } } }, { \"key\" : \"jkl\" , \"value\" : { \"purchaseId\" : \"jkl\" , \"productId\" : 789 , \"userId\" : 2 , \"amount\" : 1 , \"price\" : { \"total\" : 99.99 , \"currency\" : \"DOLLAR\" } } } ]","title":"Ingest data"},{"location":"user/getting-started/working-with-quick/query-data/","text":"Query data \u00b6 To query your data, you have to tell Quick how to connect your schema with your topics. Quick uses GraphQL directives to represent this information. You can imagine them like annotations and attributes in programming languages: They add meta information to a schema element form which Quick derives extra functionalities. The @topic directive is the most important when working with Quick. It connects elements in your schema to Kafka topics. Query by key \u00b6 In the first step, you connect the Query field findPurchase from the gateway schema to the purchase topic. You can simply change the existing schema : schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) } # The rest of the schema remains unchanged This tells Quick to look up purchases in the purchase topic. The keyArgument defines that it should return the purchase with the key specified by the argument purchaseId . You have to re-apply the schema to update Quick: quick gateway apply example -f schema.gql You can now query the topic. In a GraphQL query, you have to select all fields you want to have recursively. This query starts with the findPurchase field and passes an argument for the purchaseId . It then selects the field of Purchase that the gateway should return, including the fields of the nested type Price . In this example, the query drops the fields purchaseId and userId . find-purchase-query.gql { findPurchase ( purchaseId : \"abc\" ) { productId amount price { total currency } } } You can run the query with gql-cli and optionally pipe it to jq : gql-cli \" $QUICK_URL /gateway/example/graphql\" \\ -H \"X-API-Key: $QUICK_API_KEY \" \\ < find-purchase-query.gql This command should return a JSON object of the data: { \"findPurchase\" : { \"productId\" : 123 , \"amount\" : 1 , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" } } } Query lists \u00b6 Quick also lets you query a list of elements. You can add the following field to the query: schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) allPurchases : [ Purchase !] @topic ( name : \"purchase\" ) } # The rest of the schema remains unchanged allPurchases differs from findPurchase in two ways. First, it doesn't have an argument and therefore also no keyArgument specified in the @topic directive. Second, it returns [Purchase!] instead of Purchase . The brackets indicate that it's a list of purchases that aren't null because of the exclamation point after Purchase . After applying the schema again, you can also query all purchases: all-purchases-query.gql { allPurchases { productId userId } } Query connected topics \u00b6 As you may have already noticed, there is a relationship between Purchase and Product in that Purchase has a field productId . What if you want to have the information for the product when querying a purchase? Quick supports this also through the @topic directive. schema.gql 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) allPurchases : [ Purchase !] @topic ( name : \"purchase\" ) } type Purchase { purchaseId : String ! productId : Int ! userId : Int ! product : Product @topic ( name : \"product\" , keyField : \"productId\" ) amount : Int price : Price } # The rest of the schema remains unchanged Line 10 is new: The Purchase has now a new field product of Type Product . The directive uses the keyField argument to define their relationship: The productId holds the value that Quick should query in the product topic. With it, you can query a purchase and directly access the connected product information: purchase-with-product-query.gql { findPurchase ( purchaseId : \"abc\" ) { amount price { total currency } product { productId name description } } } This query returns the following data: { \"findPurchase\" : { \"amount\" : 1 , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" }, \"product\" : { \"productId\" : 123 , \"name\" : \"T-Shirt\" , \"description\" : \"black\" } } }","title":"Query data"},{"location":"user/getting-started/working-with-quick/query-data/#query-data","text":"To query your data, you have to tell Quick how to connect your schema with your topics. Quick uses GraphQL directives to represent this information. You can imagine them like annotations and attributes in programming languages: They add meta information to a schema element form which Quick derives extra functionalities. The @topic directive is the most important when working with Quick. It connects elements in your schema to Kafka topics.","title":"Query data"},{"location":"user/getting-started/working-with-quick/query-data/#query-by-key","text":"In the first step, you connect the Query field findPurchase from the gateway schema to the purchase topic. You can simply change the existing schema : schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) } # The rest of the schema remains unchanged This tells Quick to look up purchases in the purchase topic. The keyArgument defines that it should return the purchase with the key specified by the argument purchaseId . You have to re-apply the schema to update Quick: quick gateway apply example -f schema.gql You can now query the topic. In a GraphQL query, you have to select all fields you want to have recursively. This query starts with the findPurchase field and passes an argument for the purchaseId . It then selects the field of Purchase that the gateway should return, including the fields of the nested type Price . In this example, the query drops the fields purchaseId and userId . find-purchase-query.gql { findPurchase ( purchaseId : \"abc\" ) { productId amount price { total currency } } } You can run the query with gql-cli and optionally pipe it to jq : gql-cli \" $QUICK_URL /gateway/example/graphql\" \\ -H \"X-API-Key: $QUICK_API_KEY \" \\ < find-purchase-query.gql This command should return a JSON object of the data: { \"findPurchase\" : { \"productId\" : 123 , \"amount\" : 1 , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" } } }","title":"Query by key"},{"location":"user/getting-started/working-with-quick/query-data/#query-lists","text":"Quick also lets you query a list of elements. You can add the following field to the query: schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) allPurchases : [ Purchase !] @topic ( name : \"purchase\" ) } # The rest of the schema remains unchanged allPurchases differs from findPurchase in two ways. First, it doesn't have an argument and therefore also no keyArgument specified in the @topic directive. Second, it returns [Purchase!] instead of Purchase . The brackets indicate that it's a list of purchases that aren't null because of the exclamation point after Purchase . After applying the schema again, you can also query all purchases: all-purchases-query.gql { allPurchases { productId userId } }","title":"Query lists"},{"location":"user/getting-started/working-with-quick/query-data/#query-connected-topics","text":"As you may have already noticed, there is a relationship between Purchase and Product in that Purchase has a field productId . What if you want to have the information for the product when querying a purchase? Quick supports this also through the @topic directive. schema.gql 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) allPurchases : [ Purchase !] @topic ( name : \"purchase\" ) } type Purchase { purchaseId : String ! productId : Int ! userId : Int ! product : Product @topic ( name : \"product\" , keyField : \"productId\" ) amount : Int price : Price } # The rest of the schema remains unchanged Line 10 is new: The Purchase has now a new field product of Type Product . The directive uses the keyField argument to define their relationship: The productId holds the value that Quick should query in the product topic. With it, you can query a purchase and directly access the connected product information: purchase-with-product-query.gql { findPurchase ( purchaseId : \"abc\" ) { amount price { total currency } product { productId name description } } } This query returns the following data: { \"findPurchase\" : { \"amount\" : 1 , \"price\" : { \"total\" : 19.99 , \"currency\" : \"DOLLAR\" }, \"product\" : { \"productId\" : 123 , \"name\" : \"T-Shirt\" , \"description\" : \"black\" } } }","title":"Query connected topics"},{"location":"user/getting-started/working-with-quick/subscriptions/","text":"Subscriptions \u00b6 In Query data you have learned to use the @topic directive to query data. This section shows you how to get real-time updates of your data. Extending the schema \u00b6 Like the Query type, the Subscription type works as entry point for GraphQL. To create a new subscription, you follow the same approach as with adding a new query: You add a field to the corresponding type. In the example schema , this can look like this: schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) allPurchases : [ Purchase !] @topic ( name : \"purchase\" ) } type Subscription { purchases : Purchase @topic ( name : \"purchase\" ) } type Purchase { purchaseId : String ! productId : Int ! userId : Int ! product : Product @topic ( name : \"product\" , keyField : \"productId\" ) amount : Int price : Price } type Product { productId : Int ! name : String description : String price : Price } type Price { total : Float currency : String } Compared to the latest version of the schema , this schema now has a new type Subscription . The field purchases creates a new subscription that emits an event whenever Quick receives a new element in the purchase topic. Note however, that compared to the query fields, the field neither takes a key argument nor returns a list of purchases. This is because the stream contains purchases with all keys, but only one at a time. It also possible to include a key argument in subscription. Quick then filters the streams, and you only receive updates for the given key. Altair Setup \u00b6 The gql-cli doesn't support authentication for subscriptions. We therefore recommend using Altair . After you have installed it, you need to set it up. Note that Altair doesn't have access to the variables, therefore you have to replace them with the appropriate values. In the field Enter URL , enter $QUICK_URL/gateway/example/graphql In the left menu, click on \"Set Headers\" and add a new header with key X-API-Key and the value of $QUICK_API_KEY In the left menu, click on \"Subscription URL\" Set the URL to ws://$QUICK_HOST/gateway/example/graphql-ws . Note that the URL uses ws as protocol and has -ws suffix. Set the connection parameters to { \"X-API-Key\" : \"$QUICK_API_KEY\" } Running the subscription \u00b6 To subscribe to the purchase events, you can run the following query in Altair: subscription.gql subscription { purchases { product { name description } amount price { total currency } } } To let the subscription run, you can press the Run subscription button. You can now ingest new data into the purchase topic and will receive them in your subscription. You can test this by using the purchases.json from the ingest data section . For example, ingest the following purchase: subscription-product.json { \"key\" : \"aj\" , \"value\" : { \"purchaseId\" : \"aj\" , \"productId\" : 123 , \"userId\" : 2 , \"amount\" : 2 , \"price\" : { \"total\" : 29.99 , \"currency\" : \"DOLLAR\" } } } The subscription should emit the following event: { \"data\" : { \"purchases\" : { \"product\" : { \"name\" : \"T-Shirt\" , \"description\" : \"black\" }, \"amount\" : 2 , \"price\" : { \"total\" : 29.99 , \"currency\" : \"DOLLAR\" } } } } As you can see, Quick automatically extends the data by the product information.","title":"Subscriptions"},{"location":"user/getting-started/working-with-quick/subscriptions/#subscriptions","text":"In Query data you have learned to use the @topic directive to query data. This section shows you how to get real-time updates of your data.","title":"Subscriptions"},{"location":"user/getting-started/working-with-quick/subscriptions/#extending-the-schema","text":"Like the Query type, the Subscription type works as entry point for GraphQL. To create a new subscription, you follow the same approach as with adding a new query: You add a field to the corresponding type. In the example schema , this can look like this: schema.gql type Query { findPurchase ( purchaseId : String ) : Purchase @topic ( name : \"purchase\" , keyArgument : \"purchaseId\" ) allPurchases : [ Purchase !] @topic ( name : \"purchase\" ) } type Subscription { purchases : Purchase @topic ( name : \"purchase\" ) } type Purchase { purchaseId : String ! productId : Int ! userId : Int ! product : Product @topic ( name : \"product\" , keyField : \"productId\" ) amount : Int price : Price } type Product { productId : Int ! name : String description : String price : Price } type Price { total : Float currency : String } Compared to the latest version of the schema , this schema now has a new type Subscription . The field purchases creates a new subscription that emits an event whenever Quick receives a new element in the purchase topic. Note however, that compared to the query fields, the field neither takes a key argument nor returns a list of purchases. This is because the stream contains purchases with all keys, but only one at a time. It also possible to include a key argument in subscription. Quick then filters the streams, and you only receive updates for the given key.","title":"Extending the schema"},{"location":"user/getting-started/working-with-quick/subscriptions/#altair-setup","text":"The gql-cli doesn't support authentication for subscriptions. We therefore recommend using Altair . After you have installed it, you need to set it up. Note that Altair doesn't have access to the variables, therefore you have to replace them with the appropriate values. In the field Enter URL , enter $QUICK_URL/gateway/example/graphql In the left menu, click on \"Set Headers\" and add a new header with key X-API-Key and the value of $QUICK_API_KEY In the left menu, click on \"Subscription URL\" Set the URL to ws://$QUICK_HOST/gateway/example/graphql-ws . Note that the URL uses ws as protocol and has -ws suffix. Set the connection parameters to { \"X-API-Key\" : \"$QUICK_API_KEY\" }","title":"Altair Setup"},{"location":"user/getting-started/working-with-quick/subscriptions/#running-the-subscription","text":"To subscribe to the purchase events, you can run the following query in Altair: subscription.gql subscription { purchases { product { name description } amount price { total currency } } } To let the subscription run, you can press the Run subscription button. You can now ingest new data into the purchase topic and will receive them in your subscription. You can test this by using the purchases.json from the ingest data section . For example, ingest the following purchase: subscription-product.json { \"key\" : \"aj\" , \"value\" : { \"purchaseId\" : \"aj\" , \"productId\" : 123 , \"userId\" : 2 , \"amount\" : 2 , \"price\" : { \"total\" : 29.99 , \"currency\" : \"DOLLAR\" } } } The subscription should emit the following event: { \"data\" : { \"purchases\" : { \"product\" : { \"name\" : \"T-Shirt\" , \"description\" : \"black\" }, \"amount\" : 2 , \"price\" : { \"total\" : 29.99 , \"currency\" : \"DOLLAR\" } } } } As you can see, Quick automatically extends the data by the product information.","title":"Running the subscription"},{"location":"user/getting-started/working-with-quick/topics/","text":"Topics \u00b6 With the initial schema applied to the gateway, you can now create new topics. Because they're responsible for storing all data, topics are a fundamental component of Quick. Creating new topics \u00b6 Recalling the schema from the previous section, there are two types of data: Purchase and Product . The application should be able to store the data of both types. Therefore, the next step is to create the corresponding topics. First, you create the topic for Purchase by running: quick topic create purchase \\ --key-type string --value-type schema --schema example.Purchase The first parameter is purchase : the name of the topic you create. The key-type and value-type options define the values of key and value respectively. Quick ensures that data ingested into this topic conforms to these types. If you'd try to ingest data with a number as key into the purchase topic, Quick throws an error. Next to primitives types like string , Quick also support complex types defined by schema . When using the schema option, you have to tell Quick how this schema should look like. You can do this by referencing a type of a GraphQL schema applied to a gateway. In this case, you want to first reference the earlier create gateway called example . In example , the Purchase type corresponds to the data in this topic. The --schema option is therefore example.Purchase . You can now also create the product topic and a price topic: quick topic create product --key-type long --value-type schema --schema example.Product && quick topic create price --key-type long --value-type schema --schema example.Price In contrast to the purchase topic, this topic has keys of type long. Topic information \u00b6 The Quick CLI comes with commands to view the current state of topics in Quick. You can first take a look at the created topics: quick topic list Next, you can also view a more detailed information about a topic: quick topic describe purchase This command returns among others the types and schema of the topic. Deleting topics \u00b6 You can also delete topics. For example, the price topic is no longer used, and you want to remove it: quick topic delete price","title":"Topics"},{"location":"user/getting-started/working-with-quick/topics/#topics","text":"With the initial schema applied to the gateway, you can now create new topics. Because they're responsible for storing all data, topics are a fundamental component of Quick.","title":"Topics"},{"location":"user/getting-started/working-with-quick/topics/#creating-new-topics","text":"Recalling the schema from the previous section, there are two types of data: Purchase and Product . The application should be able to store the data of both types. Therefore, the next step is to create the corresponding topics. First, you create the topic for Purchase by running: quick topic create purchase \\ --key-type string --value-type schema --schema example.Purchase The first parameter is purchase : the name of the topic you create. The key-type and value-type options define the values of key and value respectively. Quick ensures that data ingested into this topic conforms to these types. If you'd try to ingest data with a number as key into the purchase topic, Quick throws an error. Next to primitives types like string , Quick also support complex types defined by schema . When using the schema option, you have to tell Quick how this schema should look like. You can do this by referencing a type of a GraphQL schema applied to a gateway. In this case, you want to first reference the earlier create gateway called example . In example , the Purchase type corresponds to the data in this topic. The --schema option is therefore example.Purchase . You can now also create the product topic and a price topic: quick topic create product --key-type long --value-type schema --schema example.Product && quick topic create price --key-type long --value-type schema --schema example.Price In contrast to the purchase topic, this topic has keys of type long.","title":"Creating new topics"},{"location":"user/getting-started/working-with-quick/topics/#topic-information","text":"The Quick CLI comes with commands to view the current state of topics in Quick. You can first take a look at the created topics: quick topic list Next, you can also view a more detailed information about a topic: quick topic describe purchase This command returns among others the types and schema of the topic.","title":"Topic information"},{"location":"user/getting-started/working-with-quick/topics/#deleting-topics","text":"You can also delete topics. For example, the price topic is no longer used, and you want to remove it: quick topic delete price","title":"Deleting topics"},{"location":"user/reference/cli-commands/","text":"Quick CLI \u00b6 Commands \u00b6 quick \u00b6 Control your quick deployment Usage: quick [-h] command [options ...] ... Available commands: context : Manage quick configuration topic : Manage topics gateway : Manage gateways mirror : Manage mirrors app : Manage streams applications quick context \u00b6 Manage quick configuration Usage: quick context [-h] command [options ...] ... Available commands: create : Create a new context describe : Display a context configuration list : List all context configurations activate : Activate context quick context create \u00b6 Create a new context Usage: quick context create [-h] [--host HOST] [--key API-KEY] [--context CONTEXT] [--debug] Optional: --host : Name of the host (prompted if not given) --key : API key of this quick instance (prompted if not given) --context : Name of the context (defaults to host) --debug : Enable debug output quick context describe \u00b6 Display a context configuration Usage: quick context describe [-h] [--context CONTEXT] [--debug] Optional: --context : Select context (defaults to current one) --debug : Enable debug output quick context list \u00b6 List all context configurations Usage: quick context list [-h] [--debug] Optional: --debug : Enable debug output quick context activate \u00b6 Activate context Usage: quick context activate [-h] [--debug] NAME Required: name : Name of the context to activate Optional: --debug : Enable debug output quick topic \u00b6 Manage topics Usage: quick topic [-h] command [options ...] ... Available commands: create : Create a new topic delete : Delete a topic list : List all topics describe : Display information for a topic quick topic create \u00b6 Create a new topic Usage: quick topic create [-h] -k TYPE -v TYPE [-s SCHEMA] [--immutable] [--retention-time RETENTION_TIME] [--context CONTEXT] [--debug] NAME Required: name : The name of the topic -k, --key-type : The key type of the topic -v, --value-type : The value type of the topic Optional: -s, --schema : The location of the schema file or std in --immutable : An immutable topic does not allow ingesting the same key twice (default: False) --retention-time : Retention time of data in the topic in (if not given, the data is kept indefinitely) --context : Context of quick --debug : Enable debug output quick topic delete \u00b6 Delete a topic Usage: quick topic delete [-h] [--context CONTEXT] [--debug] TOPIC Required: topic : Topic to delete Optional: --context : Context of quick --debug : Enable debug output quick topic list \u00b6 List all topics Usage: quick topic list [-h] [--context CONTEXT] [--debug] Optional: --context : Context of quick --debug : Enable debug output quick topic describe \u00b6 Display information for a topic Usage: quick topic describe [-h] [--context CONTEXT] [--debug] NAME Required: name : The name of the topic. Optional: --context : Context of quick --debug : Enable debug output quick gateway \u00b6 Manage gateways Usage: quick gateway [-h] command [options ...] ... Available commands: create : Create a gateway delete : Delete a gateway apply : Apply a new schema to a gateway list : List all gateways describe : Display information about a gateway quick gateway create \u00b6 Create a gateway Usage: quick gateway create [-h] [--replicas REPLICAS] [--tag TAG] [--context CONTEXT] [--debug] NAME Required: gateway_name : Name of the gateway Optional: --replicas : Number of replicas --tag : Docker image tag (defaults to currently installed tag) --context : Context of quick --debug : Enable debug output quick gateway delete \u00b6 Delete a gateway Usage: quick gateway delete [-h] [--context CONTEXT] [--debug] NAME Required: gateway_name : Name of the gateway Optional: --context : Context of quick --debug : Enable debug output quick gateway apply \u00b6 Apply a new schema to a gateway Usage: quick gateway apply [-h] -f FILE [--context CONTEXT] [--debug] NAME Required: gateway : Name of the gateway -f, --file : Location of the schema file or std in Optional: --context : Context of quick --debug : Enable debug output quick gateway list \u00b6 List all gateways Usage: quick gateway list [-h] [--context CONTEXT] [--debug] Optional: --context : Context of quick --debug : Enable debug output quick gateway describe \u00b6 Display information about a gateway Usage: quick gateway describe [-h] [--context CONTEXT] [--debug] NAME Required: name : The name of the gateway. Optional: --context : Context of quick --debug : Enable debug output quick mirror \u00b6 Mirrors make topics queryable. With these commands, you can control which topic can be queried through gateway. Usage: quick mirror [-h] command [options ...] ... Available commands: create : Mirror a Kafka topic delete : Delete a mirror quick mirror create \u00b6 Create a mirror for a topic and make it queryable through a gateway Usage: quick mirror create [-h] [--tag TAG] [--replicas REPLICAS] [--context CONTEXT] [--debug] TOPIC Required: topic : Topic to mirror Optional: --tag : Docker image tag (defaults to currently installed tag) --replicas : Number of replicas (default: 1) --context : Context of quick --debug : Enable debug output quick mirror delete \u00b6 Delete a mirror Usage: quick mirror delete [-h] [--context CONTEXT] [--debug] TOPIC Required: mirror : Topic to delete mirror from Optional: --context : Context of quick --debug : Enable debug output quick app \u00b6 Streams applications are Kafka Streams applications processing your data stream. You can deploy them to the quick cluster. Usage: quick app [-h] command [options ...] ... Available commands: deploy : Deploy a new application delete : Delete an application quick app deploy \u00b6 Deploy a new application. The application must be provided as a Docker image. You can specify the registry. Usage: quick app deploy [-h] --registry REGISTRY_URL --image IMAGE --tag TAG [--replicas REPLICAS] [--args [ARG=VALUE [ARG=VALUE ...]]] [--context CONTEXT] [--debug] NAME Required: name : Name of the application (must be unique) --registry : URL to container registry --image : Name of the image --tag : Docker image tag Optional: --replicas : Number of replicas --args : CLI arguments of the application (broker and schema registry not required) --context : Context of quick --debug : Enable debug output quick app delete \u00b6 Delete an application. This stops the running Streams application and removes all its state. Usage: quick app delete [-h] [--context CONTEXT] [--debug] name Required: name : Name of the application Optional: --context : Context of quick --debug : Enable debug output","title":"Quick CLI"},{"location":"user/reference/cli-commands/#quick-cli","text":"","title":"Quick CLI"},{"location":"user/reference/cli-commands/#commands","text":"","title":"Commands"},{"location":"user/reference/cli-commands/#quick","text":"Control your quick deployment Usage: quick [-h] command [options ...] ... Available commands: context : Manage quick configuration topic : Manage topics gateway : Manage gateways mirror : Manage mirrors app : Manage streams applications","title":"quick"},{"location":"user/reference/cli-commands/#quick-context","text":"Manage quick configuration Usage: quick context [-h] command [options ...] ... Available commands: create : Create a new context describe : Display a context configuration list : List all context configurations activate : Activate context","title":"quick context"},{"location":"user/reference/cli-commands/#quick-context-create","text":"Create a new context Usage: quick context create [-h] [--host HOST] [--key API-KEY] [--context CONTEXT] [--debug] Optional: --host : Name of the host (prompted if not given) --key : API key of this quick instance (prompted if not given) --context : Name of the context (defaults to host) --debug : Enable debug output","title":"quick context create"},{"location":"user/reference/cli-commands/#quick-context-describe","text":"Display a context configuration Usage: quick context describe [-h] [--context CONTEXT] [--debug] Optional: --context : Select context (defaults to current one) --debug : Enable debug output","title":"quick context describe"},{"location":"user/reference/cli-commands/#quick-context-list","text":"List all context configurations Usage: quick context list [-h] [--debug] Optional: --debug : Enable debug output","title":"quick context list"},{"location":"user/reference/cli-commands/#quick-context-activate","text":"Activate context Usage: quick context activate [-h] [--debug] NAME Required: name : Name of the context to activate Optional: --debug : Enable debug output","title":"quick context activate"},{"location":"user/reference/cli-commands/#quick-topic","text":"Manage topics Usage: quick topic [-h] command [options ...] ... Available commands: create : Create a new topic delete : Delete a topic list : List all topics describe : Display information for a topic","title":"quick topic"},{"location":"user/reference/cli-commands/#quick-topic-create","text":"Create a new topic Usage: quick topic create [-h] -k TYPE -v TYPE [-s SCHEMA] [--immutable] [--retention-time RETENTION_TIME] [--context CONTEXT] [--debug] NAME Required: name : The name of the topic -k, --key-type : The key type of the topic -v, --value-type : The value type of the topic Optional: -s, --schema : The location of the schema file or std in --immutable : An immutable topic does not allow ingesting the same key twice (default: False) --retention-time : Retention time of data in the topic in (if not given, the data is kept indefinitely) --context : Context of quick --debug : Enable debug output","title":"quick topic create"},{"location":"user/reference/cli-commands/#quick-topic-delete","text":"Delete a topic Usage: quick topic delete [-h] [--context CONTEXT] [--debug] TOPIC Required: topic : Topic to delete Optional: --context : Context of quick --debug : Enable debug output","title":"quick topic delete"},{"location":"user/reference/cli-commands/#quick-topic-list","text":"List all topics Usage: quick topic list [-h] [--context CONTEXT] [--debug] Optional: --context : Context of quick --debug : Enable debug output","title":"quick topic list"},{"location":"user/reference/cli-commands/#quick-topic-describe","text":"Display information for a topic Usage: quick topic describe [-h] [--context CONTEXT] [--debug] NAME Required: name : The name of the topic. Optional: --context : Context of quick --debug : Enable debug output","title":"quick topic describe"},{"location":"user/reference/cli-commands/#quick-gateway","text":"Manage gateways Usage: quick gateway [-h] command [options ...] ... Available commands: create : Create a gateway delete : Delete a gateway apply : Apply a new schema to a gateway list : List all gateways describe : Display information about a gateway","title":"quick gateway"},{"location":"user/reference/cli-commands/#quick-gateway-create","text":"Create a gateway Usage: quick gateway create [-h] [--replicas REPLICAS] [--tag TAG] [--context CONTEXT] [--debug] NAME Required: gateway_name : Name of the gateway Optional: --replicas : Number of replicas --tag : Docker image tag (defaults to currently installed tag) --context : Context of quick --debug : Enable debug output","title":"quick gateway create"},{"location":"user/reference/cli-commands/#quick-gateway-delete","text":"Delete a gateway Usage: quick gateway delete [-h] [--context CONTEXT] [--debug] NAME Required: gateway_name : Name of the gateway Optional: --context : Context of quick --debug : Enable debug output","title":"quick gateway delete"},{"location":"user/reference/cli-commands/#quick-gateway-apply","text":"Apply a new schema to a gateway Usage: quick gateway apply [-h] -f FILE [--context CONTEXT] [--debug] NAME Required: gateway : Name of the gateway -f, --file : Location of the schema file or std in Optional: --context : Context of quick --debug : Enable debug output","title":"quick gateway apply"},{"location":"user/reference/cli-commands/#quick-gateway-list","text":"List all gateways Usage: quick gateway list [-h] [--context CONTEXT] [--debug] Optional: --context : Context of quick --debug : Enable debug output","title":"quick gateway list"},{"location":"user/reference/cli-commands/#quick-gateway-describe","text":"Display information about a gateway Usage: quick gateway describe [-h] [--context CONTEXT] [--debug] NAME Required: name : The name of the gateway. Optional: --context : Context of quick --debug : Enable debug output","title":"quick gateway describe"},{"location":"user/reference/cli-commands/#quick-mirror","text":"Mirrors make topics queryable. With these commands, you can control which topic can be queried through gateway. Usage: quick mirror [-h] command [options ...] ... Available commands: create : Mirror a Kafka topic delete : Delete a mirror","title":"quick mirror"},{"location":"user/reference/cli-commands/#quick-mirror-create","text":"Create a mirror for a topic and make it queryable through a gateway Usage: quick mirror create [-h] [--tag TAG] [--replicas REPLICAS] [--context CONTEXT] [--debug] TOPIC Required: topic : Topic to mirror Optional: --tag : Docker image tag (defaults to currently installed tag) --replicas : Number of replicas (default: 1) --context : Context of quick --debug : Enable debug output","title":"quick mirror create"},{"location":"user/reference/cli-commands/#quick-mirror-delete","text":"Delete a mirror Usage: quick mirror delete [-h] [--context CONTEXT] [--debug] TOPIC Required: mirror : Topic to delete mirror from Optional: --context : Context of quick --debug : Enable debug output","title":"quick mirror delete"},{"location":"user/reference/cli-commands/#quick-app","text":"Streams applications are Kafka Streams applications processing your data stream. You can deploy them to the quick cluster. Usage: quick app [-h] command [options ...] ... Available commands: deploy : Deploy a new application delete : Delete an application","title":"quick app"},{"location":"user/reference/cli-commands/#quick-app-deploy","text":"Deploy a new application. The application must be provided as a Docker image. You can specify the registry. Usage: quick app deploy [-h] --registry REGISTRY_URL --image IMAGE --tag TAG [--replicas REPLICAS] [--args [ARG=VALUE [ARG=VALUE ...]]] [--context CONTEXT] [--debug] NAME Required: name : Name of the application (must be unique) --registry : URL to container registry --image : Name of the image --tag : Docker image tag Optional: --replicas : Number of replicas --args : CLI arguments of the application (broker and schema registry not required) --context : Context of quick --debug : Enable debug output","title":"quick app deploy"},{"location":"user/reference/cli-commands/#quick-app-delete","text":"Delete an application. This stops the running Streams application and removes all its state. Usage: quick app delete [-h] [--context CONTEXT] [--debug] name Required: name : Name of the application Optional: --context : Context of quick --debug : Enable debug output","title":"quick app delete"},{"location":"user/reference/configuration/","text":"Quick configuration \u00b6 Kafka \u00b6 Environment Variable Required Description QUICK_KAFKA_BOOTSTRAP_SERVER Kafka address to connect to QUICK_KAFKA_SCHEMA_REGISTRY_URL Schema Registry URL to connect to QUICK_KAFKA_APPLICATION_ID Application id to use QUICK_KAFKA_INTERNAL_PARITITIONS Number of partitions new topics are created with QUICK_KAFKA_INTERNAL_REPLICATION_FACTOR Replication factor of Kafka topics Mirror \u00b6 Environment Variable Required Description QUICK_MIRROR_PREFIX Prefix of Kubernetes deployments for mirror deployments QUICK_MIRROR_PATH REST subpath where the mirror's API is running Topic Registry \u00b6 Environment Variable Required Description QUICK_TOPIC_REGISTRY_TOPIC_NAME Topic backing the topic registry QUICK_TOPIC_REGISTRY_SERVICE_NAME Service name of the topic registry QUICK_TOPIC_REGISTRY_PARTITIONS Partition count of the topic backing the topic registry QUICK_TOPIC_REGISTRY_REPLICATION_FACTOR Replication factor of the topic backing the topic registry Avro \u00b6 Environment Variable Required Description QUICK_AVRO_NAMESPACE Namespace for avro schemas generated by Quick from GraphQL Deployment \u00b6 Environment Variable Required Description QUICK_DOCKER_REGISTRY Docker registry for use Quick images QUICK_DEFAULT_IMAGE_TAG Default image tag of Quick images to deploy QUICK_DEFAULT_REPLICAS Default amount of replicas for Quick deployments QUICK_INGRESS_HOST Host for Kubernetes Ingress objects for gateways QUICK_INGRESS_SSL Flag indicating whether the ingress should use SSL QUICK_INGRESS_ENTRYPOINT Traefik's entrypoint for ingress QUICK_MANAGER_UPDATE_MANAGED_IMAGES Flag indicating whether the manager should ensure deployments have the same image tag QUICK_MANAGER_CREATE_TOPIC_REGISTRY Flag if manager should deploy a topic registry Resources \u00b6 Environment Variable Required Description QUICK_APPLICATION_RESOURCES_MEMORY_LIMIT Memory limit for deployments QUICK_APPLICATION_RESOURCES_MEMORY_REQUEST Memory request for deployments QUICK_APPLICATION_RESOURCES_CPU_LIMIT Cpu limit for deployments QUICK_APPLICATION_RESOURCES_CPU_REQUEST Cpu requests for deployments Gateway \u00b6 Environment Variable Required Description QUICK_SCHEMA_PATH The path where the schema file is located","title":"Quick configuration"},{"location":"user/reference/configuration/#quick-configuration","text":"","title":"Quick configuration"},{"location":"user/reference/configuration/#kafka","text":"Environment Variable Required Description QUICK_KAFKA_BOOTSTRAP_SERVER Kafka address to connect to QUICK_KAFKA_SCHEMA_REGISTRY_URL Schema Registry URL to connect to QUICK_KAFKA_APPLICATION_ID Application id to use QUICK_KAFKA_INTERNAL_PARITITIONS Number of partitions new topics are created with QUICK_KAFKA_INTERNAL_REPLICATION_FACTOR Replication factor of Kafka topics","title":"Kafka"},{"location":"user/reference/configuration/#mirror","text":"Environment Variable Required Description QUICK_MIRROR_PREFIX Prefix of Kubernetes deployments for mirror deployments QUICK_MIRROR_PATH REST subpath where the mirror's API is running","title":"Mirror"},{"location":"user/reference/configuration/#topic-registry","text":"Environment Variable Required Description QUICK_TOPIC_REGISTRY_TOPIC_NAME Topic backing the topic registry QUICK_TOPIC_REGISTRY_SERVICE_NAME Service name of the topic registry QUICK_TOPIC_REGISTRY_PARTITIONS Partition count of the topic backing the topic registry QUICK_TOPIC_REGISTRY_REPLICATION_FACTOR Replication factor of the topic backing the topic registry","title":"Topic Registry"},{"location":"user/reference/configuration/#avro","text":"Environment Variable Required Description QUICK_AVRO_NAMESPACE Namespace for avro schemas generated by Quick from GraphQL","title":"Avro"},{"location":"user/reference/configuration/#deployment","text":"Environment Variable Required Description QUICK_DOCKER_REGISTRY Docker registry for use Quick images QUICK_DEFAULT_IMAGE_TAG Default image tag of Quick images to deploy QUICK_DEFAULT_REPLICAS Default amount of replicas for Quick deployments QUICK_INGRESS_HOST Host for Kubernetes Ingress objects for gateways QUICK_INGRESS_SSL Flag indicating whether the ingress should use SSL QUICK_INGRESS_ENTRYPOINT Traefik's entrypoint for ingress QUICK_MANAGER_UPDATE_MANAGED_IMAGES Flag indicating whether the manager should ensure deployments have the same image tag QUICK_MANAGER_CREATE_TOPIC_REGISTRY Flag if manager should deploy a topic registry","title":"Deployment"},{"location":"user/reference/configuration/#resources","text":"Environment Variable Required Description QUICK_APPLICATION_RESOURCES_MEMORY_LIMIT Memory limit for deployments QUICK_APPLICATION_RESOURCES_MEMORY_REQUEST Memory request for deployments QUICK_APPLICATION_RESOURCES_CPU_LIMIT Cpu limit for deployments QUICK_APPLICATION_RESOURCES_CPU_REQUEST Cpu requests for deployments","title":"Resources"},{"location":"user/reference/configuration/#gateway","text":"Environment Variable Required Description QUICK_SCHEMA_PATH The path where the schema file is located","title":"Gateway"},{"location":"user/reference/dependency-versions/","text":"Dependency versions \u00b6 Component Version Quick 0.4.1-dev Kubernetes 1.20 - 1.22 Kafka 2.7 - 2.8 Schema Registry 5.5 - 6.2 Traefik 2.4 - 2.5 Quick CLI 0.4.1-dev Python (Quick CLI) 3.7-3.9","title":"Dependency versions"},{"location":"user/reference/dependency-versions/#dependency-versions","text":"Component Version Quick 0.4.1-dev Kubernetes 1.20 - 1.22 Kafka 2.7 - 2.8 Schema Registry 5.5 - 6.2 Traefik 2.4 - 2.5 Quick CLI 0.4.1-dev Python (Quick CLI) 3.7-3.9","title":"Dependency versions"},{"location":"user/reference/graphql-extensions/","text":"GraphQL extensions \u00b6 Enums \u00b6 RestDirectiveMethod \u00b6 enum RestDirectiveMethod { GET , POST } Directives \u00b6 @topic \u00b6 directive @topic( name: String! , # Name of the topic. keyArgument: String , # The argument which contains the key. This also supports arguments from parents. keyField: String # The field which contains the key. This can be used when the key is part of a different mirror. ) on FIELD_DEFINITION @rest \u00b6 directive @rest( url: String! # url of the rest service pathParameter: [String!] # list of the arguments that should be included in the list queryParameter: [String!] # list of arguments that should be included as query parameter in the form of `argumentName=value` bodyParameter: String # argument which represents a body. This cannot be a scalar httpMethod: RestDirectiveMethod = GET # The HTTP method used when calling the rest service ) on FIELD_DEFINITION","title":"GraphQL extensions"},{"location":"user/reference/graphql-extensions/#graphql-extensions","text":"","title":"GraphQL extensions"},{"location":"user/reference/graphql-extensions/#enums","text":"","title":"Enums"},{"location":"user/reference/graphql-extensions/#restdirectivemethod","text":"enum RestDirectiveMethod { GET , POST }","title":"RestDirectiveMethod"},{"location":"user/reference/graphql-extensions/#directives","text":"","title":"Directives"},{"location":"user/reference/graphql-extensions/#topic","text":"directive @topic( name: String! , # Name of the topic. keyArgument: String , # The argument which contains the key. This also supports arguments from parents. keyField: String # The field which contains the key. This can be used when the key is part of a different mirror. ) on FIELD_DEFINITION","title":"@topic"},{"location":"user/reference/graphql-extensions/#rest","text":"directive @rest( url: String! # url of the rest service pathParameter: [String!] # list of the arguments that should be included in the list queryParameter: [String!] # list of arguments that should be included as query parameter in the form of `argumentName=value` bodyParameter: String # argument which represents a body. This cannot be a scalar httpMethod: RestDirectiveMethod = GET # The HTTP method used when calling the rest service ) on FIELD_DEFINITION","title":"@rest"},{"location":"user/reference/helm-chart/","text":"Quick Helm chart \u00b6 Below you can find the default value.yaml of Quick's Helm chart. image : # The base repository of the images repository : bakdata # The version of quick to deploy tag : \"0.4.1-dev\" # The image pull policy of manager and ingest service pullPolicy : \"Always\" avro : # The namespace used for created avro namespaces # see https://avro.apache.org/docs/current/spec.html namespace : \"\" # These configurations apply to both the helm chart ingresses and the gateway ingresses ingress : # Whether the ingress uses ssl ssl : true # Which entrypoint Traefik should use # This must match the ssl configuration: By default, websecure means ssl=true and web ssl=false entrypoint : \"websecure\" # Host of the ingress # This must be set when using a domain and can be empty when using an ip address host : \"\" # Configuration for the manager deployment manager : name : \"quick-manager\" replicaCount : 1 podAnnotations : {} # Configuration for the ingest service deployment ingest : # This value is also set as an enviornment variable for quick services so that they know how to connect to this service name : \"quick-ingest\" replicaCount : 1 podAnnotations : {} # The logging config quick should use, mainly for debugging purposes # If empty, loglevel is set to info # see https://logging.apache.org/log4j/2.x/manual/configuration.html#YAML log4jConfig : {} # The api key securing all APIs # This should be set through the CLI apiKey : \"\" # Environment variables configuring all services of quick # see the reference for more detailed information quickConfig : QUICK_KAFKA_BOOTSTRAP_SERVER : quick-kafka.default.svc.cluster.local:9092 QUICK_KAFKA_SCHEMA_REGISTRY_URL : http://quick-sr-schema-registry.default.svc.cluster.local:8081 QUICK_KAFKA_INTERNAL_PARTITIONS : \"3\" QUICK_KAFKA_INTERNAL_REPLICATION_FACTOR : \"1\" QUICK_TOPIC_REGISTRY_SERVICE_NAME : internal-topic-registry QUICK_TOPIC_REGISTRY_TOPIC_NAME : __topic-registry QUICK_TOPIC_REGISTRY_PARTITIONS : \"3\" QUICK_TOPIC_REGISTRY_REPLICATION_FACTOR : \"1\"","title":"Quick Helm chart"},{"location":"user/reference/helm-chart/#quick-helm-chart","text":"Below you can find the default value.yaml of Quick's Helm chart. image : # The base repository of the images repository : bakdata # The version of quick to deploy tag : \"0.4.1-dev\" # The image pull policy of manager and ingest service pullPolicy : \"Always\" avro : # The namespace used for created avro namespaces # see https://avro.apache.org/docs/current/spec.html namespace : \"\" # These configurations apply to both the helm chart ingresses and the gateway ingresses ingress : # Whether the ingress uses ssl ssl : true # Which entrypoint Traefik should use # This must match the ssl configuration: By default, websecure means ssl=true and web ssl=false entrypoint : \"websecure\" # Host of the ingress # This must be set when using a domain and can be empty when using an ip address host : \"\" # Configuration for the manager deployment manager : name : \"quick-manager\" replicaCount : 1 podAnnotations : {} # Configuration for the ingest service deployment ingest : # This value is also set as an enviornment variable for quick services so that they know how to connect to this service name : \"quick-ingest\" replicaCount : 1 podAnnotations : {} # The logging config quick should use, mainly for debugging purposes # If empty, loglevel is set to info # see https://logging.apache.org/log4j/2.x/manual/configuration.html#YAML log4jConfig : {} # The api key securing all APIs # This should be set through the CLI apiKey : \"\" # Environment variables configuring all services of quick # see the reference for more detailed information quickConfig : QUICK_KAFKA_BOOTSTRAP_SERVER : quick-kafka.default.svc.cluster.local:9092 QUICK_KAFKA_SCHEMA_REGISTRY_URL : http://quick-sr-schema-registry.default.svc.cluster.local:8081 QUICK_KAFKA_INTERNAL_PARTITIONS : \"3\" QUICK_KAFKA_INTERNAL_REPLICATION_FACTOR : \"1\" QUICK_TOPIC_REGISTRY_SERVICE_NAME : internal-topic-registry QUICK_TOPIC_REGISTRY_TOPIC_NAME : __topic-registry QUICK_TOPIC_REGISTRY_PARTITIONS : \"3\" QUICK_TOPIC_REGISTRY_REPLICATION_FACTOR : \"1\"","title":"Quick Helm chart"}]}